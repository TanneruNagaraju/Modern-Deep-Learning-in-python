{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset():\n",
    "    df = pd.read_csv(\"C:/Users/TANNERU/Downloads/Dataset for coding/sonar.csv\")\n",
    "    #print(df)\n",
    "    print(df.shape)\n",
    "    \n",
    "    X = df.iloc[:,:60]\n",
    "    Y = df.iloc[:,60]\n",
    "    #print(X)\n",
    "    print(\"Before Encoding\",Y)\n",
    "    print(X.shape)\n",
    "    print(Y.shape)\n",
    "    \n",
    "    #converting Y into 0 & 1\n",
    "    encoder = LabelEncoder()\n",
    "    Y = encoder.fit_transform(Y)\n",
    "    print(Y)\n",
    "    \n",
    "    Y = Y.reshape(-1,1)\n",
    "    \n",
    "    #converting into one hot encoder\n",
    "    onehot = OneHotEncoder(categories = 'auto')\n",
    "    Y = onehot.fit_transform(Y).toarray()\n",
    "    print(Y)\n",
    "    #print(Y.shape)\n",
    "\n",
    "    return X,Y\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(207, 61)\n",
      "Before Encoding 0      R\n",
      "1      R\n",
      "2      R\n",
      "3      R\n",
      "4      R\n",
      "      ..\n",
      "202    M\n",
      "203    M\n",
      "204    M\n",
      "205    M\n",
      "206    M\n",
      "Name: R, Length: 207, dtype: object\n",
      "(207, 60)\n",
      "(207,)\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[[0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(     0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109  \\\n",
       " 0    0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
       " 1    0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
       " 2    0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
       " 3    0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
       " 4    0.0286  0.0453  0.0277  0.0174  0.0384  0.0990  0.1201  0.1833  0.2105   \n",
       " ..      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       " 202  0.0187  0.0346  0.0168  0.0177  0.0393  0.1630  0.2028  0.1694  0.2328   \n",
       " 203  0.0323  0.0101  0.0298  0.0564  0.0760  0.0958  0.0990  0.1018  0.1030   \n",
       " 204  0.0522  0.0437  0.0180  0.0292  0.0351  0.1171  0.1257  0.1178  0.1258   \n",
       " 205  0.0303  0.0353  0.0490  0.0608  0.0167  0.1354  0.1465  0.1123  0.1945   \n",
       " 206  0.0260  0.0363  0.0136  0.0272  0.0214  0.0338  0.0655  0.1400  0.1843   \n",
       " \n",
       "      0.2111  ...  0.0232  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  \\\n",
       " 0    0.2872  ...  0.0125  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140   \n",
       " 1    0.6194  ...  0.0033  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316   \n",
       " 2    0.1264  ...  0.0241  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050   \n",
       " 3    0.4459  ...  0.0156  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072   \n",
       " 4    0.3039  ...  0.0104  0.0045  0.0014  0.0038  0.0013  0.0089  0.0057   \n",
       " ..      ...  ...     ...     ...     ...     ...     ...     ...     ...   \n",
       " 202  0.2684  ...  0.0203  0.0116  0.0098  0.0199  0.0033  0.0101  0.0065   \n",
       " 203  0.2154  ...  0.0051  0.0061  0.0093  0.0135  0.0063  0.0063  0.0034   \n",
       " 204  0.2529  ...  0.0155  0.0160  0.0029  0.0051  0.0062  0.0089  0.0140   \n",
       " 205  0.2354  ...  0.0042  0.0086  0.0046  0.0126  0.0036  0.0035  0.0034   \n",
       " 206  0.2354  ...  0.0181  0.0146  0.0129  0.0047  0.0039  0.0061  0.0040   \n",
       " \n",
       "      0.0084  0.0090  0.0032  \n",
       " 0    0.0049  0.0052  0.0044  \n",
       " 1    0.0164  0.0095  0.0078  \n",
       " 2    0.0044  0.0040  0.0117  \n",
       " 3    0.0048  0.0107  0.0094  \n",
       " 4    0.0027  0.0051  0.0062  \n",
       " ..      ...     ...     ...  \n",
       " 202  0.0115  0.0193  0.0157  \n",
       " 203  0.0032  0.0062  0.0067  \n",
       " 204  0.0138  0.0077  0.0031  \n",
       " 205  0.0079  0.0036  0.0048  \n",
       " 206  0.0036  0.0061  0.0115  \n",
       " \n",
       " [207 rows x 60 columns],\n",
       " array([[0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.]]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(207, 61)\n",
      "Before Encoding 0      R\n",
      "1      R\n",
      "2      R\n",
      "3      R\n",
      "4      R\n",
      "      ..\n",
      "202    M\n",
      "203    M\n",
      "204    M\n",
      "205    M\n",
      "206    M\n",
      "Name: R, Length: 207, dtype: object\n",
      "(207, 60)\n",
      "(207,)\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[[0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n",
      "train_x.shape (165, 60)\n",
      "train_y.shape (165, 2)\n",
      "test_x.shape (42, 60)\n",
      "test_y.shape (42, 2)\n",
      "n_dim 60\n",
      "epoch:  0  -  cost:  16.177273  - MSE:  455.6605804467131 - Train Accuracy:  0.46060607\n",
      "epoch:  1  -  cost:  15.50182  - MSE:  438.68921677530955 - Train Accuracy:  0.46060607\n",
      "epoch:  2  -  cost:  14.829504  - MSE:  422.53579226402786 - Train Accuracy:  0.46060607\n",
      "epoch:  3  -  cost:  14.162503  - MSE:  407.3555109734116 - Train Accuracy:  0.46060607\n",
      "epoch:  4  -  cost:  13.501955  - MSE:  393.0915949623202 - Train Accuracy:  0.46060607\n",
      "epoch:  5  -  cost:  12.844675  - MSE:  379.60992740023886 - Train Accuracy:  0.46060607\n",
      "epoch:  6  -  cost:  12.197175  - MSE:  367.0099638272605 - Train Accuracy:  0.46060607\n",
      "epoch:  7  -  cost:  11.557765  - MSE:  355.253709796403 - Train Accuracy:  0.46060607\n",
      "epoch:  8  -  cost:  10.922334  - MSE:  344.3093143583553 - Train Accuracy:  0.46060607\n",
      "epoch:  9  -  cost:  10.29258  - MSE:  334.1912765310632 - Train Accuracy:  0.46060607\n",
      "epoch:  10  -  cost:  9.666496  - MSE:  324.8696773559395 - Train Accuracy:  0.46060607\n",
      "epoch:  11  -  cost:  9.045914  - MSE:  316.3192162969429 - Train Accuracy:  0.46060607\n",
      "epoch:  12  -  cost:  8.431382  - MSE:  308.4427952967952 - Train Accuracy:  0.46060607\n",
      "epoch:  13  -  cost:  7.8304377  - MSE:  301.3478494189762 - Train Accuracy:  0.46060607\n",
      "epoch:  14  -  cost:  7.2371078  - MSE:  294.9492567879297 - Train Accuracy:  0.46060607\n",
      "epoch:  15  -  cost:  6.648994  - MSE:  289.2292979929803 - Train Accuracy:  0.46060607\n",
      "epoch:  16  -  cost:  6.0681314  - MSE:  284.14665137220146 - Train Accuracy:  0.46060607\n",
      "epoch:  17  -  cost:  5.498628  - MSE:  279.6759730631058 - Train Accuracy:  0.46060607\n",
      "epoch:  18  -  cost:  4.942  - MSE:  275.8751658033173 - Train Accuracy:  0.46060607\n",
      "epoch:  19  -  cost:  4.403361  - MSE:  272.7532871521421 - Train Accuracy:  0.47272727\n",
      "epoch:  20  -  cost:  3.8948927  - MSE:  270.20159685205283 - Train Accuracy:  0.47878787\n",
      "epoch:  21  -  cost:  3.433275  - MSE:  268.2304409248687 - Train Accuracy:  0.4848485\n",
      "epoch:  22  -  cost:  3.0260372  - MSE:  266.8131246107926 - Train Accuracy:  0.4909091\n",
      "epoch:  23  -  cost:  2.6828682  - MSE:  265.8725264941932 - Train Accuracy:  0.46666667\n",
      "epoch:  24  -  cost:  2.4006493  - MSE:  265.2636901445214 - Train Accuracy:  0.4909091\n",
      "epoch:  25  -  cost:  2.174784  - MSE:  264.9214155109299 - Train Accuracy:  0.5151515\n",
      "epoch:  26  -  cost:  1.9994644  - MSE:  264.7317651493243 - Train Accuracy:  0.5151515\n",
      "epoch:  27  -  cost:  1.8666354  - MSE:  264.68342253024684 - Train Accuracy:  0.5151515\n",
      "epoch:  28  -  cost:  1.7682157  - MSE:  264.6405451268852 - Train Accuracy:  0.5090909\n",
      "epoch:  29  -  cost:  1.695735  - MSE:  264.5960392643351 - Train Accuracy:  0.5151515\n",
      "epoch:  30  -  cost:  1.642191  - MSE:  264.5316104699273 - Train Accuracy:  0.4969697\n",
      "epoch:  31  -  cost:  1.6019241  - MSE:  264.41500491747354 - Train Accuracy:  0.47878787\n",
      "epoch:  32  -  cost:  1.5702944  - MSE:  264.27972640700216 - Train Accuracy:  0.4969697\n",
      "epoch:  33  -  cost:  1.5449693  - MSE:  264.14695246554214 - Train Accuracy:  0.5090909\n",
      "epoch:  34  -  cost:  1.5244259  - MSE:  264.0124312241043 - Train Accuracy:  0.5151515\n",
      "epoch:  35  -  cost:  1.5069467  - MSE:  263.8762316168011 - Train Accuracy:  0.5151515\n",
      "epoch:  36  -  cost:  1.4921101  - MSE:  263.7608462459833 - Train Accuracy:  0.5272727\n",
      "epoch:  37  -  cost:  1.4790425  - MSE:  263.618418407744 - Train Accuracy:  0.5212121\n",
      "epoch:  38  -  cost:  1.4670902  - MSE:  263.45668211283873 - Train Accuracy:  0.5212121\n",
      "epoch:  39  -  cost:  1.4560318  - MSE:  263.28377961384587 - Train Accuracy:  0.5212121\n",
      "epoch:  40  -  cost:  1.4455318  - MSE:  263.09104740744027 - Train Accuracy:  0.5212121\n",
      "epoch:  41  -  cost:  1.4355322  - MSE:  262.89409722400603 - Train Accuracy:  0.5272727\n",
      "epoch:  42  -  cost:  1.4259237  - MSE:  262.68397004293627 - Train Accuracy:  0.5272727\n",
      "epoch:  43  -  cost:  1.4166027  - MSE:  262.47067066586004 - Train Accuracy:  0.5272727\n",
      "epoch:  44  -  cost:  1.4074742  - MSE:  262.25482580809694 - Train Accuracy:  0.5272727\n",
      "epoch:  45  -  cost:  1.3986546  - MSE:  262.0546577780392 - Train Accuracy:  0.5272727\n",
      "epoch:  46  -  cost:  1.3902634  - MSE:  261.91305964225904 - Train Accuracy:  0.5272727\n",
      "epoch:  47  -  cost:  1.3821511  - MSE:  261.78828417393714 - Train Accuracy:  0.53333336\n",
      "epoch:  48  -  cost:  1.3741516  - MSE:  261.6608770436239 - Train Accuracy:  0.53333336\n",
      "epoch:  49  -  cost:  1.3661827  - MSE:  261.52530764802935 - Train Accuracy:  0.53939396\n",
      "epoch:  50  -  cost:  1.3583628  - MSE:  261.3934444800393 - Train Accuracy:  0.53333336\n",
      "epoch:  51  -  cost:  1.3506452  - MSE:  261.26878290411946 - Train Accuracy:  0.53333336\n",
      "epoch:  52  -  cost:  1.3430024  - MSE:  261.15117357645585 - Train Accuracy:  0.53333336\n",
      "epoch:  53  -  cost:  1.3354352  - MSE:  261.03619736924986 - Train Accuracy:  0.53333336\n",
      "epoch:  54  -  cost:  1.3279351  - MSE:  260.8962859582573 - Train Accuracy:  0.53333336\n",
      "epoch:  55  -  cost:  1.3205806  - MSE:  260.758843970807 - Train Accuracy:  0.53333336\n",
      "epoch:  56  -  cost:  1.3131436  - MSE:  260.62210180027694 - Train Accuracy:  0.53333336\n",
      "epoch:  57  -  cost:  1.3057486  - MSE:  260.49101576024685 - Train Accuracy:  0.53333336\n",
      "epoch:  58  -  cost:  1.2984856  - MSE:  260.36409961738093 - Train Accuracy:  0.53333336\n",
      "epoch:  59  -  cost:  1.2913885  - MSE:  260.2418978926385 - Train Accuracy:  0.53333336\n",
      "epoch:  60  -  cost:  1.2844461  - MSE:  260.1209352187376 - Train Accuracy:  0.5272727\n",
      "epoch:  61  -  cost:  1.2776752  - MSE:  260.0098709598182 - Train Accuracy:  0.5272727\n",
      "epoch:  62  -  cost:  1.2710228  - MSE:  259.89847834609236 - Train Accuracy:  0.5272727\n",
      "epoch:  63  -  cost:  1.2645128  - MSE:  259.796622042296 - Train Accuracy:  0.5272727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  64  -  cost:  1.2580956  - MSE:  259.696982381662 - Train Accuracy:  0.5272727\n",
      "epoch:  65  -  cost:  1.2518438  - MSE:  259.61386550444956 - Train Accuracy:  0.53333336\n",
      "epoch:  66  -  cost:  1.2457892  - MSE:  259.5318241672356 - Train Accuracy:  0.53333336\n",
      "epoch:  67  -  cost:  1.2398467  - MSE:  259.4637099661319 - Train Accuracy:  0.53333336\n",
      "epoch:  68  -  cost:  1.2339712  - MSE:  259.3994566170376 - Train Accuracy:  0.53333336\n",
      "epoch:  69  -  cost:  1.2281679  - MSE:  259.3376033085118 - Train Accuracy:  0.53333336\n",
      "epoch:  70  -  cost:  1.222428  - MSE:  259.2750988398208 - Train Accuracy:  0.53939396\n",
      "epoch:  71  -  cost:  1.2167635  - MSE:  259.2135575756441 - Train Accuracy:  0.53939396\n",
      "epoch:  72  -  cost:  1.2110909  - MSE:  259.15650832406124 - Train Accuracy:  0.53939396\n",
      "epoch:  73  -  cost:  1.2052963  - MSE:  259.08750445434754 - Train Accuracy:  0.53939396\n",
      "epoch:  74  -  cost:  1.1996053  - MSE:  259.0280834517899 - Train Accuracy:  0.53939396\n",
      "epoch:  75  -  cost:  1.1940769  - MSE:  258.9518767655015 - Train Accuracy:  0.53939396\n",
      "epoch:  76  -  cost:  1.1886315  - MSE:  258.8826620157282 - Train Accuracy:  0.53939396\n",
      "epoch:  77  -  cost:  1.1832371  - MSE:  258.81715754904116 - Train Accuracy:  0.54545456\n",
      "epoch:  78  -  cost:  1.1779553  - MSE:  258.7659580577648 - Train Accuracy:  0.54545456\n",
      "epoch:  79  -  cost:  1.1727532  - MSE:  258.7075520522108 - Train Accuracy:  0.54545456\n",
      "epoch:  80  -  cost:  1.1675872  - MSE:  258.64986429119296 - Train Accuracy:  0.55151516\n",
      "epoch:  81  -  cost:  1.1624426  - MSE:  258.59873901437265 - Train Accuracy:  0.55151516\n",
      "epoch:  82  -  cost:  1.1573548  - MSE:  258.55302100428406 - Train Accuracy:  0.55757576\n",
      "epoch:  83  -  cost:  1.1522635  - MSE:  258.5051205441622 - Train Accuracy:  0.55757576\n",
      "epoch:  84  -  cost:  1.1472954  - MSE:  258.46227513849095 - Train Accuracy:  0.55757576\n",
      "epoch:  85  -  cost:  1.1424443  - MSE:  258.43351124291826 - Train Accuracy:  0.56363636\n",
      "epoch:  86  -  cost:  1.1377116  - MSE:  258.4044400383363 - Train Accuracy:  0.56363636\n",
      "epoch:  87  -  cost:  1.1330894  - MSE:  258.37839246869663 - Train Accuracy:  0.56363636\n",
      "epoch:  88  -  cost:  1.1284912  - MSE:  258.33904943653425 - Train Accuracy:  0.56363636\n",
      "epoch:  89  -  cost:  1.1239785  - MSE:  258.3070742179839 - Train Accuracy:  0.56363636\n",
      "epoch:  90  -  cost:  1.1194972  - MSE:  258.2924022625243 - Train Accuracy:  0.56363636\n",
      "epoch:  91  -  cost:  1.1150588  - MSE:  258.28045325623214 - Train Accuracy:  0.56363636\n",
      "epoch:  92  -  cost:  1.1106657  - MSE:  258.270177807583 - Train Accuracy:  0.56363636\n",
      "epoch:  93  -  cost:  1.1062968  - MSE:  258.2619372146318 - Train Accuracy:  0.56969696\n",
      "epoch:  94  -  cost:  1.101876  - MSE:  258.2552550984652 - Train Accuracy:  0.58181816\n",
      "epoch:  95  -  cost:  1.09755  - MSE:  258.2555665050325 - Train Accuracy:  0.58181816\n",
      "epoch:  96  -  cost:  1.093264  - MSE:  258.25738879298467 - Train Accuracy:  0.58181816\n",
      "epoch:  97  -  cost:  1.0890305  - MSE:  258.25994352090265 - Train Accuracy:  0.5939394\n",
      "epoch:  98  -  cost:  1.0848652  - MSE:  258.2664120851625 - Train Accuracy:  0.58787876\n",
      "epoch:  99  -  cost:  1.0807737  - MSE:  258.279215784285 - Train Accuracy:  0.5939394\n",
      "epoch:  100  -  cost:  1.0767214  - MSE:  258.29114647781716 - Train Accuracy:  0.5939394\n",
      "epoch:  101  -  cost:  1.0727212  - MSE:  258.3013177702642 - Train Accuracy:  0.6\n",
      "epoch:  102  -  cost:  1.0687819  - MSE:  258.3223634559497 - Train Accuracy:  0.6\n",
      "epoch:  103  -  cost:  1.0648844  - MSE:  258.3443358266275 - Train Accuracy:  0.6\n",
      "epoch:  104  -  cost:  1.0610427  - MSE:  258.3711584665251 - Train Accuracy:  0.6\n",
      "epoch:  105  -  cost:  1.0572362  - MSE:  258.3970843349521 - Train Accuracy:  0.5939394\n",
      "epoch:  106  -  cost:  1.0534496  - MSE:  258.4252404317985 - Train Accuracy:  0.5939394\n",
      "epoch:  107  -  cost:  1.0496688  - MSE:  258.45029904719746 - Train Accuracy:  0.5939394\n",
      "epoch:  108  -  cost:  1.045902  - MSE:  258.47092797916616 - Train Accuracy:  0.5939394\n",
      "epoch:  109  -  cost:  1.0421693  - MSE:  258.4917911524285 - Train Accuracy:  0.5939394\n",
      "epoch:  110  -  cost:  1.0384674  - MSE:  258.5111649693207 - Train Accuracy:  0.5939394\n",
      "epoch:  111  -  cost:  1.0348277  - MSE:  258.5323078905897 - Train Accuracy:  0.5939394\n",
      "epoch:  112  -  cost:  1.0312245  - MSE:  258.55186700244036 - Train Accuracy:  0.6\n",
      "epoch:  113  -  cost:  1.0276651  - MSE:  258.5801993223614 - Train Accuracy:  0.6\n",
      "epoch:  114  -  cost:  1.0241377  - MSE:  258.6063545887846 - Train Accuracy:  0.6060606\n",
      "epoch:  115  -  cost:  1.0205892  - MSE:  258.6357485397901 - Train Accuracy:  0.6060606\n",
      "epoch:  116  -  cost:  1.0169994  - MSE:  258.6556400831275 - Train Accuracy:  0.6060606\n",
      "epoch:  117  -  cost:  1.0134306  - MSE:  258.6686470177312 - Train Accuracy:  0.6060606\n",
      "epoch:  118  -  cost:  1.0098922  - MSE:  258.68309996332886 - Train Accuracy:  0.6060606\n",
      "epoch:  119  -  cost:  1.0064013  - MSE:  258.69859636552354 - Train Accuracy:  0.6060606\n",
      "epoch:  120  -  cost:  1.0029418  - MSE:  258.71285784438845 - Train Accuracy:  0.6060606\n",
      "epoch:  121  -  cost:  0.9995265  - MSE:  258.7298032370684 - Train Accuracy:  0.6060606\n",
      "epoch:  122  -  cost:  0.996132  - MSE:  258.74723863146704 - Train Accuracy:  0.6121212\n",
      "epoch:  123  -  cost:  0.9926942  - MSE:  258.7541107254875 - Train Accuracy:  0.6121212\n",
      "epoch:  124  -  cost:  0.98926234  - MSE:  258.75624418118764 - Train Accuracy:  0.6121212\n",
      "epoch:  125  -  cost:  0.98586595  - MSE:  258.75942138954713 - Train Accuracy:  0.6121212\n",
      "epoch:  126  -  cost:  0.9825109  - MSE:  258.763643124568 - Train Accuracy:  0.6121212\n",
      "epoch:  127  -  cost:  0.97921413  - MSE:  258.7643677120094 - Train Accuracy:  0.6121212\n",
      "epoch:  128  -  cost:  0.97594357  - MSE:  258.7911011189445 - Train Accuracy:  0.6121212\n",
      "epoch:  129  -  cost:  0.9727433  - MSE:  258.82345907067275 - Train Accuracy:  0.6121212\n",
      "epoch:  130  -  cost:  0.9695687  - MSE:  258.8568743457776 - Train Accuracy:  0.6181818\n",
      "epoch:  131  -  cost:  0.9664198  - MSE:  258.890041632506 - Train Accuracy:  0.6181818\n",
      "epoch:  132  -  cost:  0.9632954  - MSE:  258.91791384558917 - Train Accuracy:  0.6181818\n",
      "epoch:  133  -  cost:  0.96019095  - MSE:  258.94903838186315 - Train Accuracy:  0.6181818\n",
      "epoch:  134  -  cost:  0.9571012  - MSE:  258.9801812257883 - Train Accuracy:  0.6181818\n",
      "epoch:  135  -  cost:  0.95401776  - MSE:  259.01336966549724 - Train Accuracy:  0.6181818\n",
      "epoch:  136  -  cost:  0.9509589  - MSE:  259.04128236952323 - Train Accuracy:  0.6181818\n",
      "epoch:  137  -  cost:  0.94791794  - MSE:  259.0735701652654 - Train Accuracy:  0.6181818\n",
      "epoch:  138  -  cost:  0.944899  - MSE:  259.10730825458955 - Train Accuracy:  0.6242424\n",
      "epoch:  139  -  cost:  0.94190127  - MSE:  259.14127906052516 - Train Accuracy:  0.6242424\n",
      "epoch:  140  -  cost:  0.93893814  - MSE:  259.1754039026731 - Train Accuracy:  0.6242424\n",
      "epoch:  141  -  cost:  0.936015  - MSE:  259.2137492157864 - Train Accuracy:  0.6242424\n",
      "epoch:  142  -  cost:  0.9331036  - MSE:  259.2566017039946 - Train Accuracy:  0.6242424\n",
      "epoch:  143  -  cost:  0.9301622  - MSE:  259.28900408488596 - Train Accuracy:  0.6242424\n",
      "epoch:  144  -  cost:  0.9272669  - MSE:  259.3260793899799 - Train Accuracy:  0.6242424\n",
      "epoch:  145  -  cost:  0.9243627  - MSE:  259.35965202827583 - Train Accuracy:  0.6242424\n",
      "epoch:  146  -  cost:  0.9214794  - MSE:  259.3967929149875 - Train Accuracy:  0.6242424\n",
      "epoch:  147  -  cost:  0.9186457  - MSE:  259.4367736271513 - Train Accuracy:  0.6242424\n",
      "epoch:  148  -  cost:  0.9158288  - MSE:  259.4710169458157 - Train Accuracy:  0.6242424\n",
      "epoch:  149  -  cost:  0.9130287  - MSE:  259.5097468050036 - Train Accuracy:  0.6181818\n",
      "epoch:  150  -  cost:  0.91025573  - MSE:  259.54830939683035 - Train Accuracy:  0.6181818\n",
      "epoch:  151  -  cost:  0.9074975  - MSE:  259.5817449904735 - Train Accuracy:  0.6181818\n",
      "epoch:  152  -  cost:  0.90476185  - MSE:  259.6180036407642 - Train Accuracy:  0.6181818\n",
      "epoch:  153  -  cost:  0.9020529  - MSE:  259.6493887762749 - Train Accuracy:  0.6181818\n",
      "epoch:  154  -  cost:  0.8993532  - MSE:  259.6873742045346 - Train Accuracy:  0.6181818\n",
      "epoch:  155  -  cost:  0.8966663  - MSE:  259.72167864204346 - Train Accuracy:  0.6242424\n",
      "epoch:  156  -  cost:  0.8940044  - MSE:  259.7487065624789 - Train Accuracy:  0.6242424\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  157  -  cost:  0.8913546  - MSE:  259.77927843915785 - Train Accuracy:  0.6242424\n",
      "epoch:  158  -  cost:  0.88873094  - MSE:  259.8093349010446 - Train Accuracy:  0.6242424\n",
      "epoch:  159  -  cost:  0.88611424  - MSE:  259.83293139713516 - Train Accuracy:  0.6242424\n",
      "epoch:  160  -  cost:  0.8835169  - MSE:  259.86115699615794 - Train Accuracy:  0.6242424\n",
      "epoch:  161  -  cost:  0.8809377  - MSE:  259.883981773078 - Train Accuracy:  0.630303\n",
      "epoch:  162  -  cost:  0.8783675  - MSE:  259.9106984211258 - Train Accuracy:  0.630303\n",
      "epoch:  163  -  cost:  0.87582344  - MSE:  259.9381513239596 - Train Accuracy:  0.630303\n",
      "epoch:  164  -  cost:  0.87328464  - MSE:  259.9591120059744 - Train Accuracy:  0.630303\n",
      "epoch:  165  -  cost:  0.87076026  - MSE:  259.9873718683599 - Train Accuracy:  0.630303\n",
      "epoch:  166  -  cost:  0.86825275  - MSE:  260.00929309924663 - Train Accuracy:  0.630303\n",
      "epoch:  167  -  cost:  0.8657527  - MSE:  260.0364931870637 - Train Accuracy:  0.630303\n",
      "epoch:  168  -  cost:  0.8632611  - MSE:  260.0596803500225 - Train Accuracy:  0.630303\n",
      "epoch:  169  -  cost:  0.8607629  - MSE:  260.08724979887774 - Train Accuracy:  0.630303\n",
      "epoch:  170  -  cost:  0.8582857  - MSE:  260.11166700697095 - Train Accuracy:  0.630303\n",
      "epoch:  171  -  cost:  0.85581934  - MSE:  260.1292504515702 - Train Accuracy:  0.6363636\n",
      "epoch:  172  -  cost:  0.8532852  - MSE:  260.15044586859466 - Train Accuracy:  0.6424242\n",
      "epoch:  173  -  cost:  0.8506991  - MSE:  260.1459396324678 - Train Accuracy:  0.6424242\n",
      "epoch:  174  -  cost:  0.8481071  - MSE:  260.1451706190022 - Train Accuracy:  0.6424242\n",
      "epoch:  175  -  cost:  0.8455411  - MSE:  260.1414871773827 - Train Accuracy:  0.6424242\n",
      "epoch:  176  -  cost:  0.84300435  - MSE:  260.1246926164103 - Train Accuracy:  0.6424242\n",
      "epoch:  177  -  cost:  0.84048367  - MSE:  260.11306288043255 - Train Accuracy:  0.6424242\n",
      "epoch:  178  -  cost:  0.8379691  - MSE:  260.09631836935927 - Train Accuracy:  0.6424242\n",
      "epoch:  179  -  cost:  0.8354299  - MSE:  260.07811663497336 - Train Accuracy:  0.6424242\n",
      "epoch:  180  -  cost:  0.8329032  - MSE:  260.0508857723826 - Train Accuracy:  0.6484848\n",
      "epoch:  181  -  cost:  0.83038366  - MSE:  260.0306494873096 - Train Accuracy:  0.6484848\n",
      "epoch:  182  -  cost:  0.8278894  - MSE:  260.01750511272814 - Train Accuracy:  0.6484848\n",
      "epoch:  183  -  cost:  0.8254066  - MSE:  259.9982378086881 - Train Accuracy:  0.6545454\n",
      "epoch:  184  -  cost:  0.8229343  - MSE:  259.9844060587217 - Train Accuracy:  0.6545454\n",
      "epoch:  185  -  cost:  0.82048756  - MSE:  259.9634306291006 - Train Accuracy:  0.6545454\n",
      "epoch:  186  -  cost:  0.81803876  - MSE:  259.9466936640748 - Train Accuracy:  0.6545454\n",
      "epoch:  187  -  cost:  0.8156096  - MSE:  259.9307484299102 - Train Accuracy:  0.6606061\n",
      "epoch:  188  -  cost:  0.8132009  - MSE:  259.9096693130235 - Train Accuracy:  0.6606061\n",
      "epoch:  189  -  cost:  0.81080323  - MSE:  259.89667235238807 - Train Accuracy:  0.6606061\n",
      "epoch:  190  -  cost:  0.8084326  - MSE:  259.8840654847365 - Train Accuracy:  0.6666667\n",
      "epoch:  191  -  cost:  0.8060868  - MSE:  259.87751050249074 - Train Accuracy:  0.6666667\n",
      "epoch:  192  -  cost:  0.8037614  - MSE:  259.8791359006289 - Train Accuracy:  0.6727273\n",
      "epoch:  193  -  cost:  0.80146474  - MSE:  259.8844937809995 - Train Accuracy:  0.6727273\n",
      "epoch:  194  -  cost:  0.7991729  - MSE:  259.88270935489095 - Train Accuracy:  0.6727273\n",
      "epoch:  195  -  cost:  0.79689795  - MSE:  259.88789449968596 - Train Accuracy:  0.6727273\n",
      "epoch:  196  -  cost:  0.794642  - MSE:  259.88582540663924 - Train Accuracy:  0.6727273\n",
      "epoch:  197  -  cost:  0.7923926  - MSE:  259.8908715270451 - Train Accuracy:  0.6727273\n",
      "epoch:  198  -  cost:  0.7901468  - MSE:  259.8966200181051 - Train Accuracy:  0.6727273\n",
      "epoch:  199  -  cost:  0.78787804  - MSE:  259.8913720419613 - Train Accuracy:  0.6727273\n",
      "epoch:  200  -  cost:  0.78561807  - MSE:  259.8935167561159 - Train Accuracy:  0.6727273\n",
      "epoch:  201  -  cost:  0.7833818  - MSE:  259.8964249230025 - Train Accuracy:  0.6727273\n",
      "epoch:  202  -  cost:  0.7811429  - MSE:  259.89111577850997 - Train Accuracy:  0.6727273\n",
      "epoch:  203  -  cost:  0.7788827  - MSE:  259.88450837500943 - Train Accuracy:  0.6727273\n",
      "epoch:  204  -  cost:  0.7766304  - MSE:  259.86887491839997 - Train Accuracy:  0.6727273\n",
      "epoch:  205  -  cost:  0.774376  - MSE:  259.8579284727174 - Train Accuracy:  0.6727273\n",
      "epoch:  206  -  cost:  0.77216166  - MSE:  259.8371850969888 - Train Accuracy:  0.6727273\n",
      "epoch:  207  -  cost:  0.7699572  - MSE:  259.845576610412 - Train Accuracy:  0.6727273\n",
      "epoch:  208  -  cost:  0.7677791  - MSE:  259.85210830357454 - Train Accuracy:  0.6727273\n",
      "epoch:  209  -  cost:  0.7656088  - MSE:  259.85110749749504 - Train Accuracy:  0.6727273\n",
      "epoch:  210  -  cost:  0.7634437  - MSE:  259.8579000522056 - Train Accuracy:  0.6727273\n",
      "epoch:  211  -  cost:  0.76126194  - MSE:  259.85791045492635 - Train Accuracy:  0.6787879\n",
      "epoch:  212  -  cost:  0.7590823  - MSE:  259.8632258938929 - Train Accuracy:  0.6787879\n",
      "epoch:  213  -  cost:  0.75691545  - MSE:  259.8613854251788 - Train Accuracy:  0.6848485\n",
      "epoch:  214  -  cost:  0.7547438  - MSE:  259.8642926997926 - Train Accuracy:  0.6848485\n",
      "epoch:  215  -  cost:  0.752604  - MSE:  259.86067986385393 - Train Accuracy:  0.6848485\n",
      "epoch:  216  -  cost:  0.7504702  - MSE:  259.85179221083064 - Train Accuracy:  0.6848485\n",
      "epoch:  217  -  cost:  0.7483366  - MSE:  259.84503063093325 - Train Accuracy:  0.6848485\n",
      "epoch:  218  -  cost:  0.74623716  - MSE:  259.84602831857205 - Train Accuracy:  0.6848485\n",
      "epoch:  219  -  cost:  0.7441714  - MSE:  259.8359687508559 - Train Accuracy:  0.6848485\n",
      "epoch:  220  -  cost:  0.7421137  - MSE:  259.8340768097202 - Train Accuracy:  0.6848485\n",
      "epoch:  221  -  cost:  0.74006546  - MSE:  259.82363878644634 - Train Accuracy:  0.6848485\n",
      "epoch:  222  -  cost:  0.7380335  - MSE:  259.8216302718597 - Train Accuracy:  0.6909091\n",
      "epoch:  223  -  cost:  0.73601097  - MSE:  259.8104344389123 - Train Accuracy:  0.6909091\n",
      "epoch:  224  -  cost:  0.7340051  - MSE:  259.80745652022716 - Train Accuracy:  0.6909091\n",
      "epoch:  225  -  cost:  0.73199713  - MSE:  259.7959764270043 - Train Accuracy:  0.6909091\n",
      "epoch:  226  -  cost:  0.7300039  - MSE:  259.7900890047359 - Train Accuracy:  0.6909091\n",
      "epoch:  227  -  cost:  0.72801054  - MSE:  259.77609742171524 - Train Accuracy:  0.6909091\n",
      "epoch:  228  -  cost:  0.72604465  - MSE:  259.76287481948924 - Train Accuracy:  0.6909091\n",
      "epoch:  229  -  cost:  0.72409624  - MSE:  259.7549363750317 - Train Accuracy:  0.6909091\n",
      "epoch:  230  -  cost:  0.72207487  - MSE:  259.73187454244646 - Train Accuracy:  0.6909091\n",
      "epoch:  231  -  cost:  0.7200524  - MSE:  259.7194819685682 - Train Accuracy:  0.6909091\n",
      "epoch:  232  -  cost:  0.71805793  - MSE:  259.7080900178101 - Train Accuracy:  0.6909091\n",
      "epoch:  233  -  cost:  0.7160794  - MSE:  259.68909473744174 - Train Accuracy:  0.6909091\n",
      "epoch:  234  -  cost:  0.7141133  - MSE:  259.678678742579 - Train Accuracy:  0.6909091\n",
      "epoch:  235  -  cost:  0.7121673  - MSE:  259.66166698594355 - Train Accuracy:  0.6909091\n",
      "epoch:  236  -  cost:  0.7102223  - MSE:  259.6511077007678 - Train Accuracy:  0.6969697\n",
      "epoch:  237  -  cost:  0.70829374  - MSE:  259.6407308142457 - Train Accuracy:  0.6969697\n",
      "epoch:  238  -  cost:  0.70638514  - MSE:  259.62052349304423 - Train Accuracy:  0.6969697\n",
      "epoch:  239  -  cost:  0.7044819  - MSE:  259.6083182556532 - Train Accuracy:  0.6969697\n",
      "epoch:  240  -  cost:  0.7025889  - MSE:  259.5964040591445 - Train Accuracy:  0.6969697\n",
      "epoch:  241  -  cost:  0.70071363  - MSE:  259.5849205265892 - Train Accuracy:  0.6969697\n",
      "epoch:  242  -  cost:  0.6988425  - MSE:  259.5642489384718 - Train Accuracy:  0.6969697\n",
      "epoch:  243  -  cost:  0.6969794  - MSE:  259.5490451555592 - Train Accuracy:  0.6969697\n",
      "epoch:  244  -  cost:  0.6951238  - MSE:  259.5340483426195 - Train Accuracy:  0.6969697\n",
      "epoch:  245  -  cost:  0.6932734  - MSE:  259.51226991508656 - Train Accuracy:  0.6969697\n",
      "epoch:  246  -  cost:  0.6914278  - MSE:  259.4993026040234 - Train Accuracy:  0.6969697\n",
      "epoch:  247  -  cost:  0.68958354  - MSE:  259.48272420426935 - Train Accuracy:  0.6969697\n",
      "epoch:  248  -  cost:  0.6877638  - MSE:  259.46605907554436 - Train Accuracy:  0.6969697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  249  -  cost:  0.68596655  - MSE:  259.4253940647413 - Train Accuracy:  0.6969697\n",
      "epoch:  250  -  cost:  0.6841785  - MSE:  259.3854099139907 - Train Accuracy:  0.6969697\n",
      "epoch:  251  -  cost:  0.6824044  - MSE:  259.3466914951546 - Train Accuracy:  0.6969697\n",
      "epoch:  252  -  cost:  0.68062663  - MSE:  259.300791103528 - Train Accuracy:  0.6969697\n",
      "epoch:  253  -  cost:  0.6788286  - MSE:  259.2545323922729 - Train Accuracy:  0.6969697\n",
      "epoch:  254  -  cost:  0.67704  - MSE:  259.20880997768217 - Train Accuracy:  0.6969697\n",
      "epoch:  255  -  cost:  0.67526  - MSE:  259.16347493440145 - Train Accuracy:  0.7030303\n",
      "epoch:  256  -  cost:  0.6734923  - MSE:  259.11854387779204 - Train Accuracy:  0.7030303\n",
      "epoch:  257  -  cost:  0.67173845  - MSE:  259.07163013767723 - Train Accuracy:  0.7030303\n",
      "epoch:  258  -  cost:  0.6699909  - MSE:  259.02587543115175 - Train Accuracy:  0.7030303\n",
      "epoch:  259  -  cost:  0.668254  - MSE:  258.98007873646105 - Train Accuracy:  0.7030303\n",
      "epoch:  260  -  cost:  0.666532  - MSE:  258.92329578079745 - Train Accuracy:  0.7030303\n",
      "epoch:  261  -  cost:  0.6648265  - MSE:  258.8788177286627 - Train Accuracy:  0.7030303\n",
      "epoch:  262  -  cost:  0.66312987  - MSE:  258.8339853720915 - Train Accuracy:  0.7030303\n",
      "epoch:  263  -  cost:  0.6614418  - MSE:  258.7892078716801 - Train Accuracy:  0.7030303\n",
      "epoch:  264  -  cost:  0.6597621  - MSE:  258.7446056399041 - Train Accuracy:  0.7030303\n",
      "epoch:  265  -  cost:  0.6580931  - MSE:  258.70318277732537 - Train Accuracy:  0.7090909\n",
      "epoch:  266  -  cost:  0.6564326  - MSE:  258.6616719145809 - Train Accuracy:  0.7151515\n",
      "epoch:  267  -  cost:  0.6547925  - MSE:  258.62206439025664 - Train Accuracy:  0.7151515\n",
      "epoch:  268  -  cost:  0.65316385  - MSE:  258.5740651648429 - Train Accuracy:  0.7151515\n",
      "epoch:  269  -  cost:  0.65154433  - MSE:  258.52616678603744 - Train Accuracy:  0.7151515\n",
      "epoch:  270  -  cost:  0.6499339  - MSE:  258.46733348183113 - Train Accuracy:  0.7151515\n",
      "epoch:  271  -  cost:  0.6483283  - MSE:  258.418566104571 - Train Accuracy:  0.7151515\n",
      "epoch:  272  -  cost:  0.64671457  - MSE:  258.369972813869 - Train Accuracy:  0.7151515\n",
      "epoch:  273  -  cost:  0.64507073  - MSE:  258.30717950658385 - Train Accuracy:  0.7151515\n",
      "epoch:  274  -  cost:  0.6434329  - MSE:  258.2451385621118 - Train Accuracy:  0.7090909\n",
      "epoch:  275  -  cost:  0.6417987  - MSE:  258.18233974634813 - Train Accuracy:  0.7090909\n",
      "epoch:  276  -  cost:  0.6401623  - MSE:  258.1201113242945 - Train Accuracy:  0.7090909\n",
      "epoch:  277  -  cost:  0.6385167  - MSE:  258.047623232412 - Train Accuracy:  0.7090909\n",
      "epoch:  278  -  cost:  0.6368518  - MSE:  257.98607011436377 - Train Accuracy:  0.7090909\n",
      "epoch:  279  -  cost:  0.63519853  - MSE:  257.9250310873059 - Train Accuracy:  0.7090909\n",
      "epoch:  280  -  cost:  0.6335565  - MSE:  257.86792226978787 - Train Accuracy:  0.7090909\n",
      "epoch:  281  -  cost:  0.63192546  - MSE:  257.810576824462 - Train Accuracy:  0.7090909\n",
      "epoch:  282  -  cost:  0.6303027  - MSE:  257.7536246578451 - Train Accuracy:  0.7090909\n",
      "epoch:  283  -  cost:  0.62869406  - MSE:  257.6968932235347 - Train Accuracy:  0.7090909\n",
      "epoch:  284  -  cost:  0.6271063  - MSE:  257.6438641306219 - Train Accuracy:  0.7090909\n",
      "epoch:  285  -  cost:  0.6255266  - MSE:  257.5910008193998 - Train Accuracy:  0.7090909\n",
      "epoch:  286  -  cost:  0.62395674  - MSE:  257.5424944129096 - Train Accuracy:  0.7151515\n",
      "epoch:  287  -  cost:  0.62239784  - MSE:  257.49578134674783 - Train Accuracy:  0.7151515\n",
      "epoch:  288  -  cost:  0.62084866  - MSE:  257.4490083092752 - Train Accuracy:  0.7151515\n",
      "epoch:  289  -  cost:  0.6193078  - MSE:  257.399316590973 - Train Accuracy:  0.7151515\n",
      "epoch:  290  -  cost:  0.61777484  - MSE:  257.3527019719895 - Train Accuracy:  0.72727275\n",
      "epoch:  291  -  cost:  0.6162507  - MSE:  257.30632507211004 - Train Accuracy:  0.72727275\n",
      "epoch:  292  -  cost:  0.614735  - MSE:  257.26024137303733 - Train Accuracy:  0.72727275\n",
      "epoch:  293  -  cost:  0.61322594  - MSE:  257.2133467985744 - Train Accuracy:  0.72727275\n",
      "epoch:  294  -  cost:  0.61172515  - MSE:  257.16676779225236 - Train Accuracy:  0.72727275\n",
      "epoch:  295  -  cost:  0.6102337  - MSE:  257.11729900597027 - Train Accuracy:  0.72727275\n",
      "epoch:  296  -  cost:  0.60876286  - MSE:  257.0708035518904 - Train Accuracy:  0.72727275\n",
      "epoch:  297  -  cost:  0.60731614  - MSE:  257.02976548675196 - Train Accuracy:  0.72727275\n",
      "epoch:  298  -  cost:  0.60587764  - MSE:  256.98861958532336 - Train Accuracy:  0.72727275\n",
      "epoch:  299  -  cost:  0.6044466  - MSE:  256.94436395769037 - Train Accuracy:  0.72727275\n",
      "epoch:  300  -  cost:  0.6030271  - MSE:  256.90330865128755 - Train Accuracy:  0.72727275\n",
      "epoch:  301  -  cost:  0.60161984  - MSE:  256.86569181674594 - Train Accuracy:  0.72121215\n",
      "epoch:  302  -  cost:  0.60021985  - MSE:  256.82536441706236 - Train Accuracy:  0.72121215\n",
      "epoch:  303  -  cost:  0.5988271  - MSE:  256.7881061684553 - Train Accuracy:  0.72121215\n",
      "epoch:  304  -  cost:  0.5974443  - MSE:  256.75034852471725 - Train Accuracy:  0.72121215\n",
      "epoch:  305  -  cost:  0.59606874  - MSE:  256.71259269013535 - Train Accuracy:  0.72121215\n",
      "epoch:  306  -  cost:  0.59469837  - MSE:  256.6748079353626 - Train Accuracy:  0.72121215\n",
      "epoch:  307  -  cost:  0.59332323  - MSE:  256.6325154008838 - Train Accuracy:  0.72121215\n",
      "epoch:  308  -  cost:  0.5919569  - MSE:  256.5947633685125 - Train Accuracy:  0.72121215\n",
      "epoch:  309  -  cost:  0.59059316  - MSE:  256.5517429670538 - Train Accuracy:  0.72121215\n",
      "epoch:  310  -  cost:  0.58923644  - MSE:  256.51186675353836 - Train Accuracy:  0.72121215\n",
      "epoch:  311  -  cost:  0.5878898  - MSE:  256.4691268687049 - Train Accuracy:  0.72121215\n",
      "epoch:  312  -  cost:  0.5865555  - MSE:  256.429284194744 - Train Accuracy:  0.72121215\n",
      "epoch:  313  -  cost:  0.58522826  - MSE:  256.38659317773846 - Train Accuracy:  0.72121215\n",
      "epoch:  314  -  cost:  0.5839156  - MSE:  256.34705126925337 - Train Accuracy:  0.7151515\n",
      "epoch:  315  -  cost:  0.5826253  - MSE:  256.295743575321 - Train Accuracy:  0.7151515\n",
      "epoch:  316  -  cost:  0.58137584  - MSE:  256.252149078164 - Train Accuracy:  0.7151515\n",
      "epoch:  317  -  cost:  0.5801349  - MSE:  256.2085937869814 - Train Accuracy:  0.7151515\n",
      "epoch:  318  -  cost:  0.57889915  - MSE:  256.1682404579332 - Train Accuracy:  0.7151515\n",
      "epoch:  319  -  cost:  0.57766706  - MSE:  256.1271894953416 - Train Accuracy:  0.7151515\n",
      "epoch:  320  -  cost:  0.57644206  - MSE:  256.0893414433578 - Train Accuracy:  0.7151515\n",
      "epoch:  321  -  cost:  0.57522386  - MSE:  256.0487730925438 - Train Accuracy:  0.7151515\n",
      "epoch:  322  -  cost:  0.5740124  - MSE:  256.0113407339366 - Train Accuracy:  0.7151515\n",
      "epoch:  323  -  cost:  0.57281  - MSE:  255.97558559785506 - Train Accuracy:  0.7151515\n",
      "epoch:  324  -  cost:  0.571615  - MSE:  255.94045705438245 - Train Accuracy:  0.7151515\n",
      "epoch:  325  -  cost:  0.5704281  - MSE:  255.90969522268756 - Train Accuracy:  0.7151515\n",
      "epoch:  326  -  cost:  0.569254  - MSE:  255.87729267767267 - Train Accuracy:  0.7151515\n",
      "epoch:  327  -  cost:  0.56808025  - MSE:  255.8464387732037 - Train Accuracy:  0.7151515\n",
      "epoch:  328  -  cost:  0.5669022  - MSE:  255.8106477694006 - Train Accuracy:  0.7151515\n",
      "epoch:  329  -  cost:  0.5657301  - MSE:  255.77917371136127 - Train Accuracy:  0.7151515\n",
      "epoch:  330  -  cost:  0.564565  - MSE:  255.74618113668726 - Train Accuracy:  0.7151515\n",
      "epoch:  331  -  cost:  0.5634081  - MSE:  255.71483143488098 - Train Accuracy:  0.7151515\n",
      "epoch:  332  -  cost:  0.56225455  - MSE:  255.67994994628896 - Train Accuracy:  0.7151515\n",
      "epoch:  333  -  cost:  0.5610441  - MSE:  255.6230262661515 - Train Accuracy:  0.7151515\n",
      "epoch:  334  -  cost:  0.5598219  - MSE:  255.5649350108066 - Train Accuracy:  0.7151515\n",
      "epoch:  335  -  cost:  0.5585679  - MSE:  255.50281402169244 - Train Accuracy:  0.7151515\n",
      "epoch:  336  -  cost:  0.55729234  - MSE:  255.42763419127897 - Train Accuracy:  0.72121215\n",
      "epoch:  337  -  cost:  0.55602163  - MSE:  255.35714389220496 - Train Accuracy:  0.72121215\n",
      "epoch:  338  -  cost:  0.5547477  - MSE:  255.28568757006747 - Train Accuracy:  0.72121215\n",
      "epoch:  339  -  cost:  0.55348253  - MSE:  255.21496702113714 - Train Accuracy:  0.72121215\n",
      "epoch:  340  -  cost:  0.55222535  - MSE:  255.1453964685713 - Train Accuracy:  0.72121215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  341  -  cost:  0.5509776  - MSE:  255.0714493680211 - Train Accuracy:  0.72121215\n",
      "epoch:  342  -  cost:  0.5497687  - MSE:  254.99858325491988 - Train Accuracy:  0.72121215\n",
      "epoch:  343  -  cost:  0.54861593  - MSE:  254.9415269963502 - Train Accuracy:  0.72121215\n",
      "epoch:  344  -  cost:  0.54747576  - MSE:  254.8846471131115 - Train Accuracy:  0.72727275\n",
      "epoch:  345  -  cost:  0.5463518  - MSE:  254.83377432700587 - Train Accuracy:  0.72121215\n",
      "epoch:  346  -  cost:  0.5452275  - MSE:  254.79018350729234 - Train Accuracy:  0.72121215\n",
      "epoch:  347  -  cost:  0.54410917  - MSE:  254.74480693461828 - Train Accuracy:  0.72121215\n",
      "epoch:  348  -  cost:  0.54299605  - MSE:  254.70127859093503 - Train Accuracy:  0.72121215\n",
      "epoch:  349  -  cost:  0.541889  - MSE:  254.65676083879447 - Train Accuracy:  0.72121215\n",
      "epoch:  350  -  cost:  0.5407885  - MSE:  254.61084635909862 - Train Accuracy:  0.72121215\n",
      "epoch:  351  -  cost:  0.539694  - MSE:  254.56674485443503 - Train Accuracy:  0.72727275\n",
      "epoch:  352  -  cost:  0.5385966  - MSE:  254.5204697143344 - Train Accuracy:  0.72727275\n",
      "epoch:  353  -  cost:  0.5374771  - MSE:  254.45848299708055 - Train Accuracy:  0.72727275\n",
      "epoch:  354  -  cost:  0.5363488  - MSE:  254.38330231010391 - Train Accuracy:  0.72727275\n",
      "epoch:  355  -  cost:  0.5352198  - MSE:  254.30944996299726 - Train Accuracy:  0.72727275\n",
      "epoch:  356  -  cost:  0.53407484  - MSE:  254.23280210662142 - Train Accuracy:  0.72727275\n",
      "epoch:  357  -  cost:  0.5329335  - MSE:  254.1568364098062 - Train Accuracy:  0.72727275\n",
      "epoch:  358  -  cost:  0.5317996  - MSE:  254.08182841619336 - Train Accuracy:  0.72727275\n",
      "epoch:  359  -  cost:  0.5306734  - MSE:  254.00724882436623 - Train Accuracy:  0.73333335\n",
      "epoch:  360  -  cost:  0.5295528  - MSE:  253.93342229727128 - Train Accuracy:  0.73333335\n",
      "epoch:  361  -  cost:  0.5284388  - MSE:  253.86047337061163 - Train Accuracy:  0.73333335\n",
      "epoch:  362  -  cost:  0.5273316  - MSE:  253.78817926880046 - Train Accuracy:  0.73333335\n",
      "epoch:  363  -  cost:  0.52623117  - MSE:  253.7169223550291 - Train Accuracy:  0.73333335\n",
      "epoch:  364  -  cost:  0.525142  - MSE:  253.64690641068458 - Train Accuracy:  0.73939395\n",
      "epoch:  365  -  cost:  0.52406806  - MSE:  253.5796406969209 - Train Accuracy:  0.73939395\n",
      "epoch:  366  -  cost:  0.52299654  - MSE:  253.51320944258458 - Train Accuracy:  0.73939395\n",
      "epoch:  367  -  cost:  0.5219303  - MSE:  253.44723448036797 - Train Accuracy:  0.73939395\n",
      "epoch:  368  -  cost:  0.5208698  - MSE:  253.38175964312964 - Train Accuracy:  0.73939395\n",
      "epoch:  369  -  cost:  0.51981604  - MSE:  253.31676216269278 - Train Accuracy:  0.73939395\n",
      "epoch:  370  -  cost:  0.5187671  - MSE:  253.25212321739656 - Train Accuracy:  0.73939395\n",
      "epoch:  371  -  cost:  0.51772463  - MSE:  253.187906239056 - Train Accuracy:  0.73939395\n",
      "epoch:  372  -  cost:  0.5166879  - MSE:  253.12426341474136 - Train Accuracy:  0.73939395\n",
      "epoch:  373  -  cost:  0.5156583  - MSE:  253.06093146237765 - Train Accuracy:  0.73939395\n",
      "epoch:  374  -  cost:  0.51463497  - MSE:  252.9980702247738 - Train Accuracy:  0.73939395\n",
      "epoch:  375  -  cost:  0.51361674  - MSE:  252.93564687514086 - Train Accuracy:  0.73939395\n",
      "epoch:  376  -  cost:  0.51260597  - MSE:  252.87393281012123 - Train Accuracy:  0.73939395\n",
      "epoch:  377  -  cost:  0.5116331  - MSE:  252.81646868520124 - Train Accuracy:  0.73939395\n",
      "epoch:  378  -  cost:  0.51068455  - MSE:  252.76148126516048 - Train Accuracy:  0.73939395\n",
      "epoch:  379  -  cost:  0.50974584  - MSE:  252.70634218225405 - Train Accuracy:  0.73939395\n",
      "epoch:  380  -  cost:  0.5088084  - MSE:  252.6513491551063 - Train Accuracy:  0.73939395\n",
      "epoch:  381  -  cost:  0.5078507  - MSE:  252.59625687455866 - Train Accuracy:  0.73939395\n",
      "epoch:  382  -  cost:  0.5068986  - MSE:  252.54183472117768 - Train Accuracy:  0.73939395\n",
      "epoch:  383  -  cost:  0.5059532  - MSE:  252.48886555912742 - Train Accuracy:  0.73939395\n",
      "epoch:  384  -  cost:  0.5050179  - MSE:  252.436597073463 - Train Accuracy:  0.73939395\n",
      "epoch:  385  -  cost:  0.50410384  - MSE:  252.38398285034202 - Train Accuracy:  0.73939395\n",
      "epoch:  386  -  cost:  0.50318897  - MSE:  252.3311022052721 - Train Accuracy:  0.73939395\n",
      "epoch:  387  -  cost:  0.50227755  - MSE:  252.27817856920262 - Train Accuracy:  0.73939395\n",
      "epoch:  388  -  cost:  0.50137144  - MSE:  252.22473745090207 - Train Accuracy:  0.73939395\n",
      "epoch:  389  -  cost:  0.50045377  - MSE:  252.17149751376795 - Train Accuracy:  0.74545455\n",
      "epoch:  390  -  cost:  0.49950886  - MSE:  252.10738251557373 - Train Accuracy:  0.75151515\n",
      "epoch:  391  -  cost:  0.49857104  - MSE:  252.0443377555482 - Train Accuracy:  0.75151515\n",
      "epoch:  392  -  cost:  0.49764392  - MSE:  251.97828184366432 - Train Accuracy:  0.75151515\n",
      "epoch:  393  -  cost:  0.49671835  - MSE:  251.91214242452514 - Train Accuracy:  0.75151515\n",
      "epoch:  394  -  cost:  0.49579024  - MSE:  251.8448710737172 - Train Accuracy:  0.75151515\n",
      "epoch:  395  -  cost:  0.49486774  - MSE:  251.7777321184132 - Train Accuracy:  0.75151515\n",
      "epoch:  396  -  cost:  0.49395382  - MSE:  251.71262047143668 - Train Accuracy:  0.75151515\n",
      "epoch:  397  -  cost:  0.4930446  - MSE:  251.64786147718934 - Train Accuracy:  0.75151515\n",
      "epoch:  398  -  cost:  0.49214095  - MSE:  251.58342413698327 - Train Accuracy:  0.75757575\n",
      "epoch:  399  -  cost:  0.49124548  - MSE:  251.5194734197005 - Train Accuracy:  0.75757575\n",
      "epoch:  400  -  cost:  0.49036685  - MSE:  251.45639617177784 - Train Accuracy:  0.75757575\n",
      "epoch:  401  -  cost:  0.48949683  - MSE:  251.39384008045627 - Train Accuracy:  0.75757575\n",
      "epoch:  402  -  cost:  0.48863122  - MSE:  251.33177050391896 - Train Accuracy:  0.76363635\n",
      "epoch:  403  -  cost:  0.4877698  - MSE:  251.27008527795334 - Train Accuracy:  0.76363635\n",
      "epoch:  404  -  cost:  0.48691347  - MSE:  251.20866411426263 - Train Accuracy:  0.76363635\n",
      "epoch:  405  -  cost:  0.48606136  - MSE:  251.14766875898897 - Train Accuracy:  0.76363635\n",
      "epoch:  406  -  cost:  0.48521656  - MSE:  251.08972321352277 - Train Accuracy:  0.76363635\n",
      "epoch:  407  -  cost:  0.48437837  - MSE:  251.03145142767585 - Train Accuracy:  0.76969695\n",
      "epoch:  408  -  cost:  0.48355067  - MSE:  250.97730219978084 - Train Accuracy:  0.76969695\n",
      "epoch:  409  -  cost:  0.48273233  - MSE:  250.92275497397773 - Train Accuracy:  0.76969695\n",
      "epoch:  410  -  cost:  0.48192757  - MSE:  250.86906414277524 - Train Accuracy:  0.76969695\n",
      "epoch:  411  -  cost:  0.48113143  - MSE:  250.81521722911384 - Train Accuracy:  0.76969695\n",
      "epoch:  412  -  cost:  0.48033804  - MSE:  250.7615062368703 - Train Accuracy:  0.76969695\n",
      "epoch:  413  -  cost:  0.4795485  - MSE:  250.7075195789293 - Train Accuracy:  0.76969695\n",
      "epoch:  414  -  cost:  0.4787624  - MSE:  250.65371116479682 - Train Accuracy:  0.76969695\n",
      "epoch:  415  -  cost:  0.4779803  - MSE:  250.59973659565324 - Train Accuracy:  0.76969695\n",
      "epoch:  416  -  cost:  0.47720245  - MSE:  250.54602989350786 - Train Accuracy:  0.76969695\n",
      "epoch:  417  -  cost:  0.476428  - MSE:  250.49262326317827 - Train Accuracy:  0.76969695\n",
      "epoch:  418  -  cost:  0.47565743  - MSE:  250.43891542311272 - Train Accuracy:  0.76969695\n",
      "epoch:  419  -  cost:  0.4748909  - MSE:  250.3855455801707 - Train Accuracy:  0.76969695\n",
      "epoch:  420  -  cost:  0.47413123  - MSE:  250.332082024431 - Train Accuracy:  0.76969695\n",
      "epoch:  421  -  cost:  0.4733817  - MSE:  250.28445120596024 - Train Accuracy:  0.76969695\n",
      "epoch:  422  -  cost:  0.4726394  - MSE:  250.23777373421962 - Train Accuracy:  0.76969695\n",
      "epoch:  423  -  cost:  0.47190067  - MSE:  250.19138441138034 - Train Accuracy:  0.76969695\n",
      "epoch:  424  -  cost:  0.4711651  - MSE:  250.14524349091457 - Train Accuracy:  0.77575755\n",
      "epoch:  425  -  cost:  0.47043306  - MSE:  250.09932058608362 - Train Accuracy:  0.77575755\n",
      "epoch:  426  -  cost:  0.4697041  - MSE:  250.05371040182075 - Train Accuracy:  0.77575755\n",
      "epoch:  427  -  cost:  0.46897668  - MSE:  250.00829884010278 - Train Accuracy:  0.77575755\n",
      "epoch:  428  -  cost:  0.46824887  - MSE:  249.96159313512015 - Train Accuracy:  0.77575755\n",
      "epoch:  429  -  cost:  0.46752393  - MSE:  249.91516329198038 - Train Accuracy:  0.77575755\n",
      "epoch:  430  -  cost:  0.4668021  - MSE:  249.8690291632935 - Train Accuracy:  0.77575755\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  431  -  cost:  0.46608365  - MSE:  249.82309096192097 - Train Accuracy:  0.77575755\n",
      "epoch:  432  -  cost:  0.46536893  - MSE:  249.7767402468125 - Train Accuracy:  0.77575755\n",
      "epoch:  433  -  cost:  0.46465468  - MSE:  249.73050357734346 - Train Accuracy:  0.77575755\n",
      "epoch:  434  -  cost:  0.46393493  - MSE:  249.68281129714077 - Train Accuracy:  0.77575755\n",
      "epoch:  435  -  cost:  0.46321818  - MSE:  249.6354031782211 - Train Accuracy:  0.77575755\n",
      "epoch:  436  -  cost:  0.46250528  - MSE:  249.5882230812042 - Train Accuracy:  0.77575755\n",
      "epoch:  437  -  cost:  0.46181396  - MSE:  249.5471098356705 - Train Accuracy:  0.77575755\n",
      "epoch:  438  -  cost:  0.46112663  - MSE:  249.50608412698088 - Train Accuracy:  0.77575755\n",
      "epoch:  439  -  cost:  0.46044216  - MSE:  249.46510643098168 - Train Accuracy:  0.77575755\n",
      "epoch:  440  -  cost:  0.45976046  - MSE:  249.42441066378427 - Train Accuracy:  0.77575755\n",
      "epoch:  441  -  cost:  0.45908186  - MSE:  249.38498773865544 - Train Accuracy:  0.7818182\n",
      "epoch:  442  -  cost:  0.4584064  - MSE:  249.34581542018498 - Train Accuracy:  0.7818182\n",
      "epoch:  443  -  cost:  0.45773366  - MSE:  249.30689960918227 - Train Accuracy:  0.7818182\n",
      "epoch:  444  -  cost:  0.45706606  - MSE:  249.26828258865018 - Train Accuracy:  0.7878788\n",
      "epoch:  445  -  cost:  0.45640054  - MSE:  249.2298614404036 - Train Accuracy:  0.7878788\n",
      "epoch:  446  -  cost:  0.45573777  - MSE:  249.1915287336328 - Train Accuracy:  0.7878788\n",
      "epoch:  447  -  cost:  0.45507765  - MSE:  249.1533777511628 - Train Accuracy:  0.7878788\n",
      "epoch:  448  -  cost:  0.45442015  - MSE:  249.115456407582 - Train Accuracy:  0.7878788\n",
      "epoch:  449  -  cost:  0.4537672  - MSE:  249.07563352827506 - Train Accuracy:  0.7878788\n",
      "epoch:  450  -  cost:  0.45311853  - MSE:  249.03612716192487 - Train Accuracy:  0.7878788\n",
      "epoch:  451  -  cost:  0.45247108  - MSE:  249.00094305579097 - Train Accuracy:  0.7939394\n",
      "epoch:  452  -  cost:  0.45182472  - MSE:  248.9643604664128 - Train Accuracy:  0.7939394\n",
      "epoch:  453  -  cost:  0.4511806  - MSE:  248.9276905568655 - Train Accuracy:  0.7939394\n",
      "epoch:  454  -  cost:  0.4505389  - MSE:  248.8909598282876 - Train Accuracy:  0.7939394\n",
      "epoch:  455  -  cost:  0.4499002  - MSE:  248.8542768776178 - Train Accuracy:  0.7939394\n",
      "epoch:  456  -  cost:  0.44926536  - MSE:  248.81485393212182 - Train Accuracy:  0.7939394\n",
      "epoch:  457  -  cost:  0.4486337  - MSE:  248.77576612753325 - Train Accuracy:  0.7939394\n",
      "epoch:  458  -  cost:  0.44800425  - MSE:  248.73692673406998 - Train Accuracy:  0.8\n",
      "epoch:  459  -  cost:  0.44737723  - MSE:  248.6982221287006 - Train Accuracy:  0.8\n",
      "epoch:  460  -  cost:  0.44675234  - MSE:  248.65981581624925 - Train Accuracy:  0.8\n",
      "epoch:  461  -  cost:  0.44613025  - MSE:  248.62144546279407 - Train Accuracy:  0.8\n",
      "epoch:  462  -  cost:  0.44550994  - MSE:  248.58300366145053 - Train Accuracy:  0.8\n",
      "epoch:  463  -  cost:  0.4448916  - MSE:  248.54531124097554 - Train Accuracy:  0.8\n",
      "epoch:  464  -  cost:  0.44427574  - MSE:  248.50777924689638 - Train Accuracy:  0.8\n",
      "epoch:  465  -  cost:  0.44366163  - MSE:  248.4703420934211 - Train Accuracy:  0.8\n",
      "epoch:  466  -  cost:  0.44305012  - MSE:  248.4330516204676 - Train Accuracy:  0.8\n",
      "epoch:  467  -  cost:  0.44244117  - MSE:  248.39593876222074 - Train Accuracy:  0.8\n",
      "epoch:  468  -  cost:  0.44183406  - MSE:  248.3588581802401 - Train Accuracy:  0.8\n",
      "epoch:  469  -  cost:  0.4412297  - MSE:  248.3218217710572 - Train Accuracy:  0.8\n",
      "epoch:  470  -  cost:  0.44062722  - MSE:  248.28498254702748 - Train Accuracy:  0.8\n",
      "epoch:  471  -  cost:  0.4400266  - MSE:  248.24824430399366 - Train Accuracy:  0.8\n",
      "epoch:  472  -  cost:  0.4394294  - MSE:  248.21171600701365 - Train Accuracy:  0.8\n",
      "epoch:  473  -  cost:  0.4388334  - MSE:  248.1752687469495 - Train Accuracy:  0.8\n",
      "epoch:  474  -  cost:  0.43823835  - MSE:  248.1389797208906 - Train Accuracy:  0.8\n",
      "epoch:  475  -  cost:  0.4376587  - MSE:  248.10292971871124 - Train Accuracy:  0.8\n",
      "epoch:  476  -  cost:  0.43709344  - MSE:  248.07141160504952 - Train Accuracy:  0.8\n",
      "epoch:  477  -  cost:  0.43653  - MSE:  248.04074297752135 - Train Accuracy:  0.8\n",
      "epoch:  478  -  cost:  0.43596867  - MSE:  248.01020899180963 - Train Accuracy:  0.8\n",
      "epoch:  479  -  cost:  0.43540928  - MSE:  247.97980914803114 - Train Accuracy:  0.8\n",
      "epoch:  480  -  cost:  0.43485057  - MSE:  247.94967660915327 - Train Accuracy:  0.8\n",
      "epoch:  481  -  cost:  0.43429127  - MSE:  247.9166638007574 - Train Accuracy:  0.8\n",
      "epoch:  482  -  cost:  0.4337346  - MSE:  247.8814091205699 - Train Accuracy:  0.8\n",
      "epoch:  483  -  cost:  0.43318033  - MSE:  247.8461970693102 - Train Accuracy:  0.8\n",
      "epoch:  484  -  cost:  0.43262723  - MSE:  247.81122498802804 - Train Accuracy:  0.8\n",
      "epoch:  485  -  cost:  0.43207633  - MSE:  247.77650368128337 - Train Accuracy:  0.8\n",
      "epoch:  486  -  cost:  0.43152758  - MSE:  247.74195118527462 - Train Accuracy:  0.8\n",
      "epoch:  487  -  cost:  0.43098015  - MSE:  247.7076172621665 - Train Accuracy:  0.8\n",
      "epoch:  488  -  cost:  0.43043524  - MSE:  247.67342356784806 - Train Accuracy:  0.8\n",
      "epoch:  489  -  cost:  0.42989188  - MSE:  247.63942331767944 - Train Accuracy:  0.8060606\n",
      "epoch:  490  -  cost:  0.4293507  - MSE:  247.60570406440695 - Train Accuracy:  0.8060606\n",
      "epoch:  491  -  cost:  0.42881146  - MSE:  247.57210010381766 - Train Accuracy:  0.8060606\n",
      "epoch:  492  -  cost:  0.428277  - MSE:  247.545550383383 - Train Accuracy:  0.8060606\n",
      "epoch:  493  -  cost:  0.4277434  - MSE:  247.51292774813896 - Train Accuracy:  0.8060606\n",
      "epoch:  494  -  cost:  0.42721197  - MSE:  247.4868497184592 - Train Accuracy:  0.8060606\n",
      "epoch:  495  -  cost:  0.42668253  - MSE:  247.4547063092198 - Train Accuracy:  0.8060606\n",
      "epoch:  496  -  cost:  0.42615527  - MSE:  247.4292470906655 - Train Accuracy:  0.8060606\n",
      "epoch:  497  -  cost:  0.42562926  - MSE:  247.39758120136915 - Train Accuracy:  0.8121212\n",
      "epoch:  498  -  cost:  0.42510557  - MSE:  247.37240130284275 - Train Accuracy:  0.8121212\n",
      "epoch:  499  -  cost:  0.42458326  - MSE:  247.34111266938322 - Train Accuracy:  0.8121212\n",
      "epoch:  500  -  cost:  0.42406288  - MSE:  247.31002099054984 - Train Accuracy:  0.8121212\n",
      "epoch:  501  -  cost:  0.4235439  - MSE:  247.28541843806886 - Train Accuracy:  0.8121212\n",
      "epoch:  502  -  cost:  0.4230268  - MSE:  247.25453423303 - Train Accuracy:  0.8121212\n",
      "epoch:  503  -  cost:  0.42251125  - MSE:  247.2295547235551 - Train Accuracy:  0.8121212\n",
      "epoch:  504  -  cost:  0.42199722  - MSE:  247.19850030772093 - Train Accuracy:  0.8121212\n",
      "epoch:  505  -  cost:  0.42149225  - MSE:  247.17379489084712 - Train Accuracy:  0.8121212\n",
      "epoch:  506  -  cost:  0.42099127  - MSE:  247.14438973475146 - Train Accuracy:  0.8121212\n",
      "epoch:  507  -  cost:  0.42048553  - MSE:  247.12308335848815 - Train Accuracy:  0.8121212\n",
      "epoch:  508  -  cost:  0.41998172  - MSE:  247.0959453206614 - Train Accuracy:  0.8121212\n",
      "epoch:  509  -  cost:  0.41947895  - MSE:  247.0751194970124 - Train Accuracy:  0.8121212\n",
      "epoch:  510  -  cost:  0.41897875  - MSE:  247.0483413075722 - Train Accuracy:  0.8121212\n",
      "epoch:  511  -  cost:  0.41847935  - MSE:  247.02789048334301 - Train Accuracy:  0.8121212\n",
      "epoch:  512  -  cost:  0.4179829  - MSE:  247.00789380714065 - Train Accuracy:  0.8121212\n",
      "epoch:  513  -  cost:  0.4174882  - MSE:  246.98180927739725 - Train Accuracy:  0.8121212\n",
      "epoch:  514  -  cost:  0.4169957  - MSE:  246.96212764382017 - Train Accuracy:  0.8121212\n",
      "epoch:  515  -  cost:  0.41650644  - MSE:  246.9350008613882 - Train Accuracy:  0.8121212\n",
      "epoch:  516  -  cost:  0.4160188  - MSE:  246.9141882642802 - Train Accuracy:  0.8121212\n",
      "epoch:  517  -  cost:  0.41553277  - MSE:  246.8875135240009 - Train Accuracy:  0.8121212\n",
      "epoch:  518  -  cost:  0.4150482  - MSE:  246.8670687835697 - Train Accuracy:  0.8121212\n",
      "epoch:  519  -  cost:  0.41456538  - MSE:  246.84079723447508 - Train Accuracy:  0.8121212\n",
      "epoch:  520  -  cost:  0.41408113  - MSE:  246.81906296384602 - Train Accuracy:  0.8121212\n",
      "epoch:  521  -  cost:  0.41359913  - MSE:  246.79143333528464 - Train Accuracy:  0.8121212\n",
      "epoch:  522  -  cost:  0.41311845  - MSE:  246.77002442044918 - Train Accuracy:  0.8121212\n",
      "epoch:  523  -  cost:  0.41263956  - MSE:  246.74245154026795 - Train Accuracy:  0.8121212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  524  -  cost:  0.412162  - MSE:  246.72113428774213 - Train Accuracy:  0.8181818\n",
      "epoch:  525  -  cost:  0.4116861  - MSE:  246.69368057737384 - Train Accuracy:  0.8242424\n",
      "epoch:  526  -  cost:  0.41121197  - MSE:  246.67241421154054 - Train Accuracy:  0.8242424\n",
      "epoch:  527  -  cost:  0.41073918  - MSE:  246.64525479812355 - Train Accuracy:  0.8242424\n",
      "epoch:  528  -  cost:  0.41026777  - MSE:  246.624382352986 - Train Accuracy:  0.8242424\n",
      "epoch:  529  -  cost:  0.40979767  - MSE:  246.5975354705468 - Train Accuracy:  0.8242424\n",
      "epoch:  530  -  cost:  0.4093295  - MSE:  246.5768613671141 - Train Accuracy:  0.8242424\n",
      "epoch:  531  -  cost:  0.40886208  - MSE:  246.5502555156037 - Train Accuracy:  0.830303\n",
      "epoch:  532  -  cost:  0.40839687  - MSE:  246.52990781799127 - Train Accuracy:  0.830303\n",
      "epoch:  533  -  cost:  0.40793264  - MSE:  246.50362864036302 - Train Accuracy:  0.830303\n",
      "epoch:  534  -  cost:  0.40747076  - MSE:  246.48355712666 - Train Accuracy:  0.830303\n",
      "epoch:  535  -  cost:  0.407009  - MSE:  246.4574987436457 - Train Accuracy:  0.830303\n",
      "epoch:  536  -  cost:  0.40655184  - MSE:  246.43172239023392 - Train Accuracy:  0.830303\n",
      "epoch:  537  -  cost:  0.4061036  - MSE:  246.41162925494123 - Train Accuracy:  0.830303\n",
      "epoch:  538  -  cost:  0.40565658  - MSE:  246.38565668230498 - Train Accuracy:  0.830303\n",
      "epoch:  539  -  cost:  0.40521088  - MSE:  246.36585590114166 - Train Accuracy:  0.830303\n",
      "epoch:  540  -  cost:  0.40476698  - MSE:  246.34012131806608 - Train Accuracy:  0.830303\n",
      "epoch:  541  -  cost:  0.40432435  - MSE:  246.32094825989083 - Train Accuracy:  0.830303\n",
      "epoch:  542  -  cost:  0.40388286  - MSE:  246.2958399832329 - Train Accuracy:  0.830303\n",
      "epoch:  543  -  cost:  0.40344307  - MSE:  246.2709613020278 - Train Accuracy:  0.830303\n",
      "epoch:  544  -  cost:  0.40300497  - MSE:  246.2520890596715 - Train Accuracy:  0.830303\n",
      "epoch:  545  -  cost:  0.402566  - MSE:  246.22753565742244 - Train Accuracy:  0.830303\n",
      "epoch:  546  -  cost:  0.4021287  - MSE:  246.20896298665957 - Train Accuracy:  0.830303\n",
      "epoch:  547  -  cost:  0.40169257  - MSE:  246.1845642433648 - Train Accuracy:  0.830303\n",
      "epoch:  548  -  cost:  0.40125844  - MSE:  246.16034733995008 - Train Accuracy:  0.830303\n",
      "epoch:  549  -  cost:  0.4008245  - MSE:  246.1422715557132 - Train Accuracy:  0.830303\n",
      "epoch:  550  -  cost:  0.40039313  - MSE:  246.11825880397257 - Train Accuracy:  0.830303\n",
      "epoch:  551  -  cost:  0.3999631  - MSE:  246.09974604486789 - Train Accuracy:  0.830303\n",
      "epoch:  552  -  cost:  0.3995343  - MSE:  246.07540673958152 - Train Accuracy:  0.8363636\n",
      "epoch:  553  -  cost:  0.3991063  - MSE:  246.05187889832666 - Train Accuracy:  0.8363636\n",
      "epoch:  554  -  cost:  0.3986818  - MSE:  246.03111244115172 - Train Accuracy:  0.8363636\n",
      "epoch:  555  -  cost:  0.39825833  - MSE:  246.0104827501165 - Train Accuracy:  0.8424242\n",
      "epoch:  556  -  cost:  0.3978364  - MSE:  245.99588738732152 - Train Accuracy:  0.8424242\n",
      "epoch:  557  -  cost:  0.3974128  - MSE:  245.97556828275097 - Train Accuracy:  0.8484849\n",
      "epoch:  558  -  cost:  0.39699033  - MSE:  245.9551782204601 - Train Accuracy:  0.8484849\n",
      "epoch:  559  -  cost:  0.39656928  - MSE:  245.9349645389769 - Train Accuracy:  0.8484849\n",
      "epoch:  560  -  cost:  0.3961509  - MSE:  245.91470127153465 - Train Accuracy:  0.8484849\n",
      "epoch:  561  -  cost:  0.39573386  - MSE:  245.89462262270726 - Train Accuracy:  0.8484849\n",
      "epoch:  562  -  cost:  0.39531827  - MSE:  245.87477407045657 - Train Accuracy:  0.8484849\n",
      "epoch:  563  -  cost:  0.39490366  - MSE:  245.85504306368287 - Train Accuracy:  0.8484849\n",
      "epoch:  564  -  cost:  0.3944885  - MSE:  245.83554067902165 - Train Accuracy:  0.8484849\n",
      "epoch:  565  -  cost:  0.39407423  - MSE:  245.8162792673559 - Train Accuracy:  0.8484849\n",
      "epoch:  566  -  cost:  0.39366126  - MSE:  245.8028770213394 - Train Accuracy:  0.8484849\n",
      "epoch:  567  -  cost:  0.39324975  - MSE:  245.78359596084738 - Train Accuracy:  0.8545455\n",
      "epoch:  568  -  cost:  0.3928381  - MSE:  245.76452188874887 - Train Accuracy:  0.8545455\n",
      "epoch:  569  -  cost:  0.3924288  - MSE:  245.74542156011375 - Train Accuracy:  0.8545455\n",
      "epoch:  570  -  cost:  0.39202103  - MSE:  245.7245107972162 - Train Accuracy:  0.8606061\n",
      "epoch:  571  -  cost:  0.39161408  - MSE:  245.70383604381013 - Train Accuracy:  0.8606061\n",
      "epoch:  572  -  cost:  0.391209  - MSE:  245.6834673249388 - Train Accuracy:  0.8606061\n",
      "epoch:  573  -  cost:  0.39080486  - MSE:  245.66321593434026 - Train Accuracy:  0.8606061\n",
      "epoch:  574  -  cost:  0.39040205  - MSE:  245.64320178035666 - Train Accuracy:  0.8606061\n",
      "epoch:  575  -  cost:  0.39000046  - MSE:  245.62333806638986 - Train Accuracy:  0.8606061\n",
      "epoch:  576  -  cost:  0.38959983  - MSE:  245.60365195149876 - Train Accuracy:  0.8606061\n",
      "epoch:  577  -  cost:  0.38920075  - MSE:  245.58984734268762 - Train Accuracy:  0.8606061\n",
      "epoch:  578  -  cost:  0.38880268  - MSE:  245.57028300268436 - Train Accuracy:  0.8606061\n",
      "epoch:  579  -  cost:  0.38840583  - MSE:  245.55093461891224 - Train Accuracy:  0.8606061\n",
      "epoch:  580  -  cost:  0.3880103  - MSE:  245.53179106487173 - Train Accuracy:  0.8606061\n",
      "epoch:  581  -  cost:  0.3876157  - MSE:  245.51272816220657 - Train Accuracy:  0.8606061\n",
      "epoch:  582  -  cost:  0.38722244  - MSE:  245.4938552457232 - Train Accuracy:  0.8606061\n",
      "epoch:  583  -  cost:  0.3868301  - MSE:  245.4751329882098 - Train Accuracy:  0.8606061\n",
      "epoch:  584  -  cost:  0.3864392  - MSE:  245.45647083145508 - Train Accuracy:  0.8606061\n",
      "epoch:  585  -  cost:  0.38604897  - MSE:  245.43793678960023 - Train Accuracy:  0.8606061\n",
      "epoch:  586  -  cost:  0.38565832  - MSE:  245.41838873776447 - Train Accuracy:  0.8606061\n",
      "epoch:  587  -  cost:  0.38526884  - MSE:  245.39903293685208 - Train Accuracy:  0.8606061\n",
      "epoch:  588  -  cost:  0.38488054  - MSE:  245.38046453754083 - Train Accuracy:  0.8606061\n",
      "epoch:  589  -  cost:  0.384493  - MSE:  245.36206496095994 - Train Accuracy:  0.8606061\n",
      "epoch:  590  -  cost:  0.3841016  - MSE:  245.34354799466053 - Train Accuracy:  0.8606061\n",
      "epoch:  591  -  cost:  0.38371348  - MSE:  245.32093100008296 - Train Accuracy:  0.8606061\n",
      "epoch:  592  -  cost:  0.38332945  - MSE:  245.29844763363457 - Train Accuracy:  0.8606061\n",
      "epoch:  593  -  cost:  0.3829471  - MSE:  245.27634586646516 - Train Accuracy:  0.8606061\n",
      "epoch:  594  -  cost:  0.38256595  - MSE:  245.25457621914816 - Train Accuracy:  0.8606061\n",
      "epoch:  595  -  cost:  0.382186  - MSE:  245.23354338602687 - Train Accuracy:  0.8606061\n",
      "epoch:  596  -  cost:  0.38180792  - MSE:  245.21735784430217 - Train Accuracy:  0.8606061\n",
      "epoch:  597  -  cost:  0.38143036  - MSE:  245.1963381092269 - Train Accuracy:  0.8606061\n",
      "epoch:  598  -  cost:  0.38105398  - MSE:  245.1756234102805 - Train Accuracy:  0.8606061\n",
      "epoch:  599  -  cost:  0.38067862  - MSE:  245.15500074482532 - Train Accuracy:  0.8606061\n",
      "epoch:  600  -  cost:  0.3803072  - MSE:  245.12619328358448 - Train Accuracy:  0.8606061\n",
      "epoch:  601  -  cost:  0.3799367  - MSE:  245.09797893522716 - Train Accuracy:  0.8606061\n",
      "epoch:  602  -  cost:  0.37956768  - MSE:  245.07029075966517 - Train Accuracy:  0.8606061\n",
      "epoch:  603  -  cost:  0.3791993  - MSE:  245.05135971952322 - Train Accuracy:  0.8606061\n",
      "epoch:  604  -  cost:  0.37882903  - MSE:  245.02914104567085 - Train Accuracy:  0.8606061\n",
      "epoch:  605  -  cost:  0.3784604  - MSE:  245.00716919830435 - Train Accuracy:  0.8606061\n",
      "epoch:  606  -  cost:  0.37809256  - MSE:  244.98537171002178 - Train Accuracy:  0.8606061\n",
      "epoch:  607  -  cost:  0.37772593  - MSE:  244.96391329574587 - Train Accuracy:  0.8606061\n",
      "epoch:  608  -  cost:  0.37736052  - MSE:  244.9426888962228 - Train Accuracy:  0.8606061\n",
      "epoch:  609  -  cost:  0.37700254  - MSE:  244.92163349768893 - Train Accuracy:  0.8606061\n",
      "epoch:  610  -  cost:  0.376647  - MSE:  244.9101520589887 - Train Accuracy:  0.8606061\n",
      "epoch:  611  -  cost:  0.37629363  - MSE:  244.89846813554283 - Train Accuracy:  0.8606061\n",
      "epoch:  612  -  cost:  0.37594497  - MSE:  244.88844537563025 - Train Accuracy:  0.8606061\n",
      "epoch:  613  -  cost:  0.37559682  - MSE:  244.87829118710528 - Train Accuracy:  0.8606061\n",
      "epoch:  614  -  cost:  0.3752514  - MSE:  244.8677582215687 - Train Accuracy:  0.8606061\n",
      "epoch:  615  -  cost:  0.37490696  - MSE:  244.864003870625 - Train Accuracy:  0.8606061\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  616  -  cost:  0.37456465  - MSE:  244.85361128515862 - Train Accuracy:  0.8606061\n",
      "epoch:  617  -  cost:  0.37422186  - MSE:  244.85007380597332 - Train Accuracy:  0.8606061\n",
      "epoch:  618  -  cost:  0.37388209  - MSE:  244.84013022931478 - Train Accuracy:  0.8666667\n",
      "epoch:  619  -  cost:  0.3735417  - MSE:  244.83607160480543 - Train Accuracy:  0.8666667\n",
      "epoch:  620  -  cost:  0.37320423  - MSE:  244.8255822935274 - Train Accuracy:  0.8666667\n",
      "epoch:  621  -  cost:  0.37286493  - MSE:  244.82191819505863 - Train Accuracy:  0.8666667\n",
      "epoch:  622  -  cost:  0.37253058  - MSE:  244.81188305507044 - Train Accuracy:  0.8666667\n",
      "epoch:  623  -  cost:  0.3721937  - MSE:  244.80860874396564 - Train Accuracy:  0.8666667\n",
      "epoch:  624  -  cost:  0.3718593  - MSE:  244.80952889424657 - Train Accuracy:  0.8666667\n",
      "epoch:  625  -  cost:  0.37151283  - MSE:  244.79341673395794 - Train Accuracy:  0.8666667\n",
      "epoch:  626  -  cost:  0.37116763  - MSE:  244.77771356305468 - Train Accuracy:  0.8727273\n",
      "epoch:  627  -  cost:  0.37082505  - MSE:  244.76892380479273 - Train Accuracy:  0.8727273\n",
      "epoch:  628  -  cost:  0.37048236  - MSE:  244.75414023200696 - Train Accuracy:  0.8727273\n",
      "epoch:  629  -  cost:  0.37014064  - MSE:  244.73964027119968 - Train Accuracy:  0.8727273\n",
      "epoch:  630  -  cost:  0.36979973  - MSE:  244.72537390071307 - Train Accuracy:  0.8727273\n",
      "epoch:  631  -  cost:  0.36946085  - MSE:  244.71236614752715 - Train Accuracy:  0.8727273\n",
      "epoch:  632  -  cost:  0.36912417  - MSE:  244.70520234020304 - Train Accuracy:  0.8727273\n",
      "epoch:  633  -  cost:  0.368793  - MSE:  244.69651150726384 - Train Accuracy:  0.8727273\n",
      "epoch:  634  -  cost:  0.36846858  - MSE:  244.6883871588008 - Train Accuracy:  0.8727273\n",
      "epoch:  635  -  cost:  0.36814436  - MSE:  244.6800390449399 - Train Accuracy:  0.8727273\n",
      "epoch:  636  -  cost:  0.36782172  - MSE:  244.67278540991316 - Train Accuracy:  0.8727273\n",
      "epoch:  637  -  cost:  0.36749932  - MSE:  244.6649885241724 - Train Accuracy:  0.8727273\n",
      "epoch:  638  -  cost:  0.36717832  - MSE:  244.65825950261527 - Train Accuracy:  0.8727273\n",
      "epoch:  639  -  cost:  0.3668583  - MSE:  244.65126288756034 - Train Accuracy:  0.8727273\n",
      "epoch:  640  -  cost:  0.36653966  - MSE:  244.64530540523208 - Train Accuracy:  0.8727273\n",
      "epoch:  641  -  cost:  0.36622173  - MSE:  244.64251393820012 - Train Accuracy:  0.8727273\n",
      "epoch:  642  -  cost:  0.36590454  - MSE:  244.63659935936968 - Train Accuracy:  0.8727273\n",
      "epoch:  643  -  cost:  0.36558884  - MSE:  244.63007981892085 - Train Accuracy:  0.8727273\n",
      "epoch:  644  -  cost:  0.36527354  - MSE:  244.6246363731419 - Train Accuracy:  0.8727273\n",
      "epoch:  645  -  cost:  0.36495936  - MSE:  244.6185106961996 - Train Accuracy:  0.8727273\n",
      "epoch:  646  -  cost:  0.36464635  - MSE:  244.61261950032383 - Train Accuracy:  0.8727273\n",
      "epoch:  647  -  cost:  0.3643335  - MSE:  244.60776869001234 - Train Accuracy:  0.8727273\n",
      "epoch:  648  -  cost:  0.3640229  - MSE:  244.6022993613156 - Train Accuracy:  0.8787879\n",
      "epoch:  649  -  cost:  0.36371276  - MSE:  244.60816028832392 - Train Accuracy:  0.8787879\n",
      "epoch:  650  -  cost:  0.3634033  - MSE:  244.60276685540174 - Train Accuracy:  0.8787879\n",
      "epoch:  651  -  cost:  0.36309478  - MSE:  244.59767412752825 - Train Accuracy:  0.8787879\n",
      "epoch:  652  -  cost:  0.36278734  - MSE:  244.5934043352732 - Train Accuracy:  0.8787879\n",
      "epoch:  653  -  cost:  0.36248022  - MSE:  244.58844928530777 - Train Accuracy:  0.8787879\n",
      "epoch:  654  -  cost:  0.36217472  - MSE:  244.58373364575232 - Train Accuracy:  0.8787879\n",
      "epoch:  655  -  cost:  0.36186895  - MSE:  244.58386101489955 - Train Accuracy:  0.8787879\n",
      "epoch:  656  -  cost:  0.3615616  - MSE:  244.57884124698208 - Train Accuracy:  0.8787879\n",
      "epoch:  657  -  cost:  0.36125487  - MSE:  244.57404454667497 - Train Accuracy:  0.8787879\n",
      "epoch:  658  -  cost:  0.36094874  - MSE:  244.570374259309 - Train Accuracy:  0.8787879\n",
      "epoch:  659  -  cost:  0.36064398  - MSE:  244.5661236729291 - Train Accuracy:  0.8787879\n",
      "epoch:  660  -  cost:  0.36033964  - MSE:  244.56859284175923 - Train Accuracy:  0.8787879\n",
      "epoch:  661  -  cost:  0.36003584  - MSE:  244.56491307366053 - Train Accuracy:  0.8787879\n",
      "epoch:  662  -  cost:  0.3597333  - MSE:  244.5613180898067 - Train Accuracy:  0.8787879\n",
      "epoch:  663  -  cost:  0.35943136  - MSE:  244.56176390858795 - Train Accuracy:  0.8787879\n",
      "epoch:  664  -  cost:  0.3591306  - MSE:  244.55754648940786 - Train Accuracy:  0.8787879\n",
      "epoch:  665  -  cost:  0.35883066  - MSE:  244.55437246548485 - Train Accuracy:  0.8787879\n",
      "epoch:  666  -  cost:  0.35853222  - MSE:  244.55043245320806 - Train Accuracy:  0.8787879\n",
      "epoch:  667  -  cost:  0.35823506  - MSE:  244.55323555713156 - Train Accuracy:  0.8787879\n",
      "epoch:  668  -  cost:  0.3579373  - MSE:  244.5498158950458 - Train Accuracy:  0.8787879\n",
      "epoch:  669  -  cost:  0.35764122  - MSE:  244.5465540267874 - Train Accuracy:  0.8787879\n",
      "epoch:  670  -  cost:  0.3573477  - MSE:  244.543815034173 - Train Accuracy:  0.8787879\n",
      "epoch:  671  -  cost:  0.35705397  - MSE:  244.5422526800024 - Train Accuracy:  0.8787879\n",
      "epoch:  672  -  cost:  0.3567624  - MSE:  244.54518684633305 - Train Accuracy:  0.8787879\n",
      "epoch:  673  -  cost:  0.35647097  - MSE:  244.54979219480234 - Train Accuracy:  0.8787879\n",
      "epoch:  674  -  cost:  0.3561795  - MSE:  244.54816427844656 - Train Accuracy:  0.8787879\n",
      "epoch:  675  -  cost:  0.35588863  - MSE:  244.546643820192 - Train Accuracy:  0.8787879\n",
      "epoch:  676  -  cost:  0.35559916  - MSE:  244.54520414444292 - Train Accuracy:  0.8787879\n",
      "epoch:  677  -  cost:  0.35531244  - MSE:  244.54987104400456 - Train Accuracy:  0.8787879\n",
      "epoch:  678  -  cost:  0.35502455  - MSE:  244.55288870204458 - Train Accuracy:  0.8787879\n",
      "epoch:  679  -  cost:  0.35473743  - MSE:  244.5516318943667 - Train Accuracy:  0.8787879\n",
      "epoch:  680  -  cost:  0.35445073  - MSE:  244.5510101824681 - Train Accuracy:  0.8787879\n",
      "epoch:  681  -  cost:  0.35416684  - MSE:  244.55008915611901 - Train Accuracy:  0.8787879\n",
      "epoch:  682  -  cost:  0.35388175  - MSE:  244.55604611987368 - Train Accuracy:  0.8787879\n",
      "epoch:  683  -  cost:  0.35359743  - MSE:  244.55927448101053 - Train Accuracy:  0.8787879\n",
      "epoch:  684  -  cost:  0.35331374  - MSE:  244.5595994361105 - Train Accuracy:  0.8787879\n",
      "epoch:  685  -  cost:  0.35303327  - MSE:  244.55975486773792 - Train Accuracy:  0.8787879\n",
      "epoch:  686  -  cost:  0.35275182  - MSE:  244.56685428969013 - Train Accuracy:  0.8787879\n",
      "epoch:  687  -  cost:  0.35247105  - MSE:  244.56729861924794 - Train Accuracy:  0.8787879\n",
      "epoch:  688  -  cost:  0.35219067  - MSE:  244.56820664544352 - Train Accuracy:  0.8787879\n",
      "epoch:  689  -  cost:  0.3519136  - MSE:  244.5688248272668 - Train Accuracy:  0.8787879\n",
      "epoch:  690  -  cost:  0.3516352  - MSE:  244.57991042243967 - Train Accuracy:  0.8787879\n",
      "epoch:  691  -  cost:  0.35135707  - MSE:  244.58056906859952 - Train Accuracy:  0.8787879\n",
      "epoch:  692  -  cost:  0.35108033  - MSE:  244.58181349774424 - Train Accuracy:  0.8787879\n",
      "epoch:  693  -  cost:  0.3508056  - MSE:  244.58903456823015 - Train Accuracy:  0.8848485\n",
      "epoch:  694  -  cost:  0.3505295  - MSE:  244.59068309886575 - Train Accuracy:  0.8848485\n",
      "epoch:  695  -  cost:  0.35025463  - MSE:  244.59588511713736 - Train Accuracy:  0.8848485\n",
      "epoch:  696  -  cost:  0.349982  - MSE:  244.59690487957292 - Train Accuracy:  0.8848485\n",
      "epoch:  697  -  cost:  0.34970888  - MSE:  244.6043583555468 - Train Accuracy:  0.8848485\n",
      "epoch:  698  -  cost:  0.3494358  - MSE:  244.60621307675098 - Train Accuracy:  0.8848485\n",
      "epoch:  699  -  cost:  0.3491641  - MSE:  244.608161775506 - Train Accuracy:  0.8848485\n",
      "epoch:  700  -  cost:  0.3488945  - MSE:  244.61595749671176 - Train Accuracy:  0.8848485\n",
      "epoch:  701  -  cost:  0.3486222  - MSE:  244.62162991783498 - Train Accuracy:  0.8848485\n",
      "epoch:  702  -  cost:  0.3483465  - MSE:  244.61966656869194 - Train Accuracy:  0.8848485\n",
      "epoch:  703  -  cost:  0.34807375  - MSE:  244.61848838444251 - Train Accuracy:  0.8848485\n",
      "epoch:  704  -  cost:  0.3478003  - MSE:  244.62653373826146 - Train Accuracy:  0.8848485\n",
      "epoch:  705  -  cost:  0.34752738  - MSE:  244.6253565130289 - Train Accuracy:  0.8848485\n",
      "epoch:  706  -  cost:  0.3472572  - MSE:  244.62783512864323 - Train Accuracy:  0.8848485\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  707  -  cost:  0.34698513  - MSE:  244.63252629179055 - Train Accuracy:  0.8848485\n",
      "epoch:  708  -  cost:  0.34671336  - MSE:  244.6355060157134 - Train Accuracy:  0.8848485\n",
      "epoch:  709  -  cost:  0.34644508  - MSE:  244.64085968792014 - Train Accuracy:  0.8848485\n",
      "epoch:  710  -  cost:  0.34617463  - MSE:  244.64367831744607 - Train Accuracy:  0.8848485\n",
      "epoch:  711  -  cost:  0.34590596  - MSE:  244.6460177946304 - Train Accuracy:  0.8848485\n",
      "epoch:  712  -  cost:  0.34563917  - MSE:  244.65153982095654 - Train Accuracy:  0.8848485\n",
      "epoch:  713  -  cost:  0.3453711  - MSE:  244.6546796435814 - Train Accuracy:  0.8848485\n",
      "epoch:  714  -  cost:  0.3451046  - MSE:  244.65430820042235 - Train Accuracy:  0.8848485\n",
      "epoch:  715  -  cost:  0.344839  - MSE:  244.6633856128205 - Train Accuracy:  0.8848485\n",
      "epoch:  716  -  cost:  0.34457287  - MSE:  244.66323778955226 - Train Accuracy:  0.8848485\n",
      "epoch:  717  -  cost:  0.3443102  - MSE:  244.67010576788147 - Train Accuracy:  0.8848485\n",
      "epoch:  718  -  cost:  0.34404677  - MSE:  244.67895110507266 - Train Accuracy:  0.8848485\n",
      "epoch:  719  -  cost:  0.34378335  - MSE:  244.68604564119067 - Train Accuracy:  0.8848485\n",
      "epoch:  720  -  cost:  0.3435226  - MSE:  244.69571145510278 - Train Accuracy:  0.8848485\n",
      "epoch:  721  -  cost:  0.34325987  - MSE:  244.70278609858732 - Train Accuracy:  0.8848485\n",
      "epoch:  722  -  cost:  0.343  - MSE:  244.7058030243998 - Train Accuracy:  0.8848485\n",
      "epoch:  723  -  cost:  0.34273982  - MSE:  244.71905912003353 - Train Accuracy:  0.8848485\n",
      "epoch:  724  -  cost:  0.34247985  - MSE:  244.7226661743832 - Train Accuracy:  0.8848485\n",
      "epoch:  725  -  cost:  0.34222254  - MSE:  244.73589806579398 - Train Accuracy:  0.8848485\n",
      "epoch:  726  -  cost:  0.3419632  - MSE:  244.73953819240555 - Train Accuracy:  0.8848485\n",
      "epoch:  727  -  cost:  0.34170675  - MSE:  244.74625356525775 - Train Accuracy:  0.8848485\n",
      "epoch:  728  -  cost:  0.3414498  - MSE:  244.75610476422497 - Train Accuracy:  0.8848485\n",
      "epoch:  729  -  cost:  0.34119347  - MSE:  244.76343721005665 - Train Accuracy:  0.8848485\n",
      "epoch:  730  -  cost:  0.34093875  - MSE:  244.77331555616735 - Train Accuracy:  0.8848485\n",
      "epoch:  731  -  cost:  0.34068277  - MSE:  244.78066414314512 - Train Accuracy:  0.8848485\n",
      "epoch:  732  -  cost:  0.34042966  - MSE:  244.78406411666825 - Train Accuracy:  0.8848485\n",
      "epoch:  733  -  cost:  0.3401756  - MSE:  244.79759208705642 - Train Accuracy:  0.8848485\n",
      "epoch:  734  -  cost:  0.33992267  - MSE:  244.80151911577425 - Train Accuracy:  0.8848485\n",
      "epoch:  735  -  cost:  0.3396705  - MSE:  244.81519496196688 - Train Accuracy:  0.8848485\n",
      "epoch:  736  -  cost:  0.3394181  - MSE:  244.81928486644597 - Train Accuracy:  0.8848485\n",
      "epoch:  737  -  cost:  0.33916846  - MSE:  244.8325217422646 - Train Accuracy:  0.8848485\n",
      "epoch:  738  -  cost:  0.33891642  - MSE:  244.83676245494908 - Train Accuracy:  0.8848485\n",
      "epoch:  739  -  cost:  0.33866802  - MSE:  244.8443887606296 - Train Accuracy:  0.8848485\n",
      "epoch:  740  -  cost:  0.33841762  - MSE:  244.85422235059386 - Train Accuracy:  0.8848485\n",
      "epoch:  741  -  cost:  0.33817005  - MSE:  244.86190567951624 - Train Accuracy:  0.8848485\n",
      "epoch:  742  -  cost:  0.33792168  - MSE:  244.87224093622692 - Train Accuracy:  0.8848485\n",
      "epoch:  743  -  cost:  0.33767438  - MSE:  244.88001693898883 - Train Accuracy:  0.8848485\n",
      "epoch:  744  -  cost:  0.33742797  - MSE:  244.89035283178097 - Train Accuracy:  0.8848485\n",
      "epoch:  745  -  cost:  0.33718187  - MSE:  244.8981421627381 - Train Accuracy:  0.8848485\n",
      "epoch:  746  -  cost:  0.3369434  - MSE:  244.9171365087207 - Train Accuracy:  0.8848485\n",
      "epoch:  747  -  cost:  0.33669674  - MSE:  244.9251031288196 - Train Accuracy:  0.8848485\n",
      "epoch:  748  -  cost:  0.33645707  - MSE:  244.92961322189976 - Train Accuracy:  0.8848485\n",
      "epoch:  749  -  cost:  0.3362157  - MSE:  244.94880076631208 - Train Accuracy:  0.8848485\n",
      "epoch:  750  -  cost:  0.3359753  - MSE:  244.95699834709384 - Train Accuracy:  0.8848485\n",
      "epoch:  751  -  cost:  0.3357334  - MSE:  244.97391216592845 - Train Accuracy:  0.8848485\n",
      "epoch:  752  -  cost:  0.33549592  - MSE:  244.98695192149492 - Train Accuracy:  0.8848485\n",
      "epoch:  753  -  cost:  0.33525622  - MSE:  244.99493896310784 - Train Accuracy:  0.8848485\n",
      "epoch:  754  -  cost:  0.3350168  - MSE:  245.00847312646783 - Train Accuracy:  0.8848485\n",
      "epoch:  755  -  cost:  0.33478472  - MSE:  245.0159030510397 - Train Accuracy:  0.8848485\n",
      "epoch:  756  -  cost:  0.3345437  - MSE:  245.0354182738696 - Train Accuracy:  0.8848485\n",
      "epoch:  757  -  cost:  0.33429673  - MSE:  245.03066633993993 - Train Accuracy:  0.8848485\n",
      "epoch:  758  -  cost:  0.33404824  - MSE:  245.03574337113722 - Train Accuracy:  0.8848485\n",
      "epoch:  759  -  cost:  0.33380234  - MSE:  245.04115322763894 - Train Accuracy:  0.8848485\n",
      "epoch:  760  -  cost:  0.33355868  - MSE:  245.03729303239967 - Train Accuracy:  0.8848485\n",
      "epoch:  761  -  cost:  0.33331263  - MSE:  245.0492250781978 - Train Accuracy:  0.8848485\n",
      "epoch:  762  -  cost:  0.3330684  - MSE:  245.04646171927612 - Train Accuracy:  0.8848485\n",
      "epoch:  763  -  cost:  0.33282366  - MSE:  245.0527028578405 - Train Accuracy:  0.8848485\n",
      "epoch:  764  -  cost:  0.33258134  - MSE:  245.05867712525165 - Train Accuracy:  0.8848485\n",
      "epoch:  765  -  cost:  0.3323406  - MSE:  245.0563425697572 - Train Accuracy:  0.8848485\n",
      "epoch:  766  -  cost:  0.33209834  - MSE:  245.0685835371648 - Train Accuracy:  0.8848485\n",
      "epoch:  767  -  cost:  0.33185822  - MSE:  245.06659029649114 - Train Accuracy:  0.8848485\n",
      "epoch:  768  -  cost:  0.33161655  - MSE:  245.0735351579537 - Train Accuracy:  0.8848485\n",
      "epoch:  769  -  cost:  0.33137578  - MSE:  245.07978747520116 - Train Accuracy:  0.8848485\n",
      "epoch:  770  -  cost:  0.33113754  - MSE:  245.07779356576677 - Train Accuracy:  0.8848485\n",
      "epoch:  771  -  cost:  0.33089608  - MSE:  245.09020815503953 - Train Accuracy:  0.8848485\n",
      "epoch:  772  -  cost:  0.33065912  - MSE:  245.08854694790594 - Train Accuracy:  0.8848485\n",
      "epoch:  773  -  cost:  0.33041975  - MSE:  245.09574455832237 - Train Accuracy:  0.8848485\n",
      "epoch:  774  -  cost:  0.33018106  - MSE:  245.10259054660432 - Train Accuracy:  0.8848485\n",
      "epoch:  775  -  cost:  0.3299459  - MSE:  245.10995056245122 - Train Accuracy:  0.8848485\n",
      "epoch:  776  -  cost:  0.32971054  - MSE:  245.108538874053 - Train Accuracy:  0.8848485\n",
      "epoch:  777  -  cost:  0.32947415  - MSE:  245.12139597136246 - Train Accuracy:  0.8848485\n",
      "epoch:  778  -  cost:  0.32923964  - MSE:  245.12106927118055 - Train Accuracy:  0.8848485\n",
      "epoch:  779  -  cost:  0.32900444  - MSE:  245.1287057240747 - Train Accuracy:  0.8848485\n",
      "epoch:  780  -  cost:  0.32876968  - MSE:  245.13590182728902 - Train Accuracy:  0.8848485\n",
      "epoch:  781  -  cost:  0.3285388  - MSE:  245.14359594469252 - Train Accuracy:  0.8848485\n",
      "epoch:  782  -  cost:  0.3283087  - MSE:  245.14277328239538 - Train Accuracy:  0.8848485\n",
      "epoch:  783  -  cost:  0.32807437  - MSE:  245.15621183432697 - Train Accuracy:  0.8848485\n",
      "epoch:  784  -  cost:  0.32784483  - MSE:  245.15516664240243 - Train Accuracy:  0.8848485\n",
      "epoch:  785  -  cost:  0.32761255  - MSE:  245.16798862980934 - Train Accuracy:  0.8848485\n",
      "epoch:  786  -  cost:  0.3273768  - MSE:  245.17723301609516 - Train Accuracy:  0.8848485\n",
      "epoch:  787  -  cost:  0.32714033  - MSE:  245.17703762925262 - Train Accuracy:  0.8848485\n",
      "epoch:  788  -  cost:  0.32690382  - MSE:  245.1851189898372 - Train Accuracy:  0.8848485\n",
      "epoch:  789  -  cost:  0.3266684  - MSE:  245.1937908935348 - Train Accuracy:  0.8848485\n",
      "epoch:  790  -  cost:  0.3264371  - MSE:  245.1996741336452 - Train Accuracy:  0.8848485\n",
      "epoch:  791  -  cost:  0.3262032  - MSE:  245.21465698720758 - Train Accuracy:  0.8848485\n",
      "epoch:  792  -  cost:  0.3259715  - MSE:  245.22334074742247 - Train Accuracy:  0.8848485\n",
      "epoch:  793  -  cost:  0.3257436  - MSE:  245.22924554644018 - Train Accuracy:  0.8848485\n",
      "epoch:  794  -  cost:  0.32550943  - MSE:  245.2436286305908 - Train Accuracy:  0.8848485\n",
      "epoch:  795  -  cost:  0.32528028  - MSE:  245.25871049713072 - Train Accuracy:  0.8848485\n",
      "epoch:  796  -  cost:  0.32505345  - MSE:  245.25851377458997 - Train Accuracy:  0.8848485\n",
      "epoch:  797  -  cost:  0.32482174  - MSE:  245.2793620280688 - Train Accuracy:  0.8848485\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  798  -  cost:  0.32459676  - MSE:  245.27975157644173 - Train Accuracy:  0.8848485\n",
      "epoch:  799  -  cost:  0.32436815  - MSE:  245.3001566259159 - Train Accuracy:  0.8848485\n",
      "epoch:  800  -  cost:  0.3241428  - MSE:  245.31583657306305 - Train Accuracy:  0.8848485\n",
      "epoch:  801  -  cost:  0.32391974  - MSE:  245.3165688694176 - Train Accuracy:  0.8848485\n",
      "epoch:  802  -  cost:  0.3236954  - MSE:  245.33742007536247 - Train Accuracy:  0.8848485\n",
      "epoch:  803  -  cost:  0.3234708  - MSE:  245.34684699113183 - Train Accuracy:  0.8848485\n",
      "epoch:  804  -  cost:  0.32325104  - MSE:  245.35408872603512 - Train Accuracy:  0.8848485\n",
      "epoch:  805  -  cost:  0.32302958  - MSE:  245.3668458090086 - Train Accuracy:  0.8848485\n",
      "epoch:  806  -  cost:  0.32281122  - MSE:  245.38077267805141 - Train Accuracy:  0.8848485\n",
      "epoch:  807  -  cost:  0.32259515  - MSE:  245.38824270639435 - Train Accuracy:  0.8909091\n",
      "epoch:  808  -  cost:  0.3223785  - MSE:  245.39310008497307 - Train Accuracy:  0.8909091\n",
      "epoch:  809  -  cost:  0.3221619  - MSE:  245.40620830833225 - Train Accuracy:  0.8909091\n",
      "epoch:  810  -  cost:  0.32194778  - MSE:  245.42016302651686 - Train Accuracy:  0.8909091\n",
      "epoch:  811  -  cost:  0.3217346  - MSE:  245.42074131508616 - Train Accuracy:  0.8909091\n",
      "epoch:  812  -  cost:  0.32152152  - MSE:  245.44226706909433 - Train Accuracy:  0.8909091\n",
      "epoch:  813  -  cost:  0.3213111  - MSE:  245.4511777735718 - Train Accuracy:  0.8909091\n",
      "epoch:  814  -  cost:  0.32110098  - MSE:  245.45851279101856 - Train Accuracy:  0.8909091\n",
      "epoch:  815  -  cost:  0.32088903  - MSE:  245.479294117617 - Train Accuracy:  0.8969697\n",
      "epoch:  816  -  cost:  0.3206785  - MSE:  245.48857671487391 - Train Accuracy:  0.8969697\n",
      "epoch:  817  -  cost:  0.32047346  - MSE:  245.49526339238687 - Train Accuracy:  0.8969697\n",
      "epoch:  818  -  cost:  0.3202609  - MSE:  245.51010345799833 - Train Accuracy:  0.8969697\n",
      "epoch:  819  -  cost:  0.32005304  - MSE:  245.52653614201185 - Train Accuracy:  0.8969697\n",
      "epoch:  820  -  cost:  0.31985068  - MSE:  245.53990496943257 - Train Accuracy:  0.8969697\n",
      "epoch:  821  -  cost:  0.31963825  - MSE:  245.54753740849523 - Train Accuracy:  0.8969697\n",
      "epoch:  822  -  cost:  0.31943235  - MSE:  245.5605298089265 - Train Accuracy:  0.8969697\n",
      "epoch:  823  -  cost:  0.3192241  - MSE:  245.56662400840065 - Train Accuracy:  0.8969697\n",
      "epoch:  824  -  cost:  0.31901437  - MSE:  245.58179954887387 - Train Accuracy:  0.8969697\n",
      "epoch:  825  -  cost:  0.31880468  - MSE:  245.59670759647065 - Train Accuracy:  0.8969697\n",
      "epoch:  826  -  cost:  0.31859973  - MSE:  245.59468304135083 - Train Accuracy:  0.8969697\n",
      "epoch:  827  -  cost:  0.31838942  - MSE:  245.614787637043 - Train Accuracy:  0.8969697\n",
      "epoch:  828  -  cost:  0.31818223  - MSE:  245.62935128020797 - Train Accuracy:  0.9030303\n",
      "epoch:  829  -  cost:  0.3179763  - MSE:  245.6362673418402 - Train Accuracy:  0.9030303\n",
      "epoch:  830  -  cost:  0.31777054  - MSE:  245.64632881168637 - Train Accuracy:  0.9030303\n",
      "epoch:  831  -  cost:  0.31756598  - MSE:  245.65461660827208 - Train Accuracy:  0.9030303\n",
      "epoch:  832  -  cost:  0.31736225  - MSE:  245.6737084058181 - Train Accuracy:  0.9030303\n",
      "epoch:  833  -  cost:  0.31715882  - MSE:  245.6801128611713 - Train Accuracy:  0.9030303\n",
      "epoch:  834  -  cost:  0.31695363  - MSE:  245.69234329284197 - Train Accuracy:  0.9030303\n",
      "epoch:  835  -  cost:  0.31674942  - MSE:  245.707607928992 - Train Accuracy:  0.9030303\n",
      "epoch:  836  -  cost:  0.31654787  - MSE:  245.71779659411808 - Train Accuracy:  0.9030303\n",
      "epoch:  837  -  cost:  0.31634662  - MSE:  245.72178124292208 - Train Accuracy:  0.9030303\n",
      "epoch:  838  -  cost:  0.3161445  - MSE:  245.73716554090208 - Train Accuracy:  0.9030303\n",
      "epoch:  839  -  cost:  0.31594616  - MSE:  245.75307243652037 - Train Accuracy:  0.9030303\n",
      "epoch:  840  -  cost:  0.31574473  - MSE:  245.75979644542136 - Train Accuracy:  0.9030303\n",
      "epoch:  841  -  cost:  0.31554508  - MSE:  245.76943057214314 - Train Accuracy:  0.9030303\n",
      "epoch:  842  -  cost:  0.3153442  - MSE:  245.78513744819256 - Train Accuracy:  0.9030303\n",
      "epoch:  843  -  cost:  0.31514558  - MSE:  245.79838585106194 - Train Accuracy:  0.9030303\n",
      "epoch:  844  -  cost:  0.3149512  - MSE:  245.79574761979515 - Train Accuracy:  0.9030303\n",
      "epoch:  845  -  cost:  0.31474957  - MSE:  245.8169186549747 - Train Accuracy:  0.9030303\n",
      "epoch:  846  -  cost:  0.31455293  - MSE:  245.8299577524826 - Train Accuracy:  0.9030303\n",
      "epoch:  847  -  cost:  0.3143584  - MSE:  245.83936897552627 - Train Accuracy:  0.9030303\n",
      "epoch:  848  -  cost:  0.3141603  - MSE:  245.84650246539843 - Train Accuracy:  0.9030303\n",
      "epoch:  849  -  cost:  0.31396106  - MSE:  245.86813649086594 - Train Accuracy:  0.9030303\n",
      "epoch:  850  -  cost:  0.31376293  - MSE:  245.87981911406783 - Train Accuracy:  0.9030303\n",
      "epoch:  851  -  cost:  0.31356615  - MSE:  245.8878621111997 - Train Accuracy:  0.9030303\n",
      "epoch:  852  -  cost:  0.31337073  - MSE:  245.90129642711202 - Train Accuracy:  0.9030303\n",
      "epoch:  853  -  cost:  0.31317446  - MSE:  245.91352924065956 - Train Accuracy:  0.9030303\n",
      "epoch:  854  -  cost:  0.31297952  - MSE:  245.9287853816734 - Train Accuracy:  0.9030303\n",
      "epoch:  855  -  cost:  0.3127854  - MSE:  245.93674453160838 - Train Accuracy:  0.90909094\n",
      "epoch:  856  -  cost:  0.3125902  - MSE:  245.9540552745245 - Train Accuracy:  0.91515154\n",
      "epoch:  857  -  cost:  0.3123961  - MSE:  245.97087786506074 - Train Accuracy:  0.91515154\n",
      "epoch:  858  -  cost:  0.31220138  - MSE:  245.97620649623084 - Train Accuracy:  0.91515154\n",
      "epoch:  859  -  cost:  0.31201056  - MSE:  245.99800121043913 - Train Accuracy:  0.91515154\n",
      "epoch:  860  -  cost:  0.31181777  - MSE:  246.00434913677518 - Train Accuracy:  0.91515154\n",
      "epoch:  861  -  cost:  0.31162578  - MSE:  246.0169108163333 - Train Accuracy:  0.91515154\n",
      "epoch:  862  -  cost:  0.31143254  - MSE:  246.0336819817303 - Train Accuracy:  0.91515154\n",
      "epoch:  863  -  cost:  0.31124115  - MSE:  246.0481045610132 - Train Accuracy:  0.91515154\n",
      "epoch:  864  -  cost:  0.3110512  - MSE:  246.05332029391056 - Train Accuracy:  0.91515154\n",
      "epoch:  865  -  cost:  0.31086358  - MSE:  246.07504302679817 - Train Accuracy:  0.91515154\n",
      "epoch:  866  -  cost:  0.31067368  - MSE:  246.08352382153413 - Train Accuracy:  0.91515154\n",
      "epoch:  867  -  cost:  0.31048447  - MSE:  246.09482775282183 - Train Accuracy:  0.91515154\n",
      "epoch:  868  -  cost:  0.31029555  - MSE:  246.1137716719344 - Train Accuracy:  0.91515154\n",
      "epoch:  869  -  cost:  0.31010702  - MSE:  246.13050824710825 - Train Accuracy:  0.91515154\n",
      "epoch:  870  -  cost:  0.3099205  - MSE:  246.13766652066974 - Train Accuracy:  0.91515154\n",
      "epoch:  871  -  cost:  0.30973202  - MSE:  246.15662808094308 - Train Accuracy:  0.91515154\n",
      "epoch:  872  -  cost:  0.30954552  - MSE:  246.17677078869104 - Train Accuracy:  0.91515154\n",
      "epoch:  873  -  cost:  0.30935937  - MSE:  246.1857989892573 - Train Accuracy:  0.91515154\n",
      "epoch:  874  -  cost:  0.3091739  - MSE:  246.19883903571576 - Train Accuracy:  0.91515154\n",
      "epoch:  875  -  cost:  0.30898663  - MSE:  246.21785329177123 - Train Accuracy:  0.91515154\n",
      "epoch:  876  -  cost:  0.30880085  - MSE:  246.23671388205366 - Train Accuracy:  0.91515154\n",
      "epoch:  877  -  cost:  0.3086159  - MSE:  246.2441517774916 - Train Accuracy:  0.91515154\n",
      "epoch:  878  -  cost:  0.30843177  - MSE:  246.2630083109854 - Train Accuracy:  0.91515154\n",
      "epoch:  879  -  cost:  0.30824986  - MSE:  246.2846517575887 - Train Accuracy:  0.91515154\n",
      "epoch:  880  -  cost:  0.30806547  - MSE:  246.29370744953053 - Train Accuracy:  0.91515154\n",
      "epoch:  881  -  cost:  0.3078818  - MSE:  246.30884319725868 - Train Accuracy:  0.91515154\n",
      "epoch:  882  -  cost:  0.30769742  - MSE:  246.32761106960857 - Train Accuracy:  0.91515154\n",
      "epoch:  883  -  cost:  0.30751002  - MSE:  246.35422237417814 - Train Accuracy:  0.91515154\n",
      "epoch:  884  -  cost:  0.30732545  - MSE:  246.3805490767664 - Train Accuracy:  0.91515154\n",
      "epoch:  885  -  cost:  0.30714008  - MSE:  246.39612646090396 - Train Accuracy:  0.91515154\n",
      "epoch:  886  -  cost:  0.3069547  - MSE:  246.42501680188712 - Train Accuracy:  0.91515154\n",
      "epoch:  887  -  cost:  0.30677053  - MSE:  246.45756919875126 - Train Accuracy:  0.91515154\n",
      "epoch:  888  -  cost:  0.3065879  - MSE:  246.46740646493842 - Train Accuracy:  0.91515154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  889  -  cost:  0.30640417  - MSE:  246.4953374501631 - Train Accuracy:  0.91515154\n",
      "epoch:  890  -  cost:  0.3062213  - MSE:  246.52143097564831 - Train Accuracy:  0.91515154\n",
      "epoch:  891  -  cost:  0.30604246  - MSE:  246.53252470903178 - Train Accuracy:  0.91515154\n",
      "epoch:  892  -  cost:  0.30585787  - MSE:  246.56037222208718 - Train Accuracy:  0.91515154\n",
      "epoch:  893  -  cost:  0.30567628  - MSE:  246.5868197264094 - Train Accuracy:  0.91515154\n",
      "epoch:  894  -  cost:  0.30550063  - MSE:  246.59617189651132 - Train Accuracy:  0.91515154\n",
      "epoch:  895  -  cost:  0.3053152  - MSE:  246.62378722915136 - Train Accuracy:  0.91515154\n",
      "epoch:  896  -  cost:  0.30513877  - MSE:  246.64591920547278 - Train Accuracy:  0.91515154\n",
      "epoch:  897  -  cost:  0.304959  - MSE:  246.655145847885 - Train Accuracy:  0.91515154\n",
      "epoch:  898  -  cost:  0.3047797  - MSE:  246.68319491720982 - Train Accuracy:  0.91515154\n",
      "epoch:  899  -  cost:  0.30460188  - MSE:  246.70248871512575 - Train Accuracy:  0.91515154\n",
      "epoch:  900  -  cost:  0.30442172  - MSE:  246.72675747236198 - Train Accuracy:  0.91515154\n",
      "epoch:  901  -  cost:  0.3042472  - MSE:  246.74106499279836 - Train Accuracy:  0.91515154\n",
      "epoch:  902  -  cost:  0.30406702  - MSE:  246.76939371092945 - Train Accuracy:  0.91515154\n",
      "epoch:  903  -  cost:  0.30389234  - MSE:  246.79061959951864 - Train Accuracy:  0.91515154\n",
      "epoch:  904  -  cost:  0.30371574  - MSE:  246.80060360303528 - Train Accuracy:  0.91515154\n",
      "epoch:  905  -  cost:  0.30353892  - MSE:  246.82877075329856 - Train Accuracy:  0.91515154\n",
      "epoch:  906  -  cost:  0.30336562  - MSE:  246.8477208724911 - Train Accuracy:  0.91515154\n",
      "epoch:  907  -  cost:  0.30318767  - MSE:  246.87328945272245 - Train Accuracy:  0.91515154\n",
      "epoch:  908  -  cost:  0.30301455  - MSE:  246.87989782540905 - Train Accuracy:  0.91515154\n",
      "epoch:  909  -  cost:  0.30283794  - MSE:  246.90203883941427 - Train Accuracy:  0.91515154\n",
      "epoch:  910  -  cost:  0.30266577  - MSE:  246.93429009328034 - Train Accuracy:  0.91515154\n",
      "epoch:  911  -  cost:  0.30249482  - MSE:  246.95066946959798 - Train Accuracy:  0.91515154\n",
      "epoch:  912  -  cost:  0.30231926  - MSE:  246.97182299875507 - Train Accuracy:  0.91515154\n",
      "epoch:  913  -  cost:  0.3021486  - MSE:  246.99412267291532 - Train Accuracy:  0.91515154\n",
      "epoch:  914  -  cost:  0.30197686  - MSE:  247.0125663157382 - Train Accuracy:  0.91515154\n",
      "epoch:  915  -  cost:  0.30180353  - MSE:  247.03105495904407 - Train Accuracy:  0.91515154\n",
      "epoch:  916  -  cost:  0.301634  - MSE:  247.0511832939144 - Train Accuracy:  0.92121214\n",
      "epoch:  917  -  cost:  0.30146053  - MSE:  247.0745820543682 - Train Accuracy:  0.92121214\n",
      "epoch:  918  -  cost:  0.30129147  - MSE:  247.09676790893704 - Train Accuracy:  0.92121214\n",
      "epoch:  919  -  cost:  0.30112207  - MSE:  247.1080244435299 - Train Accuracy:  0.92121214\n",
      "epoch:  920  -  cost:  0.30095062  - MSE:  247.13241158717787 - Train Accuracy:  0.92121214\n",
      "epoch:  921  -  cost:  0.30078232  - MSE:  247.14180917832965 - Train Accuracy:  0.92121214\n",
      "epoch:  922  -  cost:  0.30061495  - MSE:  247.1636616733873 - Train Accuracy:  0.92121214\n",
      "epoch:  923  -  cost:  0.30044773  - MSE:  247.17895063565473 - Train Accuracy:  0.92121214\n",
      "epoch:  924  -  cost:  0.30027786  - MSE:  247.1965982923571 - Train Accuracy:  0.92121214\n",
      "epoch:  925  -  cost:  0.30011207  - MSE:  247.213268327558 - Train Accuracy:  0.92121214\n",
      "epoch:  926  -  cost:  0.29994485  - MSE:  247.23000637266497 - Train Accuracy:  0.92121214\n",
      "epoch:  927  -  cost:  0.29976833  - MSE:  247.23964160054445 - Train Accuracy:  0.92121214\n",
      "epoch:  928  -  cost:  0.2995937  - MSE:  247.25999581032877 - Train Accuracy:  0.92121214\n",
      "epoch:  929  -  cost:  0.2994232  - MSE:  247.27364488728225 - Train Accuracy:  0.92121214\n",
      "epoch:  930  -  cost:  0.29925132  - MSE:  247.28560326478987 - Train Accuracy:  0.92121214\n",
      "epoch:  931  -  cost:  0.2990764  - MSE:  247.3018991702442 - Train Accuracy:  0.92121214\n",
      "epoch:  932  -  cost:  0.2989089  - MSE:  247.31393969226778 - Train Accuracy:  0.92121214\n",
      "epoch:  933  -  cost:  0.29873344  - MSE:  247.32450218949063 - Train Accuracy:  0.92121214\n",
      "epoch:  934  -  cost:  0.29856223  - MSE:  247.34382300452722 - Train Accuracy:  0.92121214\n",
      "epoch:  935  -  cost:  0.298393  - MSE:  247.35765278988225 - Train Accuracy:  0.92121214\n",
      "epoch:  936  -  cost:  0.29822284  - MSE:  247.37422178847186 - Train Accuracy:  0.92121214\n",
      "epoch:  937  -  cost:  0.29805034  - MSE:  247.38683884819875 - Train Accuracy:  0.92121214\n",
      "epoch:  938  -  cost:  0.2978811  - MSE:  247.41356613544997 - Train Accuracy:  0.92121214\n",
      "epoch:  939  -  cost:  0.29771355  - MSE:  247.42628405592222 - Train Accuracy:  0.92121214\n",
      "epoch:  940  -  cost:  0.29753974  - MSE:  247.43734043972887 - Train Accuracy:  0.92121214\n",
      "epoch:  941  -  cost:  0.29737148  - MSE:  247.45244034014442 - Train Accuracy:  0.92121214\n",
      "epoch:  942  -  cost:  0.29720402  - MSE:  247.46461775646208 - Train Accuracy:  0.92121214\n",
      "epoch:  943  -  cost:  0.2970313  - MSE:  247.48282810938846 - Train Accuracy:  0.92121214\n",
      "epoch:  944  -  cost:  0.29686388  - MSE:  247.49808884548287 - Train Accuracy:  0.92121214\n",
      "epoch:  945  -  cost:  0.2967035  - MSE:  247.51267527236095 - Train Accuracy:  0.92121214\n",
      "epoch:  946  -  cost:  0.29653317  - MSE:  247.52029563311456 - Train Accuracy:  0.92121214\n",
      "epoch:  947  -  cost:  0.29636908  - MSE:  247.52643151513863 - Train Accuracy:  0.92121214\n",
      "epoch:  948  -  cost:  0.29620355  - MSE:  247.53450557821841 - Train Accuracy:  0.92121214\n",
      "epoch:  949  -  cost:  0.29603648  - MSE:  247.5497001291473 - Train Accuracy:  0.92121214\n",
      "epoch:  950  -  cost:  0.29587525  - MSE:  247.55990590395763 - Train Accuracy:  0.92121214\n",
      "epoch:  951  -  cost:  0.29571322  - MSE:  247.56840689421378 - Train Accuracy:  0.92121214\n",
      "epoch:  952  -  cost:  0.2955475  - MSE:  247.58522858286986 - Train Accuracy:  0.92121214\n",
      "epoch:  953  -  cost:  0.29538482  - MSE:  247.60335226805802 - Train Accuracy:  0.92121214\n",
      "epoch:  954  -  cost:  0.29522866  - MSE:  247.6120797468561 - Train Accuracy:  0.92121214\n",
      "epoch:  955  -  cost:  0.29506943  - MSE:  247.6273487768047 - Train Accuracy:  0.92121214\n",
      "epoch:  956  -  cost:  0.29491013  - MSE:  247.63943246885506 - Train Accuracy:  0.92121214\n",
      "epoch:  957  -  cost:  0.29475594  - MSE:  247.65449067896776 - Train Accuracy:  0.92121214\n",
      "epoch:  958  -  cost:  0.2945973  - MSE:  247.66367047641847 - Train Accuracy:  0.92121214\n",
      "epoch:  959  -  cost:  0.2944409  - MSE:  247.66835252261032 - Train Accuracy:  0.92727274\n",
      "epoch:  960  -  cost:  0.2942836  - MSE:  247.6810487908495 - Train Accuracy:  0.92727274\n",
      "epoch:  961  -  cost:  0.2941268  - MSE:  247.70457914236934 - Train Accuracy:  0.92727274\n",
      "epoch:  962  -  cost:  0.29397538  - MSE:  247.71520515833933 - Train Accuracy:  0.92727274\n",
      "epoch:  963  -  cost:  0.29381627  - MSE:  247.7313306471862 - Train Accuracy:  0.92727274\n",
      "epoch:  964  -  cost:  0.29366022  - MSE:  247.7437191666514 - Train Accuracy:  0.92727274\n",
      "epoch:  965  -  cost:  0.29351002  - MSE:  247.75452763143528 - Train Accuracy:  0.92727274\n",
      "epoch:  966  -  cost:  0.29335102  - MSE:  247.7635868472427 - Train Accuracy:  0.92727274\n",
      "epoch:  967  -  cost:  0.2931961  - MSE:  247.77676065916634 - Train Accuracy:  0.92727274\n",
      "epoch:  968  -  cost:  0.29304364  - MSE:  247.79322017222572 - Train Accuracy:  0.92727274\n",
      "epoch:  969  -  cost:  0.29288828  - MSE:  247.80565044962947 - Train Accuracy:  0.92727274\n",
      "epoch:  970  -  cost:  0.29273477  - MSE:  247.8300441691948 - Train Accuracy:  0.92727274\n",
      "epoch:  971  -  cost:  0.29258382  - MSE:  247.84299119936549 - Train Accuracy:  0.92727274\n",
      "epoch:  972  -  cost:  0.29243216  - MSE:  247.85111384700684 - Train Accuracy:  0.92727274\n",
      "epoch:  973  -  cost:  0.29227614  - MSE:  247.86960566579495 - Train Accuracy:  0.92727274\n",
      "epoch:  974  -  cost:  0.29212546  - MSE:  247.88596799153822 - Train Accuracy:  0.92727274\n",
      "epoch:  975  -  cost:  0.29197857  - MSE:  247.90036659935754 - Train Accuracy:  0.92727274\n",
      "epoch:  976  -  cost:  0.2918262  - MSE:  247.90818368742597 - Train Accuracy:  0.92727274\n",
      "epoch:  977  -  cost:  0.2916732  - MSE:  247.92273537675305 - Train Accuracy:  0.92727274\n",
      "epoch:  978  -  cost:  0.29152256  - MSE:  247.9396830501588 - Train Accuracy:  0.92727274\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  979  -  cost:  0.29137364  - MSE:  247.95068097531632 - Train Accuracy:  0.92727274\n",
      "epoch:  980  -  cost:  0.29122522  - MSE:  247.96501650855134 - Train Accuracy:  0.92727274\n",
      "epoch:  981  -  cost:  0.29107448  - MSE:  247.9776766021305 - Train Accuracy:  0.92727274\n",
      "epoch:  982  -  cost:  0.2909266  - MSE:  247.98123634067773 - Train Accuracy:  0.92727274\n",
      "epoch:  983  -  cost:  0.29077613  - MSE:  247.99794753720843 - Train Accuracy:  0.92727274\n",
      "epoch:  984  -  cost:  0.29062635  - MSE:  248.0146487066621 - Train Accuracy:  0.92727274\n",
      "epoch:  985  -  cost:  0.29047883  - MSE:  248.0251827182698 - Train Accuracy:  0.92727274\n",
      "epoch:  986  -  cost:  0.29033172  - MSE:  248.03576708625496 - Train Accuracy:  0.92727274\n",
      "epoch:  987  -  cost:  0.29018235  - MSE:  248.05190840189866 - Train Accuracy:  0.92727274\n",
      "epoch:  988  -  cost:  0.2900343  - MSE:  248.06836104456886 - Train Accuracy:  0.92727274\n",
      "epoch:  989  -  cost:  0.28988692  - MSE:  248.0767918023855 - Train Accuracy:  0.92727274\n",
      "epoch:  990  -  cost:  0.28974074  - MSE:  248.09072987747848 - Train Accuracy:  0.92727274\n",
      "epoch:  991  -  cost:  0.28959328  - MSE:  248.10662751965612 - Train Accuracy:  0.92727274\n",
      "epoch:  992  -  cost:  0.28944767  - MSE:  248.11570610822295 - Train Accuracy:  0.92727274\n",
      "epoch:  993  -  cost:  0.2893029  - MSE:  248.12415607101124 - Train Accuracy:  0.92727274\n",
      "epoch:  994  -  cost:  0.28915268  - MSE:  248.1379409447604 - Train Accuracy:  0.92727274\n",
      "epoch:  995  -  cost:  0.28900635  - MSE:  248.14840024580596 - Train Accuracy:  0.92727274\n",
      "epoch:  996  -  cost:  0.28886315  - MSE:  248.16089297258787 - Train Accuracy:  0.92727274\n",
      "epoch:  997  -  cost:  0.28871658  - MSE:  248.17480153606888 - Train Accuracy:  0.92727274\n",
      "epoch:  998  -  cost:  0.2885715  - MSE:  248.18537541497176 - Train Accuracy:  0.92727274\n",
      "epoch:  999  -  cost:  0.2884291  - MSE:  248.1937579078066 - Train Accuracy:  0.92727274\n",
      "Model saved in file: %s TensorFlow_Basics\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy 0.7380952\n",
      "Final MSE 248.1937579078066\n"
     ]
    }
   ],
   "source": [
    "# Read the dataset\n",
    "X, Y = read_dataset()\n",
    "\n",
    "# Shuffle the dataset to mix up the rows\n",
    "X, Y = shuffle(X, Y, random_state=1)\n",
    "\n",
    "# Convert the dataset into train and test datasets\n",
    "train_x, test_x, train_y, test_y = train_test_split(X, Y, test_size=0.20, random_state=45)\n",
    "\n",
    "# Inspect the shape of the train and test datasets\n",
    "print(\"train_x.shape\",train_x.shape)\n",
    "print(\"train_y.shape\",train_y.shape)\n",
    "print(\"test_x.shape\",test_x.shape)\n",
    "print(\"test_y.shape\",test_y.shape)\n",
    "\n",
    "# Define the hyperparameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 1000\n",
    "cost_history = np.empty(shape=[1], dtype=float)\n",
    "# Number of features <=> number of columns\n",
    "n_dim = X.shape[1]   #60\n",
    "print(\"n_dim\",n_dim)\n",
    "n_class = 2 # 2 classes\n",
    "model_path = \"TensorFlow_Basics\"\n",
    "\n",
    "# Define the number of hidden layers an the\n",
    "# number of neurons for each layer\n",
    "n_hidden_1 = 60  # 1st hidden layer with 60 neurons\n",
    "n_hidden_2 = 60\n",
    "n_hidden_3 = 60\n",
    "n_hidden_4 = 60\n",
    "\n",
    "# Inputs and outputs\n",
    "x = tf.placeholder(tf.float32,[None, n_dim])\n",
    "y_ = tf.placeholder(tf.float32,[None, n_class])\n",
    "\n",
    "# Model parameters\n",
    "W = tf.Variable(tf.zeros([n_dim,n_class]))\n",
    "b = tf.Variable(tf.zeros([n_class]))\n",
    "\n",
    "# Model\n",
    "def multilayer_perceptron(x, weights, biases):\n",
    "    # Hidden layer with RELU activations\n",
    "    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    "    # Hidden layer with sigmoid activations\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
    "    layer_2 = tf.nn.sigmoid(layer_2)\n",
    "    # Hidden layer with sigmoid activations\n",
    "    layer_3 = tf.add(tf.matmul(layer_2, weights['h3']), biases['b3'])\n",
    "    layer_3 = tf.nn.sigmoid(layer_3)\n",
    "    # Hidden layer with RELU activations\n",
    "    layer_4 = tf.add(tf.matmul(layer_3, weights['h4']), biases['b4'])\n",
    "    layer_4 = tf.nn.relu(layer_4)\n",
    "    # Output layer with linear activations\n",
    "    out_layer = tf.matmul(layer_4, weights['out']) + biases['out']\n",
    "    return out_layer\n",
    "\n",
    "# define the weights and the biases for each layer\n",
    "\n",
    "weights = {\n",
    "    'h1': tf.Variable(tf.truncated_normal([n_dim, n_hidden_1])),\n",
    "    'h2': tf.Variable(tf.truncated_normal([n_hidden_1, n_hidden_2])),\n",
    "    'h3': tf.Variable(tf.truncated_normal([n_hidden_2, n_hidden_3])),\n",
    "    'h4': tf.Variable(tf.truncated_normal([n_hidden_3, n_hidden_4])),\n",
    "    'out': tf.Variable(tf.truncated_normal([n_hidden_4, n_class])),\n",
    "    }\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.truncated_normal([n_hidden_1])),\n",
    "    'b2': tf.Variable(tf.truncated_normal([n_hidden_2])),\n",
    "    'b3': tf.Variable(tf.truncated_normal([n_hidden_3])),\n",
    "    'b4': tf.Variable(tf.truncated_normal([n_hidden_4])),\n",
    "    'out': tf.Variable(tf.truncated_normal([n_class])),\n",
    "    }\n",
    "\n",
    "# Initialization\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Call your model defined\n",
    "y = multilayer_perceptron(x, weights, biases)\n",
    "\n",
    "# Define the cost function and optimizer\n",
    "cost_function = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=y, labels=y_))\n",
    "training_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost_function)\n",
    "\n",
    "# Launch the graph\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "mse_history = []\n",
    "accuracy_history = []\n",
    "\n",
    "# Calculate the cost and the accuracy for each epoch\n",
    "for epoch in range(training_epochs):\n",
    "    #optimizer\n",
    "    sess.run(training_step, feed_dict={x:train_x, y_:train_y})\n",
    "    #cost\n",
    "    cost = sess.run(cost_function,feed_dict={x:train_x, y_:train_y})\n",
    "    cost_history = np.append(cost_history, cost)\n",
    "    #error_rate\n",
    "    correct_prediction = tf.equal(tf.argmax(y,1),tf.argmax(y_,1))\n",
    "    #accuracy\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    #print(\"Accuracy: \", (sess.run(accuracy, feed_dict={x:test_x, y_:test_y})))\n",
    "    #ypredictions\n",
    "    pred_y = sess.run(y,feed_dict={x:test_x} )\n",
    "    #mean_squared_error\n",
    "    mse = tf.reduce_mean(tf.square(pred_y - test_y))\n",
    "    mse_ = sess.run(mse)\n",
    "    #Accuracy\n",
    "    accuracy = (sess.run(accuracy,feed_dict={x:train_x, y_:train_y}))\n",
    "    accuracy_history.append(accuracy)\n",
    "    print('epoch: ', epoch,' - ', 'cost: ', cost, \" - MSE: \", mse_, \"- Train Accuracy: \", accuracy)\n",
    "    \n",
    "save_path = saver.save(sess, model_path)\n",
    "print(\"Model saved in file: %s\", save_path)\n",
    "\n",
    "plt.plot(accuracy_history)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()\n",
    "\n",
    "#Final \n",
    "#error rate\n",
    "correct_prediction = tf.equal(tf.argmax(y,1),tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "accuracy = (sess.run(accuracy,feed_dict={x:test_x,y_:test_y}))\n",
    "print(\"Testing Accuracy\",accuracy)\n",
    "\n",
    "#final prediction\n",
    "pred_y = sess.run(y,feed_dict={x:test_x})\n",
    "#final mse\n",
    "mse = tf.reduce_mean(tf.square(pred_y - test_y))\n",
    "print(\"Final MSE\",sess.run(mse))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra and doubted one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.empty(2,dtype = int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.empty([2,2],dtype = int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.empty([3,3],dtype = int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.empty(shape = [1],dtype = float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.empty(1,dtype = float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
