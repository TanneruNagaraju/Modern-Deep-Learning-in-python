{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from mlp_functions import forward,derivative_w2,derivative_b2,derivative_w1,derivative_b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_normalized_data():\n",
    "    print(\"Reading in and transforming data...\")\n",
    "    \n",
    "    \n",
    "    df = pd.read_csv('C:/Users/TANNERU/Downloads/train.csv/train.csv')\n",
    "    #print(df)\n",
    "    data = df.values.astype(np.float32)\n",
    "    #print(data)\n",
    "    \n",
    "    np.random.shuffle(data)\n",
    "    \n",
    "    \n",
    "    X = data[:,1:] #except 1 columns\n",
    "    Y = data[:,0].astype(np.int32) #only 1st column\n",
    "    print(\"Innputs\",X)\n",
    "    print(\"output\",Y)\n",
    "    print(X.shape) #(42000, 784)\n",
    "    print(Y.shape) #(42000,)\n",
    "    \n",
    "    \n",
    "    Xtrain = X[:-1000]\n",
    "    Xtest = X[-1000:]\n",
    "    Ytrain = Y[:-1000]\n",
    "    Ytest = Y[-1000:]\n",
    "    print(\"Xtrain\",Xtrain.shape)#(41000, 784)\n",
    "    print(\"Xtest\",Xtest.shape)#(1000, 784)\n",
    "    print(\"Ytrain\",Ytrain.shape)#(41000,)\n",
    "    print(\"Ytest\",Ytest.shape) #(1000,)\n",
    "    \n",
    "    \n",
    "    mu = Xtrain.mean(axis = 0) #(784,)\n",
    "    std = Xtrain.std(axis = 0) \n",
    "    np.place(std,std == 0,1) # changes all values to 0,1\n",
    "    print(np.place(std,std == 0,1))\n",
    "    #print(mu)\n",
    "    print(mu.shape)#(784,)\n",
    "    \n",
    "    \n",
    "    #center the data\n",
    "    Xtrain = (Xtrain - mu)/std\n",
    "    Xtest = (Xtest - mu)/std\n",
    "    print(Xtrain)\n",
    "    print(Xtest)\n",
    "    \n",
    "    \n",
    "    return Xtrain,Xtest,Ytrain,Ytest\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in and transforming data...\n",
      "Innputs [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "output [9 9 1 ... 5 0 3]\n",
      "(42000, 784)\n",
      "(42000,)\n",
      "Xtrain (41000, 784)\n",
      "Xtest (1000, 784)\n",
      "Ytrain (41000,)\n",
      "Ytest (1000,)\n",
      "None\n",
      "(784,)\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32),\n",
       " array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32),\n",
       " array([9, 9, 1, ..., 9, 9, 8]),\n",
       " array([7, 3, 6, 9, 1, 7, 0, 8, 1, 9, 1, 4, 4, 6, 2, 5, 0, 8, 5, 4, 6, 1,\n",
       "        3, 2, 1, 1, 5, 6, 1, 7, 3, 2, 1, 9, 9, 0, 7, 1, 5, 2, 3, 7, 7, 3,\n",
       "        1, 1, 8, 6, 0, 4, 2, 5, 8, 2, 9, 3, 7, 6, 7, 5, 4, 4, 2, 0, 6, 4,\n",
       "        9, 7, 4, 1, 7, 0, 9, 6, 1, 7, 3, 4, 5, 5, 8, 5, 9, 3, 3, 8, 0, 9,\n",
       "        5, 3, 2, 0, 7, 9, 9, 7, 7, 8, 1, 0, 2, 7, 1, 7, 9, 8, 9, 2, 0, 8,\n",
       "        1, 4, 6, 2, 8, 7, 4, 8, 0, 5, 7, 7, 6, 7, 1, 3, 2, 1, 8, 9, 4, 0,\n",
       "        8, 0, 1, 7, 3, 4, 8, 8, 5, 7, 7, 0, 3, 4, 4, 4, 8, 6, 2, 8, 5, 0,\n",
       "        1, 4, 3, 6, 5, 7, 8, 5, 5, 9, 7, 9, 8, 0, 6, 5, 4, 0, 6, 2, 4, 3,\n",
       "        2, 3, 1, 4, 8, 8, 7, 0, 7, 7, 7, 2, 1, 9, 4, 8, 9, 8, 5, 4, 8, 1,\n",
       "        0, 9, 2, 1, 2, 8, 2, 6, 5, 6, 7, 0, 2, 8, 2, 6, 6, 0, 2, 9, 0, 9,\n",
       "        7, 6, 8, 7, 2, 2, 9, 2, 1, 1, 6, 4, 1, 5, 8, 2, 1, 4, 0, 3, 4, 2,\n",
       "        1, 2, 6, 7, 9, 1, 4, 9, 8, 1, 2, 2, 2, 6, 5, 9, 8, 8, 8, 7, 9, 9,\n",
       "        3, 9, 8, 5, 6, 0, 8, 5, 8, 9, 3, 0, 1, 7, 3, 6, 9, 0, 0, 5, 4, 5,\n",
       "        0, 0, 1, 9, 6, 3, 0, 2, 7, 1, 2, 2, 0, 4, 8, 4, 6, 7, 0, 7, 4, 4,\n",
       "        5, 2, 3, 0, 7, 4, 9, 2, 3, 6, 8, 9, 6, 4, 2, 9, 4, 6, 0, 2, 5, 8,\n",
       "        5, 8, 2, 4, 0, 7, 6, 2, 4, 7, 5, 3, 7, 3, 6, 6, 1, 9, 0, 4, 3, 4,\n",
       "        2, 4, 0, 5, 7, 4, 9, 5, 0, 6, 3, 3, 6, 0, 4, 0, 5, 8, 6, 2, 5, 3,\n",
       "        1, 3, 2, 0, 3, 5, 5, 8, 0, 0, 7, 2, 3, 0, 8, 1, 0, 7, 3, 4, 9, 8,\n",
       "        6, 7, 9, 0, 9, 7, 1, 5, 3, 8, 1, 1, 7, 7, 8, 8, 0, 3, 9, 4, 2, 3,\n",
       "        1, 4, 1, 1, 6, 4, 4, 8, 6, 2, 4, 2, 6, 7, 0, 0, 4, 2, 2, 3, 5, 7,\n",
       "        8, 8, 6, 9, 0, 0, 5, 5, 6, 0, 4, 7, 5, 0, 0, 4, 5, 7, 3, 0, 5, 0,\n",
       "        6, 6, 3, 3, 0, 3, 2, 2, 1, 0, 7, 6, 9, 4, 2, 7, 4, 4, 4, 3, 6, 6,\n",
       "        0, 9, 6, 7, 4, 4, 1, 1, 5, 3, 3, 6, 6, 0, 0, 6, 3, 6, 4, 2, 1, 1,\n",
       "        7, 4, 3, 6, 6, 4, 4, 8, 8, 5, 6, 1, 8, 0, 1, 1, 9, 4, 8, 6, 3, 4,\n",
       "        8, 2, 6, 0, 9, 3, 4, 3, 1, 1, 8, 7, 7, 7, 3, 3, 1, 5, 6, 6, 2, 3,\n",
       "        3, 9, 7, 2, 4, 4, 4, 0, 5, 4, 1, 7, 2, 3, 1, 5, 7, 9, 4, 2, 7, 7,\n",
       "        1, 1, 1, 0, 4, 4, 2, 3, 0, 9, 8, 8, 2, 7, 8, 3, 6, 3, 4, 0, 5, 6,\n",
       "        1, 6, 0, 3, 9, 0, 6, 0, 3, 7, 6, 3, 6, 3, 2, 0, 6, 0, 9, 5, 0, 1,\n",
       "        3, 9, 1, 3, 2, 6, 8, 3, 7, 8, 2, 8, 0, 3, 8, 1, 5, 9, 6, 4, 4, 9,\n",
       "        3, 6, 7, 8, 8, 9, 5, 9, 3, 2, 4, 9, 7, 2, 5, 4, 1, 9, 1, 4, 7, 0,\n",
       "        8, 1, 5, 8, 9, 1, 5, 9, 8, 2, 3, 6, 4, 8, 3, 2, 9, 8, 8, 2, 7, 7,\n",
       "        7, 3, 6, 4, 9, 1, 7, 8, 8, 4, 3, 7, 1, 6, 9, 9, 7, 6, 1, 6, 1, 9,\n",
       "        3, 4, 7, 9, 9, 8, 0, 4, 0, 5, 2, 1, 3, 7, 0, 8, 7, 6, 7, 0, 2, 7,\n",
       "        6, 4, 4, 2, 7, 1, 9, 9, 9, 6, 1, 0, 0, 1, 6, 4, 8, 4, 6, 5, 6, 5,\n",
       "        4, 4, 0, 0, 9, 7, 3, 8, 0, 3, 7, 0, 7, 9, 0, 1, 1, 0, 4, 9, 1, 3,\n",
       "        4, 1, 8, 4, 4, 7, 2, 6, 2, 9, 1, 8, 5, 3, 0, 6, 7, 8, 3, 6, 3, 5,\n",
       "        6, 7, 9, 1, 2, 4, 2, 8, 0, 3, 0, 9, 3, 6, 7, 1, 8, 0, 4, 4, 4, 1,\n",
       "        4, 7, 9, 8, 1, 0, 3, 0, 4, 7, 0, 4, 5, 3, 0, 0, 7, 5, 2, 6, 8, 3,\n",
       "        0, 6, 1, 0, 3, 4, 1, 3, 1, 4, 0, 4, 4, 3, 1, 3, 8, 6, 1, 8, 1, 0,\n",
       "        1, 0, 4, 6, 9, 1, 6, 3, 3, 1, 1, 4, 3, 0, 4, 9, 3, 3, 7, 7, 3, 4,\n",
       "        2, 5, 9, 4, 6, 0, 4, 6, 1, 6, 4, 8, 1, 7, 1, 7, 6, 9, 3, 7, 6, 1,\n",
       "        7, 9, 3, 9, 7, 3, 5, 0, 8, 0, 1, 2, 4, 2, 7, 2, 4, 1, 0, 4, 3, 6,\n",
       "        0, 2, 6, 9, 1, 2, 0, 7, 3, 0, 2, 1, 2, 9, 9, 7, 8, 0, 1, 1, 0, 3,\n",
       "        3, 4, 2, 5, 4, 7, 5, 2, 5, 2, 8, 2, 1, 8, 6, 7, 2, 0, 7, 7, 4, 6,\n",
       "        8, 1, 9, 7, 7, 2, 3, 6, 3, 9, 6, 6, 0, 1, 3, 2, 4, 6, 2, 7, 5, 6,\n",
       "        9, 4, 1, 4, 2, 7, 0, 5, 0, 3]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_normalized_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(X,W1,b1,W2,b2):\n",
    "    #sigmoid hidden layer\n",
    "    a = X.dot(W1)+b1\n",
    "    Z = 1/(1+np.exp(-a))\n",
    "    \n",
    "    #relu for hidden layer\n",
    "    #Z = X.dot(W1)+b1\n",
    "    #Z[Z<0] = 0\n",
    "    \n",
    "    #softmax for output layer\n",
    "    A = Z.dot(W2)+b2\n",
    "    expA = np.exp(A)\n",
    "    Y = expA/expA.sum(axis = 1 ,keepdims = True)\n",
    "    return Y ,Z\n",
    "\n",
    "\n",
    "\n",
    "def derivative_w2(Z,T,Y):\n",
    "    return Z.T.dot(Y-T)\n",
    "\n",
    "def derivative_b2(T,Y):\n",
    "    return (Y-T).sum(axis = 0)\n",
    "\n",
    "\n",
    "def derivative_w1(X,Z,T,Y,W2):\n",
    "    # sigmoid\n",
    "    dz = (Y-T).dot(W2.T)*(Z*(1-Z))\n",
    "    return X.T.dot(dz)\n",
    "\n",
    "    # relu\n",
    "    #dz = (Y-T).dot(W2.T)*(Z>0)\n",
    "    #return X.T.dot(dz)\n",
    "\n",
    "def derivative_b1(Z,T,Y,W2):\n",
    "    return ((Y-T).dot(W2.T)*(Z*(1-Z))).sum(axis = 0) # for sigmoid\n",
    "\n",
    "    #return ((Y-T).dot(W2.T)*(Z>0)).sum(axis = 0) # for relu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(p_y):\n",
    "    return np.argmax(p_y,axis = 1)\n",
    "\n",
    "\n",
    "\n",
    "def error_rate(p_y,t):\n",
    "    prediction = predict(p_y)\n",
    "    return np.mean(prediction != t)\n",
    "\n",
    "\n",
    "def cost(p_y,t):\n",
    "    tot = -t*np.log(p_y)\n",
    "    return tot.sum()\n",
    "\n",
    "\n",
    "def y2indicator(y):\n",
    "    N = len(y)\n",
    "    y = y.astype(np.int32)\n",
    "    ind = np.zeros((N,10))\n",
    "    for i in range(N):\n",
    "        ind[i,y[i]] = 1\n",
    "    return ind\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # compare 3 scenarios:\n",
    "    # 1. batch SGD\n",
    "    # 2. batch SGD with momentum\n",
    "    # 3. batch SGD with Nesterov momentum\n",
    "    \n",
    "    max_iter = 20\n",
    "    print_period = 50\n",
    "    \n",
    "    \n",
    "    Xtrain,Xtest,Ytrain,Ytest = get_normalized_data()\n",
    "    \n",
    "    print(\"Xtrain\",Xtrain.shape)#(41000, 784)\n",
    "    print(\"Xtest\",Xtest.shape)#(1000, 784)\n",
    "    print(\"Ytrain\",Ytrain.shape)#(41000,)\n",
    "    print(\"Ytest\",Ytest.shape) #(1000,)\n",
    "    \n",
    "    lr = 0.00004\n",
    "    reg = 0.01\n",
    "    \n",
    "    Ytrain_ind = y2indicator(Ytrain)\n",
    "    Ytest_ind = y2indicator(Ytest)\n",
    "    print(Ytrain_ind.shape)#(41000, 10)\n",
    "    print(Ytest_ind.shape)#(1000, 10)\n",
    "    \n",
    "    \n",
    "    \n",
    "    N,D = Xtrain.shape #(41000, 784)\n",
    "    batch_sz = 500\n",
    "    n_batches = N // 500 #82\n",
    "    \n",
    "    \n",
    "    M = 300 # hidden units\n",
    "    K = 10\n",
    "    \n",
    "    #initializing weights\n",
    "    \n",
    "    W1 = np.random.randn(D,M)/np.sqrt(D)\n",
    "    b1 = np.random.randn(M)\n",
    "    W2 = np.random.randn(M,K)/np.sqrt(M)\n",
    "    b2 = np.random.randn(K)\n",
    "    \n",
    "    \n",
    "    W1_0 = W1.copy()\n",
    "    b1_0 = b1.copy()\n",
    "    W2_0 = W2.copy()\n",
    "    b2_0 = b2.copy()\n",
    "    \n",
    "    \n",
    "    #1.Batch\n",
    "    print(\"------------batch----------\")\n",
    "    \n",
    "    losses_batch =  []\n",
    "    errors_batch = []\n",
    "    \n",
    "    for i in range(max_iter): #20\n",
    "        for j in range(n_batches):#82\n",
    "            Xbatch = Xtrain[j*batch_sz:(j*batch_sz+batch_sz),] #500 to 1000,1000 to 1500,1500 t0 2000..........\n",
    "            Ybatch = Ytrain_ind[j*batch_sz:(j*batch_sz+batch_sz),] #500 to 1000,1000 to 1500,1500 t0 2000..........\n",
    "            pybatch,Z = forward(Xbatch,W1,b1,W2,b2)\n",
    "            \n",
    "            \n",
    "            #gradients\n",
    "            \n",
    "            gw2 = derivative_w2(Z,Ybatch,pybatch)+reg*W2\n",
    "            gb2 = derivative_b2(Ybatch,pybatch)+reg*b2\n",
    "            gw1 = derivative_w1(Xbatch,Z,Ybatch,pybatch,W2) + reg*W1\n",
    "            gb1 = derivative_b1(Z,Ybatch,pybatch,W2)+reg*b1\n",
    "            \n",
    "            \n",
    "            W2-=lr*gw2\n",
    "            b2-=lr*gb2\n",
    "            W1-=lr*gw1\n",
    "            b1-=lr*gb1\n",
    "            \n",
    "            \n",
    "            if j % print_period == 0:\n",
    "                py,_ = forward(Xtest,W1,b1,W2,b2)\n",
    "                l = cost(py,Ytest_ind)\n",
    "                losses_batch.append(l)\n",
    "                print(\"i:\",i,\"j:\",j,\"cost:\",l)\n",
    "                \n",
    "                err = error_rate(py,Ytest)\n",
    "                errors_batch.append(err)\n",
    "                print(\"error rate:\",err)\n",
    "                \n",
    "    py,_ = forward(Xtest,W1,b1,W2,b2)\n",
    "    print(\"final errora rate\",error_rate(py,Ytest))\n",
    "    \n",
    "                \n",
    "                \n",
    "                \n",
    "    #2 batch with momentum\n",
    "    print(\"------------batch with momentum----------\")\n",
    "    \n",
    "    W1_0 = W1.copy()\n",
    "    b1_0 = b1.copy()\n",
    "    W2_0 = W2.copy()\n",
    "    b2_0 = b2.copy()\n",
    "    \n",
    "    \n",
    "    losses_momentum = []\n",
    "    errors_momentum = []\n",
    "    \n",
    "    \n",
    "    mu = 0.9\n",
    "    dW2 = 0\n",
    "    db2 = 0\n",
    "    dW1 = 0\n",
    "    db1 = 0\n",
    "    \n",
    "    \n",
    "    for i in range(max_iter):\n",
    "        for j in range(n_batches):\n",
    "            Xbatch = Xtrain[j*batch_sz:(j*batch_sz + batch_sz),]\n",
    "            Ybatch = Ytrain_ind[j*batch_sz:(j*batch_sz + batch_sz),]\n",
    "            pYbatch, Z = forward(Xbatch, W1, b1, W2, b2)\n",
    "\n",
    "            # gradients\n",
    "            gW2 = derivative_w2(Z, Ybatch, pYbatch) + reg*W2\n",
    "            gb2 = derivative_b2(Ybatch, pYbatch) + reg*b2\n",
    "            gW1 = derivative_w1(Xbatch, Z, Ybatch, pYbatch, W2) + reg*W1\n",
    "            gb1 = derivative_b1(Z, Ybatch, pYbatch, W2) + reg*b1\n",
    "            \n",
    "            \n",
    "            \n",
    "            #update velocities\n",
    "            dW2 = mu*dW2 - lr*gW2\n",
    "            db2 = mu*db2 - lr*gb2\n",
    "            dW1 = mu*dW1 - lr*gW1\n",
    "            db1 = mu*db1 - lr*gb1\n",
    "            \n",
    "            #updates\n",
    "            W2 += dW2\n",
    "            b2 += db2\n",
    "            W1 += dW1\n",
    "            b1 += db1\n",
    "            \n",
    "            \n",
    "            if j % print_period == 0:\n",
    "                py,_ = forward(Xtest,W1,b1,W2,b2)\n",
    "                l = cost(py,Ytest_ind)\n",
    "                losses_momentum.append(l)\n",
    "                print(\"i:\",i,\"j:\",j,\"cost:\",l)\n",
    "                \n",
    "                err = error_rate(py,Ytest)\n",
    "                errors_momentum.append(err)\n",
    "                print(\"error rate:\",err)\n",
    "                \n",
    "    py,_ = forward(Xtest,W1,b1,W2,b2)\n",
    "    print(\"final errora rate\",error_rate(py,Ytest))\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "    #3 batch with nesteriv momentum\n",
    "    print(\"------------batch with momentum----------\")\n",
    "    \n",
    "    W1_0 = W1.copy()\n",
    "    b1_0 = b1.copy()\n",
    "    W2_0 = W2.copy()\n",
    "    b2_0 = b2.copy()\n",
    "    \n",
    "    \n",
    "    losses_nesterov = []\n",
    "    errors_nesterov = []\n",
    "    \n",
    "    \n",
    "    mu = 0.9\n",
    "    vW2 = 0\n",
    "    vb2 = 0\n",
    "    vW1 = 0\n",
    "    vb1 = 0\n",
    "    \n",
    "    \n",
    "    for i in range(max_iter):\n",
    "        for j in range(n_batches):\n",
    "            Xbatch = Xtrain[j*batch_sz:(j*batch_sz + batch_sz),]\n",
    "            Ybatch = Ytrain_ind[j*batch_sz:(j*batch_sz + batch_sz),]\n",
    "            pYbatch, Z = forward(Xbatch, W1, b1, W2, b2)\n",
    "\n",
    "            # gradients\n",
    "            gW2 = derivative_w2(Z, Ybatch, pYbatch) + reg*W2\n",
    "            gb2 = derivative_b2(Ybatch, pYbatch) + reg*b2\n",
    "            gW1 = derivative_w1(Xbatch, Z, Ybatch, pYbatch, W2) + reg*W1\n",
    "            gb1 = derivative_b1(Z, Ybatch, pYbatch, W2) + reg*b1\n",
    "            \n",
    "            \n",
    "            \n",
    "            #update velocities\n",
    "            vW2 = mu*vW2 - lr*gW2\n",
    "            vb2 = mu*vb2 - lr*gb2\n",
    "            vW1 = mu*vW1 - lr*gW1\n",
    "            vb1 = mu*vb1 - lr*gb1\n",
    "            \n",
    "            \n",
    "            \n",
    "            #param updates\n",
    "            W2 += mu*vW2 - lr*gW2\n",
    "            b2 += mu*vb2 - lr*gb2\n",
    "            W1 += mu*vW1 - lr*gW1\n",
    "            b1 += mu*vb1 - lr*gb1\n",
    "            \n",
    "            \n",
    "            if j % print_period == 0:\n",
    "                py,_ = forward(Xtest,W1,b1,W2,b2)\n",
    "                l = cost(py,Ytest_ind)\n",
    "                losses_nesterov.append(l)\n",
    "                print(\"i:\",i,\"j:\",j,\"cost:\",l)\n",
    "                \n",
    "                err = error_rate(py,Ytest)\n",
    "                errors_nesterov.append(err)\n",
    "                print(\"error rate:\",err)\n",
    "                \n",
    "    py,_ = forward(Xtest,W1,b1,W2,b2)\n",
    "    print(\"final errora rate\",error_rate(py,Ytest))\n",
    "            \n",
    "            \n",
    "          \n",
    "    plt.plot(losses_batch,label = \"batch\")\n",
    "    plt.plot(losses_momentum,label = \"momentum\")\n",
    "    plt.plot(losses_nesterov,label = \"nesterov\")\n",
    "    plt.legend()\n",
    "    plt.show()           \n",
    "        \n",
    "    \n",
    "                \n",
    "            \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in and transforming data...\n",
      "Innputs [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "output [3 3 8 ... 8 9 4]\n",
      "(42000, 784)\n",
      "(42000,)\n",
      "Xtrain (41000, 784)\n",
      "Xtest (1000, 784)\n",
      "Ytrain (41000,)\n",
      "Ytest (1000,)\n",
      "None\n",
      "(784,)\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "Xtrain (41000, 784)\n",
      "Xtest (1000, 784)\n",
      "Ytrain (41000,)\n",
      "Ytest (1000,)\n",
      "(41000, 10)\n",
      "(1000, 10)\n",
      "------------batch----------\n",
      "i: 0 j: 0 cost: 2493.339137169524\n",
      "error rate: 0.924\n",
      "i: 0 j: 50 cost: 1945.4197222696753\n",
      "error rate: 0.462\n",
      "i: 1 j: 0 cost: 1745.189356627227\n",
      "error rate: 0.342\n",
      "i: 1 j: 50 cost: 1484.2679195292724\n",
      "error rate: 0.279\n",
      "i: 2 j: 0 cost: 1345.2358280441138\n",
      "error rate: 0.233\n",
      "i: 2 j: 50 cost: 1167.9457298234936\n",
      "error rate: 0.222\n",
      "i: 3 j: 0 cost: 1075.7458125329167\n",
      "error rate: 0.196\n",
      "i: 3 j: 50 cost: 959.1364220353926\n",
      "error rate: 0.185\n",
      "i: 4 j: 0 cost: 898.2707598889699\n",
      "error rate: 0.176\n",
      "i: 4 j: 50 cost: 820.0783094421316\n",
      "error rate: 0.166\n",
      "i: 5 j: 0 cost: 778.4925085978471\n",
      "error rate: 0.161\n",
      "i: 5 j: 50 cost: 723.7810342793916\n",
      "error rate: 0.157\n",
      "i: 6 j: 0 cost: 694.0852124398186\n",
      "error rate: 0.149\n",
      "i: 6 j: 50 cost: 654.0605647309206\n",
      "error rate: 0.14\n",
      "i: 7 j: 0 cost: 631.9748799034116\n",
      "error rate: 0.14\n",
      "i: 7 j: 50 cost: 601.5235731047877\n",
      "error rate: 0.135\n",
      "i: 8 j: 0 cost: 584.5354375194607\n",
      "error rate: 0.134\n",
      "i: 8 j: 50 cost: 560.5980682321626\n",
      "error rate: 0.128\n",
      "i: 9 j: 0 cost: 547.175722995587\n",
      "error rate: 0.126\n",
      "i: 9 j: 50 cost: 527.8458648142606\n",
      "error rate: 0.122\n",
      "i: 10 j: 0 cost: 517.0136090237529\n",
      "error rate: 0.119\n",
      "i: 10 j: 50 cost: 501.0527770097943\n",
      "error rate: 0.118\n",
      "i: 11 j: 0 cost: 492.16203029016015\n",
      "error rate: 0.117\n",
      "i: 11 j: 50 cost: 478.7342768347249\n",
      "error rate: 0.115\n",
      "i: 12 j: 0 cost: 471.33703019614507\n",
      "error rate: 0.113\n",
      "i: 12 j: 50 cost: 459.858903369973\n",
      "error rate: 0.114\n",
      "i: 13 j: 0 cost: 453.635232507208\n",
      "error rate: 0.109\n",
      "i: 13 j: 50 cost: 443.6876758005025\n",
      "error rate: 0.111\n",
      "i: 14 j: 0 cost: 438.4025816140029\n",
      "error rate: 0.106\n",
      "i: 14 j: 50 cost: 429.6771902720619\n",
      "error rate: 0.11\n",
      "i: 15 j: 0 cost: 425.1538975295433\n",
      "error rate: 0.106\n",
      "i: 15 j: 50 cost: 417.4189327173559\n",
      "error rate: 0.104\n",
      "i: 16 j: 0 cost: 413.52176510521286\n",
      "error rate: 0.105\n",
      "i: 16 j: 50 cost: 406.599950662986\n",
      "error rate: 0.103\n",
      "i: 17 j: 0 cost: 403.2229817013085\n",
      "error rate: 0.102\n",
      "i: 17 j: 50 cost: 396.9765742857763\n",
      "error rate: 0.103\n",
      "i: 18 j: 0 cost: 394.0358829288094\n",
      "error rate: 0.102\n",
      "i: 18 j: 50 cost: 388.35637647397675\n",
      "error rate: 0.103\n",
      "i: 19 j: 0 cost: 385.78462470028705\n",
      "error rate: 0.1\n",
      "i: 19 j: 50 cost: 380.58549267386667\n",
      "error rate: 0.101\n",
      "final errora rate 0.1\n",
      "------------batch with momentum----------\n",
      "i: 0 j: 0 cost: 378.3280425969219\n",
      "error rate: 0.099\n",
      "i: 0 j: 50 cost: 347.2254991222202\n",
      "error rate: 0.09\n",
      "i: 1 j: 0 cost: 333.78656478639755\n",
      "error rate: 0.088\n",
      "i: 1 j: 50 cost: 312.8921359177088\n",
      "error rate: 0.084\n",
      "i: 2 j: 0 cost: 306.2812094435325\n",
      "error rate: 0.086\n",
      "i: 2 j: 50 cost: 292.19809018094776\n",
      "error rate: 0.082\n",
      "i: 3 j: 0 cost: 288.6758936633099\n",
      "error rate: 0.083\n",
      "i: 3 j: 50 cost: 277.6665284455071\n",
      "error rate: 0.081\n",
      "i: 4 j: 0 cost: 275.83065996522237\n",
      "error rate: 0.079\n",
      "i: 4 j: 50 cost: 266.5738224392432\n",
      "error rate: 0.078\n",
      "i: 5 j: 0 cost: 265.7589498194736\n",
      "error rate: 0.078\n",
      "i: 5 j: 50 cost: 257.63346706750855\n",
      "error rate: 0.08\n",
      "i: 6 j: 0 cost: 257.48076881133926\n",
      "error rate: 0.08\n",
      "i: 6 j: 50 cost: 250.14069024598413\n",
      "error rate: 0.079\n",
      "i: 7 j: 0 cost: 250.43884233389014\n",
      "error rate: 0.077\n",
      "i: 7 j: 50 cost: 243.6721335808885\n",
      "error rate: 0.078\n",
      "i: 8 j: 0 cost: 244.28791027772468\n",
      "error rate: 0.075\n",
      "i: 8 j: 50 cost: 237.95625948612104\n",
      "error rate: 0.078\n",
      "i: 9 j: 0 cost: 238.8018726602657\n",
      "error rate: 0.075\n",
      "i: 9 j: 50 cost: 232.81150953583764\n",
      "error rate: 0.078\n",
      "i: 10 j: 0 cost: 233.82802680911124\n",
      "error rate: 0.073\n",
      "i: 10 j: 50 cost: 228.11307046995654\n",
      "error rate: 0.073\n",
      "i: 11 j: 0 cost: 229.26044789351172\n",
      "error rate: 0.071\n",
      "i: 11 j: 50 cost: 223.7729942402328\n",
      "error rate: 0.071\n",
      "i: 12 j: 0 cost: 225.02329655836584\n",
      "error rate: 0.07\n",
      "i: 12 j: 50 cost: 219.72765655766625\n",
      "error rate: 0.069\n",
      "i: 13 j: 0 cost: 221.06084878519533\n",
      "error rate: 0.069\n",
      "i: 13 j: 50 cost: 215.93012126550985\n",
      "error rate: 0.069\n",
      "i: 14 j: 0 cost: 217.3316208129561\n",
      "error rate: 0.066\n",
      "i: 14 j: 50 cost: 212.3455788156917\n",
      "error rate: 0.066\n",
      "i: 15 j: 0 cost: 213.80445482651928\n",
      "error rate: 0.066\n",
      "i: 15 j: 50 cost: 208.94769107557676\n",
      "error rate: 0.065\n",
      "i: 16 j: 0 cost: 210.45546385021981\n",
      "error rate: 0.066\n",
      "i: 16 j: 50 cost: 205.71619991446204\n",
      "error rate: 0.064\n",
      "i: 17 j: 0 cost: 207.26603757518353\n",
      "error rate: 0.066\n",
      "i: 17 j: 50 cost: 202.63524005056857\n",
      "error rate: 0.062\n",
      "i: 18 j: 0 cost: 204.2213765324409\n",
      "error rate: 0.065\n",
      "i: 18 j: 50 cost: 199.6921054122501\n",
      "error rate: 0.061\n",
      "i: 19 j: 0 cost: 201.30940025063103\n",
      "error rate: 0.063\n",
      "i: 19 j: 50 cost: 196.87642263701017\n",
      "error rate: 0.061\n",
      "final errora rate 0.063\n",
      "------------batch with momentum----------\n",
      "i: 0 j: 0 cost: 198.56344486160907\n",
      "error rate: 0.062\n",
      "i: 0 j: 50 cost: 194.192602404642\n",
      "error rate: 0.06\n",
      "i: 1 j: 0 cost: 195.61752600999517\n",
      "error rate: 0.061\n",
      "i: 1 j: 50 cost: 191.63048220946627\n",
      "error rate: 0.061\n",
      "i: 2 j: 0 cost: 193.07573567688368\n",
      "error rate: 0.06\n",
      "i: 2 j: 50 cost: 189.1539358505209\n",
      "error rate: 0.06\n",
      "i: 3 j: 0 cost: 190.61294129099065\n",
      "error rate: 0.059\n",
      "i: 3 j: 50 cost: 186.77319170809304\n",
      "error rate: 0.059\n",
      "i: 4 j: 0 cost: 188.24197824627478\n",
      "error rate: 0.058\n",
      "i: 4 j: 50 cost: 184.48465351618805\n",
      "error rate: 0.058\n",
      "i: 5 j: 0 cost: 185.9580851399225\n",
      "error rate: 0.058\n",
      "i: 5 j: 50 cost: 182.28376415078026\n",
      "error rate: 0.057\n",
      "i: 6 j: 0 cost: 183.75711941125314\n",
      "error rate: 0.058\n",
      "i: 6 j: 50 cost: 180.16650479993672\n",
      "error rate: 0.057\n",
      "i: 7 j: 0 cost: 181.63543659172362\n",
      "error rate: 0.057\n",
      "i: 7 j: 50 cost: 178.1290672319216\n",
      "error rate: 0.058\n",
      "i: 8 j: 0 cost: 179.58960948767196\n",
      "error rate: 0.057\n",
      "i: 8 j: 50 cost: 176.1677507327542\n",
      "error rate: 0.058\n",
      "i: 9 j: 0 cost: 177.61635160724575\n",
      "error rate: 0.057\n",
      "i: 9 j: 50 cost: 174.27896005322606\n",
      "error rate: 0.058\n",
      "i: 10 j: 0 cost: 175.71250795309285\n",
      "error rate: 0.056\n",
      "i: 10 j: 50 cost: 172.45922651499245\n",
      "error rate: 0.058\n",
      "i: 11 j: 0 cost: 173.8750616535903\n",
      "error rate: 0.056\n",
      "i: 11 j: 50 cost: 170.70522929378666\n",
      "error rate: 0.056\n",
      "i: 12 j: 0 cost: 172.10114382902208\n",
      "error rate: 0.056\n",
      "i: 12 j: 50 cost: 169.01381178511994\n",
      "error rate: 0.056\n",
      "i: 13 j: 0 cost: 170.38804299789942\n",
      "error rate: 0.056\n",
      "i: 13 j: 50 cost: 167.38199281036552\n",
      "error rate: 0.055\n",
      "i: 14 j: 0 cost: 168.73321050256862\n",
      "error rate: 0.055\n",
      "i: 14 j: 50 cost: 165.8069733248132\n",
      "error rate: 0.054\n",
      "i: 15 j: 0 cost: 167.1342564419833\n",
      "error rate: 0.054\n",
      "i: 15 j: 50 cost: 164.28613440864854\n",
      "error rate: 0.054\n",
      "i: 16 j: 0 cost: 165.58892665432944\n",
      "error rate: 0.054\n",
      "i: 16 j: 50 cost: 162.81701745638136\n",
      "error rate: 0.054\n",
      "i: 17 j: 0 cost: 164.09505858963254\n",
      "error rate: 0.053\n",
      "i: 17 j: 50 cost: 161.39728686949667\n",
      "error rate: 0.051\n",
      "i: 18 j: 0 cost: 162.6505382180444\n",
      "error rate: 0.053\n",
      "i: 18 j: 50 cost: 160.0246964159028\n",
      "error rate: 0.051\n",
      "i: 19 j: 0 cost: 161.2532883099854\n",
      "error rate: 0.053\n",
      "i: 19 j: 50 cost: 158.69708336208961\n",
      "error rate: 0.048\n",
      "final errora rate 0.053\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
