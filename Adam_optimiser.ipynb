{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_normalized_data():\n",
    "    print(\"Reading in and transforming data...\")\n",
    "    \n",
    "    \n",
    "    df = pd.read_csv('C:/Users/TANNERU/Downloads/train.csv/train.csv')\n",
    "    #print(df)\n",
    "    data = df.values.astype(np.float32)\n",
    "    #print(data)\n",
    "    \n",
    "    np.random.shuffle(data)\n",
    "    \n",
    "    \n",
    "    X = data[:,1:] #except 1 columns\n",
    "    Y = data[:,0].astype(np.int32) #only 1st column\n",
    "    print(\"Innputs\",X)\n",
    "    print(\"output\",Y)\n",
    "    print(X.shape) #(42000, 784)\n",
    "    print(Y.shape) #(42000,)\n",
    "    \n",
    "    \n",
    "    Xtrain = X[:-1000]\n",
    "    Xtest = X[-1000:]\n",
    "    Ytrain = Y[:-1000]\n",
    "    Ytest = Y[-1000:]\n",
    "    print(\"Xtrain\",Xtrain.shape)#(41000, 784)\n",
    "    print(\"Xtest\",Xtest.shape)#(1000, 784)\n",
    "    print(\"Ytrain\",Ytrain.shape)#(41000,)\n",
    "    print(\"Ytest\",Ytest.shape) #(1000,)\n",
    "    \n",
    "    \n",
    "    mu = Xtrain.mean(axis = 0) #(784,)\n",
    "    std = Xtrain.std(axis = 0) \n",
    "    np.place(std,std == 0,1) # changes all values to 0,1\n",
    "    print(np.place(std,std == 0,1))\n",
    "    #print(mu)\n",
    "    print(mu.shape)#(784,)\n",
    "    \n",
    "    \n",
    "    #center the data\n",
    "    Xtrain = (Xtrain - mu)/std\n",
    "    Xtest = (Xtest - mu)/std\n",
    "    print(Xtrain)\n",
    "    print(Xtest)\n",
    "    \n",
    "    \n",
    "    return Xtrain,Xtest,Ytrain,Ytest\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(X,W1,b1,W2,b2):\n",
    "    #sigmoid hidden layer\n",
    "    a = X.dot(W1)+b1\n",
    "    Z = 1/(1+np.exp(-a))\n",
    "    \n",
    "    #relu for hidden layer\n",
    "    #Z = X.dot(W1)+b1\n",
    "    #Z[Z<0] = 0\n",
    "    \n",
    "    #softmax for output layer\n",
    "    A = Z.dot(W2)+b2\n",
    "    expA = np.exp(A)\n",
    "    Y = expA/expA.sum(axis = 1 ,keepdims = True)\n",
    "    return Y ,Z\n",
    "\n",
    "\n",
    "\n",
    "def derivative_w2(Z,T,Y):\n",
    "    return Z.T.dot(Y-T)\n",
    "\n",
    "def derivative_b2(T,Y):\n",
    "    return (Y-T).sum(axis = 0)\n",
    "\n",
    "\n",
    "def derivative_w1(X,Z,T,Y,W2):\n",
    "    # sigmoid\n",
    "    dz = (Y-T).dot(W2.T)*(Z*(1-Z))\n",
    "    return X.T.dot(dz)\n",
    "\n",
    "    # relu\n",
    "    #dz = (Y-T).dot(W2.T)*(Z>0)\n",
    "    #return X.T.dot(dz)\n",
    "\n",
    "def derivative_b1(Z,T,Y,W2):\n",
    "    return ((Y-T).dot(W2.T)*(Z*(1-Z))).sum(axis = 0) # for sigmoid\n",
    "\n",
    "    #return ((Y-T).dot(W2.T)*(Z>0)).sum(axis = 0) # for relu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(p_y):\n",
    "    return np.argmax(p_y,axis = 1)\n",
    "\n",
    "\n",
    "\n",
    "def error_rate(p_y,t):\n",
    "    prediction = predict(p_y)\n",
    "    return np.mean(prediction != t)\n",
    "\n",
    "\n",
    "def cost(p_y,t):\n",
    "    tot = -t*np.log(p_y)\n",
    "    return tot.sum()\n",
    "\n",
    "\n",
    "def y2indicator(y):\n",
    "    N = len(y)\n",
    "    y = y.astype(np.int32)\n",
    "    ind = np.zeros((N,10))\n",
    "    for i in range(N):\n",
    "        ind[i,y[i]] = 1\n",
    "    return ind\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    max_iter = 20\n",
    "    print_period = 80\n",
    "    \n",
    "    Xtrain,Xtest,Ytrain,Ytest = get_normalized_data()\n",
    "    \n",
    "    \n",
    "    print(\"Xtrain\",Xtrain.shape)#(41000, 784)\n",
    "    print(\"Xtest\",Xtest.shape)#(1000, 784)\n",
    "    print(\"Ytrain\",Ytrain.shape)#(41000,)\n",
    "    print(\"Ytest\",Ytest.shape) #(1000,)\n",
    "    \n",
    "    \n",
    "    reg = 0.01\n",
    "    \n",
    "    Ytrain_ind = y2indicator(Ytrain)\n",
    "    Ytest_ind = y2indicator(Ytest)\n",
    "    print(Ytrain_ind.shape)#(41000, 10)\n",
    "    print(Ytest_ind.shape)#(1000, 10)\n",
    "    \n",
    "    \n",
    "    \n",
    "    N,D = Xtrain.shape #(41000, 784)\n",
    "    batch_sz = 500\n",
    "    n_batches = N // 500 #82\n",
    "    \n",
    "    \n",
    "    M = 300 # hidden units\n",
    "    K = 10\n",
    "    \n",
    "    #initializing weights\n",
    "    \n",
    "    W1 = np.random.randn(D,M)/np.sqrt(D)\n",
    "    b1 = np.random.randn(M)\n",
    "    W2 = np.random.randn(M,K)/np.sqrt(M)\n",
    "    b2 = np.random.randn(K)\n",
    "    \n",
    "    \n",
    "    W1_0 = W1.copy()\n",
    "    b1_0 = b1.copy()\n",
    "    W2_0 = W2.copy()\n",
    "    b2_0 = b2.copy()\n",
    "    \n",
    "    #1st moment\n",
    "    mW1 = 0\n",
    "    mb1 = 0\n",
    "    mW2 = 0\n",
    "    mb2 = 0\n",
    "    \n",
    "    #2nd moment\n",
    "    \n",
    "    vW1 = 0\n",
    "    vb1 = 0\n",
    "    vW2 = 0\n",
    "    vb2 = 0\n",
    "    \n",
    "    \n",
    "    #hyper params\n",
    "    lr0 = 0.001\n",
    "    beta1 = 0.9\n",
    "    beta2 = 0.99\n",
    "    eps = 1e-8\n",
    "    \n",
    "    \n",
    "    \n",
    "    # 1. Adam\n",
    "    \n",
    "    print(\"----------------ADAM---------------\")\n",
    "    \n",
    "    \n",
    "    loss_adam = []\n",
    "    err_adam = []\n",
    "    t = 1\n",
    "    \n",
    "     \n",
    "    for i in range(max_iter): #20\n",
    "        for j in range(n_batches):#82\n",
    "            Xbatch = Xtrain[j*batch_sz:(j*batch_sz+batch_sz),] #500 to 1000,1000 to 1500,1500 t0 2000..........\n",
    "            Ybatch = Ytrain_ind[j*batch_sz:(j*batch_sz+batch_sz),] #500 to 1000,1000 to 1500,1500 t0 2000..........\n",
    "            pybatch,Z = forward(Xbatch,W1,b1,W2,b2)\n",
    "            \n",
    "            \n",
    "            #gradients #updates\n",
    "            \n",
    "            gW2 = derivative_w2(Z,Ybatch,pybatch) + reg*W2\n",
    "            gb2 = derivative_b2(Ybatch,pybatch) + reg*b2\n",
    "            gW1 = derivative_w1(Xbatch,Z,Ybatch,pybatch,W2) + reg*W1\n",
    "            gb1 = derivative_b1(Z,Ybatch,pybatch,W2) + reg*b1\n",
    "            \n",
    "            \n",
    "            #1st moment update\n",
    "            \n",
    "            mW1 = beta1*mW1 + (1-beta1)*gW1\n",
    "            mb1 = beta1*mb1 + (1-beta1)*gb1\n",
    "            mW2 = beta1*mW2 + (1-beta1)*gW2\n",
    "            mb2 = beta1*mb2 + (1-beta1)*gb2\n",
    "            \n",
    "            \n",
    "            #2nd moment\n",
    "            \n",
    "            vW1 = beta2*vW1 + (1-beta2)*gW1*gW1\n",
    "            vb1 = beta2*vb1 + (1-beta2)*gb1*gb1\n",
    "            vW2 = beta2*vW2 + (1-beta2)*gW2*gW2\n",
    "            vb2 = beta2*vb2 + (1-beta2)*gb2*gb2\n",
    "            \n",
    "            \n",
    "            # bias correction\n",
    "            \n",
    "            correction1 = 1 - beta1 ** t\n",
    "            hat_mW1 = mW1 / correction1\n",
    "            hat_mb1 = mb1 / correction1\n",
    "            hat_mW2 = mW2 / correction1\n",
    "            hat_mb2 = mb2 / correction1\n",
    "            \n",
    "            \n",
    "            correction2 = 1 - beta2 ** t\n",
    "            hat_vW1 = vW1 / correction2\n",
    "            hat_vb1 = vb1 / correction2\n",
    "            hat_vW2 = vW2 / correction2\n",
    "            hat_vb2 = vb2 / correction2\n",
    "            \n",
    "            \n",
    "            t+=1\n",
    "            \n",
    "            # updating weights\n",
    "            W1 = W1 - lr0* hat_mW1 / np.sqrt(hat_vW1 + eps)\n",
    "            b1 = b1 - lr0*hat_mb1 / np.sqrt(hat_vb1 + eps)\n",
    "            W2 = W2 - lr0*hat_mW2 / np.sqrt(hat_vW2 + eps)\n",
    "            b2 = b2 - lr0*hat_mb2 / np.sqrt(hat_vb2 + eps)\n",
    "            \n",
    "            \n",
    "            \n",
    "            if j % print_period == 0:\n",
    "                py,_ = forward(Xtest,W1,b1,W2,b2)\n",
    "                l = cost(py,Ytest_ind)\n",
    "                loss_adam.append(l)\n",
    "                print(\"i:\",i,\"j:\",j,\"cost:\",l)\n",
    "                \n",
    "                err = error_rate(py,Ytest)\n",
    "                err_adam.append(err)\n",
    "                print(\"error rate:\",err)\n",
    "                \n",
    "    py,_ = forward(Xtest,W1,b1,W2,b2)\n",
    "    print(\"final errora rate\",error_rate(py,Ytest))\n",
    "    \n",
    "                \n",
    "    \n",
    "    \n",
    "    #2 Rmsprop with momentum\n",
    "    \n",
    "    print(\"-------------------Rmsprop with momentum-----------------\")\n",
    "    \n",
    "    W1_0 = W1.copy()\n",
    "    b1_0 = b1.copy()\n",
    "    W2_0 = W2.copy()\n",
    "    b2_0 = b2.copy()\n",
    "    \n",
    "    \n",
    "    loss_rms = []\n",
    "    err_rms = []\n",
    "    \n",
    "    \n",
    "    #hyper params\n",
    "    \n",
    "    lr0 = 0.001\n",
    "    mu = 0.9\n",
    "    decay_rate = 0.99\n",
    "    eps = 1e-8\n",
    "    \n",
    "    #rmsprop  cache\n",
    "    \n",
    "    cache_W1 = 1\n",
    "    cache_b1 = 1\n",
    "    cache_W2 = 1\n",
    "    cache_b2 = 1\n",
    "    \n",
    "    #momentum\n",
    "    \n",
    "    dW1 = 0\n",
    "    db1 = 0\n",
    "    dW2 = 0\n",
    "    db2 = 0\n",
    "    \n",
    "    for i in range(max_iter): #20\n",
    "        for j in range(n_batches):#82\n",
    "            Xbatch = Xtrain[j*batch_sz:(j*batch_sz+batch_sz),] #500 to 1000,1000 to 1500,1500 t0 2000..........\n",
    "            Ybatch = Ytrain_ind[j*batch_sz:(j*batch_sz+batch_sz),] #500 to 1000,1000 to 1500,1500 t0 2000..........\n",
    "            pybatch,Z = forward(Xbatch,W1,b1,W2,b2)\n",
    "            \n",
    "            \n",
    "            #updates\n",
    "            gW2 = derivative_w2(Z,Ybatch,pybatch) + reg*W2\n",
    "            cache_W2 = decay_rate*cache_W2 + (1-decay_rate)*gW2*gW2\n",
    "            dW2 = mu*dW2 + (1-mu)*lr0*gW2 / (np.sqrt(cache_W2) + eps)\n",
    "            W2 -= dW2\n",
    "            \n",
    "            gb2 = derivative_b2(Ybatch,pybatch) + reg*b2\n",
    "            cache_b2 = decay_rate*cache_b2 + (1-decay_rate)*gb2*gb2\n",
    "            db2 = mu*db2 + (1-mu)*lr0*gb2 / (np.sqrt(cache_b2) + eps)\n",
    "            b2 -=db2\n",
    "            \n",
    "            gW1 = derivative_w1(Xbatch,Z,Ybatch,pybatch,W2) + reg*W1\n",
    "            cache_W1 = decay_rate*cache_W1 + (1-decay_rate)*gW1*gW1\n",
    "            dW1 = mu*dW1 + (1-mu)*lr0*gW1 / (np.sqrt(cache_W1) + eps)\n",
    "            W1 -= dW1\n",
    "            \n",
    "            gb1 = derivative_b1(Z,Ybatch,pybatch,W2) + reg*b1\n",
    "            cache_b1 = decay_rate*cache_b1 + (1-decay_rate)*gb1*gb1\n",
    "            db1 = mu*db1 + (1-mu)*lr0*gb1 / (np.sqrt(cache_b1) + eps)\n",
    "            b1 -= db1\n",
    "            \n",
    "            \n",
    "            if j % print_period == 0:\n",
    "                py,_ = forward(Xtest,W1,b1,W2,b2)\n",
    "                \n",
    "                ll = cost(py,Ytest_ind)\n",
    "                loss_rms.append(ll)\n",
    "                print(\"i:\",i,\"j:\",j,\"cost:\",ll)\n",
    "                \n",
    "                \n",
    "                err = error_rate(py,Ytest)\n",
    "                err_rms.append(err)\n",
    "                print(\"Erroro_rate\",err)\n",
    " \n",
    "\n",
    "    py,_  = forward(Xtest,W1,b1,W2,b2)\n",
    "    print(\"Final error rate\",error_rate(py,Ytest))\n",
    "    \n",
    "    plt.plot(loss_adam,label = 'Adam')\n",
    "    plt.plot(loss_rms,label = 'RMSprop')\n",
    "    plt.legend()\n",
    "    plt.plot()\n",
    "    \n",
    "                \n",
    "            \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in and transforming data...\n",
      "Innputs [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "output [2 1 4 ... 3 6 3]\n",
      "(42000, 784)\n",
      "(42000,)\n",
      "Xtrain (41000, 784)\n",
      "Xtest (1000, 784)\n",
      "Ytrain (41000,)\n",
      "Ytest (1000,)\n",
      "None\n",
      "(784,)\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "Xtrain (41000, 784)\n",
      "Xtest (1000, 784)\n",
      "Ytrain (41000,)\n",
      "Ytest (1000,)\n",
      "(41000, 10)\n",
      "(1000, 10)\n",
      "----------------ADAM---------------\n",
      "i: 0 j: 0 cost: 2508.2750897995397\n",
      "error rate: 0.864\n",
      "i: 0 j: 80 cost: 377.27018616679516\n",
      "error rate: 0.09\n",
      "i: 1 j: 0 cost: 372.3323128973103\n",
      "error rate: 0.089\n",
      "i: 1 j: 80 cost: 281.3655590047938\n",
      "error rate: 0.079\n",
      "i: 2 j: 0 cost: 279.4707554759746\n",
      "error rate: 0.076\n",
      "i: 2 j: 80 cost: 239.3130834767058\n",
      "error rate: 0.069\n",
      "i: 3 j: 0 cost: 238.11489120685133\n",
      "error rate: 0.068\n",
      "i: 3 j: 80 cost: 210.94261058875958\n",
      "error rate: 0.066\n",
      "i: 4 j: 0 cost: 210.08429907898227\n",
      "error rate: 0.068\n",
      "i: 4 j: 80 cost: 189.7442180727075\n",
      "error rate: 0.058\n",
      "i: 5 j: 0 cost: 189.13050748888014\n",
      "error rate: 0.056\n",
      "i: 5 j: 80 cost: 173.6559869804097\n",
      "error rate: 0.055\n",
      "i: 6 j: 0 cost: 173.23528752496242\n",
      "error rate: 0.052\n",
      "i: 6 j: 80 cost: 161.42421730865095\n",
      "error rate: 0.048\n",
      "i: 7 j: 0 cost: 161.13282492491032\n",
      "error rate: 0.046\n",
      "i: 7 j: 80 cost: 151.9351363258547\n",
      "error rate: 0.044\n",
      "i: 8 j: 0 cost: 151.73319376112892\n",
      "error rate: 0.045\n",
      "i: 8 j: 80 cost: 144.32765727861167\n",
      "error rate: 0.044\n",
      "i: 9 j: 0 cost: 144.19875901213513\n",
      "error rate: 0.043\n",
      "i: 9 j: 80 cost: 138.16211925052127\n",
      "error rate: 0.042\n",
      "i: 10 j: 0 cost: 138.1047835019491\n",
      "error rate: 0.042\n",
      "i: 10 j: 80 cost: 133.06199441294748\n",
      "error rate: 0.04\n",
      "i: 11 j: 0 cost: 133.07274187741007\n",
      "error rate: 0.04\n",
      "i: 11 j: 80 cost: 129.0453746656335\n",
      "error rate: 0.039\n",
      "i: 12 j: 0 cost: 129.11587161153156\n",
      "error rate: 0.038\n",
      "i: 12 j: 80 cost: 125.47489979321887\n",
      "error rate: 0.039\n",
      "i: 13 j: 0 cost: 125.57471675077586\n",
      "error rate: 0.037\n",
      "i: 13 j: 80 cost: 122.82914942651566\n",
      "error rate: 0.036\n",
      "i: 14 j: 0 cost: 122.97545386818594\n",
      "error rate: 0.037\n",
      "i: 14 j: 80 cost: 120.61121778739717\n",
      "error rate: 0.035\n",
      "i: 15 j: 0 cost: 120.76474996009557\n",
      "error rate: 0.036\n",
      "i: 15 j: 80 cost: 118.4306192492316\n",
      "error rate: 0.032\n",
      "i: 16 j: 0 cost: 118.55479307422974\n",
      "error rate: 0.034\n",
      "i: 16 j: 80 cost: 117.03027326016684\n",
      "error rate: 0.032\n",
      "i: 17 j: 0 cost: 117.14041820035936\n",
      "error rate: 0.033\n",
      "i: 17 j: 80 cost: 116.41729736643896\n",
      "error rate: 0.032\n",
      "i: 18 j: 0 cost: 116.50071349556612\n",
      "error rate: 0.031\n",
      "i: 18 j: 80 cost: 114.65193146976978\n",
      "error rate: 0.031\n",
      "i: 19 j: 0 cost: 114.67499035881488\n",
      "error rate: 0.031\n",
      "i: 19 j: 80 cost: 113.65088377797743\n",
      "error rate: 0.03\n",
      "final errora rate 0.03\n",
      "-------------------Rmsprop with momentum-----------------\n",
      "i: 0 j: 0 cost: 113.58702862863942\n",
      "Erroro_rate 0.03\n",
      "i: 0 j: 80 cost: 110.79179048437088\n",
      "Erroro_rate 0.031\n",
      "i: 1 j: 0 cost: 111.13043028592409\n",
      "Erroro_rate 0.031\n",
      "i: 1 j: 80 cost: 110.75675177352223\n",
      "Erroro_rate 0.031\n",
      "i: 2 j: 0 cost: 111.1326061970721\n",
      "Erroro_rate 0.031\n",
      "i: 2 j: 80 cost: 110.87415579538909\n",
      "Erroro_rate 0.031\n",
      "i: 3 j: 0 cost: 111.27304686166126\n",
      "Erroro_rate 0.032\n",
      "i: 3 j: 80 cost: 111.09396812915946\n",
      "Erroro_rate 0.031\n",
      "i: 4 j: 0 cost: 111.49581201641786\n",
      "Erroro_rate 0.032\n",
      "i: 4 j: 80 cost: 111.38016391731523\n",
      "Erroro_rate 0.03\n",
      "i: 5 j: 0 cost: 111.72453729363585\n",
      "Erroro_rate 0.03\n",
      "i: 5 j: 80 cost: 111.682725565603\n",
      "Erroro_rate 0.03\n",
      "i: 6 j: 0 cost: 111.89963063419877\n",
      "Erroro_rate 0.029\n",
      "i: 6 j: 80 cost: 111.90129732661048\n",
      "Erroro_rate 0.03\n",
      "i: 7 j: 0 cost: 111.96659125692473\n",
      "Erroro_rate 0.029\n",
      "i: 7 j: 80 cost: 111.99524843722122\n",
      "Erroro_rate 0.029\n",
      "i: 8 j: 0 cost: 111.93720160923729\n",
      "Erroro_rate 0.029\n",
      "i: 8 j: 80 cost: 112.0105277899313\n",
      "Erroro_rate 0.029\n",
      "i: 9 j: 0 cost: 111.86028949406412\n",
      "Erroro_rate 0.029\n",
      "i: 9 j: 80 cost: 112.01133473136176\n",
      "Erroro_rate 0.029\n",
      "i: 10 j: 0 cost: 111.78659729892263\n",
      "Erroro_rate 0.029\n",
      "i: 10 j: 80 cost: 112.02368065004494\n",
      "Erroro_rate 0.029\n",
      "i: 11 j: 0 cost: 111.73983065709281\n",
      "Erroro_rate 0.029\n",
      "i: 11 j: 80 cost: 112.0455595544951\n",
      "Erroro_rate 0.029\n",
      "i: 12 j: 0 cost: 111.71205795433409\n",
      "Erroro_rate 0.03\n",
      "i: 12 j: 80 cost: 112.08534601962769\n",
      "Erroro_rate 0.029\n",
      "i: 13 j: 0 cost: 111.71343193659499\n",
      "Erroro_rate 0.03\n",
      "i: 13 j: 80 cost: 111.71417202209211\n",
      "Erroro_rate 0.029\n",
      "i: 14 j: 0 cost: 111.30320833685775\n",
      "Erroro_rate 0.031\n",
      "i: 14 j: 80 cost: 112.03146030293343\n",
      "Erroro_rate 0.029\n",
      "i: 15 j: 0 cost: 111.61186227321869\n",
      "Erroro_rate 0.029\n",
      "i: 15 j: 80 cost: 110.95765856390966\n",
      "Erroro_rate 0.028\n",
      "i: 16 j: 0 cost: 110.86911276541805\n",
      "Erroro_rate 0.028\n",
      "i: 16 j: 80 cost: 112.09876717617995\n",
      "Erroro_rate 0.028\n",
      "i: 17 j: 0 cost: 111.40972997069346\n",
      "Erroro_rate 0.029\n",
      "i: 17 j: 80 cost: 111.19065275052719\n",
      "Erroro_rate 0.029\n",
      "i: 18 j: 0 cost: 110.98971028335293\n",
      "Erroro_rate 0.028\n",
      "i: 18 j: 80 cost: 113.01257415560403\n",
      "Erroro_rate 0.03\n",
      "i: 19 j: 0 cost: 112.25470162494165\n",
      "Erroro_rate 0.029\n",
      "i: 19 j: 80 cost: 111.52912579982825\n",
      "Erroro_rate 0.028\n",
      "Final error rate 0.028\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
