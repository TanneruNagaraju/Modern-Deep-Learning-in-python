{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transformed_data():\n",
    "    print(\"Transformed Data\")\n",
    "    \n",
    "    df = pd.read_csv('C:/Users/TANNERU/Downloads/train.csv/train.csv')\n",
    "    #print(df)\n",
    "    data = df.values.astype(np.float32)\n",
    "    #print(data)\n",
    "    \n",
    "    np.random.shuffle(data)\n",
    "    \n",
    "    \n",
    "    X = data[:,1:]\n",
    "    Y = data[:,0].astype(np.int32)\n",
    "    print(\"Innputs\",X)\n",
    "    print(\"output\",Y)\n",
    "    print(X.shape) #(42000, 784)\n",
    "    print(Y.shape) #(42000,)\n",
    "    \n",
    "    \n",
    "    Xtrain = X[:-1000]\n",
    "    Xtest = X[-1000:]\n",
    "    Ytrain = Y[:-1000]\n",
    "    Ytest = Y[-1000:]\n",
    "    print(\"Xtrain\",Xtrain.shape)#(41000, 784)\n",
    "    print(\"Xtest\",Xtest.shape)#(1000, 784)\n",
    "    print(\"Ytrain\",Ytrain.shape)#(41000,)\n",
    "    print(\"Ytest\",Ytest.shape) #(1000,)\n",
    "    \n",
    "    \n",
    "    mu = Xtrain.mean(axis = 0) #(784,)\n",
    "    #print(mu)\n",
    "    print(mu.shape)#(784,)\n",
    "    \n",
    "    \n",
    "    #center the data\n",
    "    Xtrain = Xtrain - mu\n",
    "    Xtest = Xtest - mu\n",
    "    print(Xtrain)\n",
    "    print(Xtest)\n",
    "    \n",
    "    #transforming data\n",
    "    pca = PCA()\n",
    "    Ztrain = pca.fit_transform(Xtrain)\n",
    "    Ztest = pca.transform(Xtest)\n",
    "    print(Ztrain.shape)\n",
    "    print(Ztest.shape)\n",
    "    print(Ztrain)\n",
    "    print(Ztest)\n",
    "    \n",
    "    #plot_cumulative_variance(pca)\n",
    "    \n",
    "    \n",
    "    \n",
    "    Ztrain = Ztrain[:,:300]\n",
    "    Ztest = Ztest[:,:300]\n",
    "    print(Ztrain.shape) #(41000, 300)\n",
    "    print(Ztest.shape) # (1000, 300)\n",
    "    \n",
    "    \n",
    "    #normalization\n",
    "    mean = Ztrain.mean(axis = 0)\n",
    "    std = Ztrain.std(axis = 0)\n",
    "    \n",
    "    Ztrain = (Ztrain - mean)/std\n",
    "    Ztest = (Ztest - mean)/std\n",
    "    \n",
    "    \n",
    "    return Ztrain,Ztest,Xtrain,Xtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_normalized_data():\n",
    "    print(\"Reading in and transforming data...\")\n",
    "    \n",
    "    \n",
    "    df = pd.read_csv('C:/Users/TANNERU/Downloads/train.csv/train.csv')\n",
    "    #print(df)\n",
    "    data = df.values.astype(np.float32)\n",
    "    #print(data)\n",
    "    \n",
    "    np.random.shuffle(data)\n",
    "    \n",
    "    \n",
    "    X = data[:,1:] #except 1 columns\n",
    "    Y = data[:,0].astype(np.int32) #only 1st column\n",
    "    print(\"Innputs\",X)\n",
    "    print(\"output\",Y)\n",
    "    print(X.shape) #(42000, 784)\n",
    "    print(Y.shape) #(42000,)\n",
    "    \n",
    "    \n",
    "    Xtrain = X[:-1000]\n",
    "    Xtest = X[-1000:]\n",
    "    Ytrain = Y[:-1000]\n",
    "    Ytest = Y[-1000:]\n",
    "    print(\"Xtrain\",Xtrain.shape)#(41000, 784)\n",
    "    print(\"Xtest\",Xtest.shape)#(1000, 784)\n",
    "    print(\"Ytrain\",Ytrain.shape)#(41000,)\n",
    "    print(\"Ytest\",Ytest.shape) #(1000,)\n",
    "    \n",
    "    \n",
    "    mu = Xtrain.mean(axis = 0) #(784,)\n",
    "    std = Xtrain.std(axis = 0) \n",
    "    np.place(std,std == 0,1) # changes all values to 0,1\n",
    "    print(np.place(std,std == 0,1))\n",
    "    #print(mu)\n",
    "    print(mu.shape)#(784,)\n",
    "    \n",
    "    \n",
    "    #center the data\n",
    "    Xtrain = (Xtrain - mu)/std\n",
    "    Xtest = (Xtest - mu)/std\n",
    "    print(Xtrain)\n",
    "    print(Xtest)\n",
    "    \n",
    "    \n",
    "    return Xtrain,Xtest,Ytrain,Ytest\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in and transforming data...\n",
      "Innputs [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "output [8 2 6 ... 6 8 2]\n",
      "(42000, 784)\n",
      "(42000,)\n",
      "Xtrain (41000, 784)\n",
      "Xtest (1000, 784)\n",
      "Ytrain (41000,)\n",
      "Ytest (1000,)\n",
      "None\n",
      "(784,)\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32),\n",
       " array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32),\n",
       " array([8, 2, 6, ..., 0, 6, 3]),\n",
       " array([5, 4, 1, 0, 1, 0, 3, 3, 0, 3, 2, 0, 3, 7, 7, 6, 9, 1, 2, 1, 1, 6,\n",
       "        0, 0, 2, 8, 8, 0, 4, 3, 2, 9, 5, 9, 6, 7, 4, 2, 7, 8, 2, 0, 8, 7,\n",
       "        3, 7, 5, 9, 6, 2, 9, 4, 7, 9, 8, 4, 8, 4, 5, 9, 9, 3, 9, 4, 4, 1,\n",
       "        4, 2, 3, 8, 0, 0, 8, 7, 9, 8, 9, 7, 0, 3, 2, 7, 9, 7, 5, 4, 3, 6,\n",
       "        7, 7, 5, 7, 6, 0, 1, 9, 8, 4, 0, 7, 7, 6, 8, 9, 5, 4, 0, 3, 3, 7,\n",
       "        7, 9, 8, 1, 9, 6, 3, 5, 8, 0, 6, 3, 3, 8, 0, 6, 4, 3, 6, 1, 3, 0,\n",
       "        4, 5, 9, 8, 9, 3, 4, 5, 0, 6, 2, 5, 6, 1, 9, 1, 4, 0, 0, 6, 3, 3,\n",
       "        4, 5, 0, 5, 9, 2, 6, 1, 3, 9, 2, 1, 0, 8, 4, 3, 9, 7, 2, 7, 1, 4,\n",
       "        1, 0, 2, 5, 2, 9, 0, 2, 1, 1, 1, 2, 4, 9, 2, 3, 3, 0, 3, 8, 1, 4,\n",
       "        0, 1, 9, 9, 2, 4, 2, 0, 3, 6, 6, 0, 6, 4, 7, 4, 3, 0, 2, 1, 8, 8,\n",
       "        2, 9, 4, 8, 0, 4, 9, 7, 2, 4, 9, 8, 1, 4, 3, 4, 0, 2, 8, 0, 4, 9,\n",
       "        4, 2, 1, 3, 9, 9, 2, 0, 3, 1, 5, 5, 4, 3, 0, 4, 1, 9, 7, 5, 6, 0,\n",
       "        6, 9, 6, 8, 5, 0, 4, 7, 4, 7, 4, 4, 0, 7, 1, 3, 6, 4, 0, 0, 3, 8,\n",
       "        0, 6, 5, 9, 9, 0, 9, 1, 1, 4, 0, 5, 7, 7, 9, 9, 9, 8, 9, 0, 9, 2,\n",
       "        7, 9, 9, 4, 8, 4, 1, 6, 4, 4, 7, 6, 2, 5, 2, 4, 1, 3, 9, 5, 6, 5,\n",
       "        9, 9, 3, 7, 8, 5, 3, 7, 2, 1, 3, 1, 8, 6, 2, 3, 8, 6, 0, 8, 5, 3,\n",
       "        2, 1, 7, 8, 7, 6, 1, 7, 1, 6, 0, 1, 4, 2, 5, 1, 2, 7, 8, 3, 9, 5,\n",
       "        7, 7, 0, 5, 4, 4, 9, 9, 3, 4, 3, 5, 2, 3, 7, 9, 0, 4, 6, 9, 0, 5,\n",
       "        4, 2, 9, 0, 5, 0, 9, 2, 2, 0, 6, 8, 2, 8, 7, 6, 1, 2, 2, 7, 7, 1,\n",
       "        2, 4, 2, 5, 1, 8, 9, 8, 0, 9, 6, 2, 6, 5, 5, 3, 4, 3, 0, 7, 9, 6,\n",
       "        1, 7, 5, 3, 7, 0, 3, 3, 2, 2, 9, 2, 1, 4, 9, 0, 2, 1, 6, 5, 4, 4,\n",
       "        4, 5, 0, 3, 8, 5, 7, 0, 1, 8, 4, 8, 6, 6, 1, 0, 8, 8, 8, 6, 9, 8,\n",
       "        7, 3, 1, 9, 3, 7, 5, 0, 7, 4, 8, 9, 2, 8, 2, 6, 2, 1, 6, 7, 5, 9,\n",
       "        3, 6, 3, 9, 7, 8, 4, 0, 0, 8, 9, 9, 9, 0, 5, 5, 6, 6, 3, 3, 6, 9,\n",
       "        1, 2, 1, 7, 9, 7, 9, 8, 3, 3, 7, 3, 5, 3, 3, 1, 5, 7, 6, 2, 1, 8,\n",
       "        7, 1, 7, 6, 3, 6, 2, 4, 3, 2, 9, 5, 9, 4, 0, 9, 4, 4, 5, 7, 6, 2,\n",
       "        4, 2, 5, 0, 7, 5, 4, 4, 7, 6, 6, 9, 2, 5, 6, 8, 7, 7, 2, 4, 2, 3,\n",
       "        0, 9, 1, 9, 3, 3, 7, 7, 6, 4, 2, 3, 0, 2, 7, 1, 2, 8, 2, 3, 6, 9,\n",
       "        2, 0, 8, 8, 8, 6, 2, 2, 4, 1, 3, 0, 6, 9, 1, 9, 7, 7, 1, 2, 7, 1,\n",
       "        5, 9, 3, 7, 0, 4, 3, 6, 3, 2, 6, 4, 0, 3, 7, 5, 2, 2, 0, 4, 0, 0,\n",
       "        1, 8, 1, 9, 3, 2, 7, 3, 7, 3, 6, 0, 5, 5, 7, 3, 9, 0, 1, 8, 5, 9,\n",
       "        9, 6, 8, 9, 6, 8, 9, 8, 3, 5, 1, 3, 5, 8, 2, 8, 4, 0, 2, 8, 6, 7,\n",
       "        0, 5, 6, 4, 9, 6, 3, 6, 8, 4, 8, 5, 9, 6, 7, 8, 0, 8, 7, 0, 5, 8,\n",
       "        5, 0, 2, 8, 0, 2, 6, 6, 6, 2, 0, 6, 2, 5, 2, 4, 8, 1, 3, 2, 0, 5,\n",
       "        5, 4, 5, 1, 5, 5, 8, 0, 2, 9, 1, 8, 4, 5, 2, 3, 2, 9, 9, 3, 5, 8,\n",
       "        4, 6, 3, 3, 4, 4, 6, 1, 6, 1, 4, 6, 1, 7, 0, 9, 4, 8, 1, 8, 3, 3,\n",
       "        9, 1, 7, 5, 8, 3, 6, 4, 0, 0, 2, 0, 8, 3, 6, 7, 7, 8, 8, 9, 4, 4,\n",
       "        3, 2, 8, 9, 5, 6, 6, 0, 1, 9, 8, 5, 7, 1, 7, 0, 8, 1, 4, 5, 0, 8,\n",
       "        0, 6, 6, 0, 7, 4, 0, 2, 6, 0, 2, 7, 2, 2, 6, 3, 6, 3, 6, 6, 0, 3,\n",
       "        7, 1, 0, 7, 9, 4, 0, 1, 0, 5, 9, 1, 3, 1, 5, 9, 3, 0, 3, 1, 6, 2,\n",
       "        6, 6, 7, 8, 1, 7, 1, 2, 3, 3, 5, 8, 9, 1, 8, 0, 9, 4, 5, 2, 0, 7,\n",
       "        2, 2, 5, 2, 0, 3, 5, 5, 1, 9, 0, 9, 3, 4, 6, 7, 1, 4, 4, 8, 4, 7,\n",
       "        9, 6, 7, 0, 1, 0, 4, 7, 4, 0, 7, 4, 7, 0, 9, 0, 2, 0, 3, 8, 3, 9,\n",
       "        4, 2, 6, 2, 5, 5, 6, 4, 8, 6, 3, 6, 7, 4, 3, 2, 8, 8, 7, 3, 0, 6,\n",
       "        7, 0, 9, 5, 1, 3, 7, 1, 3, 1, 5, 7, 5, 8, 1, 9, 6, 0, 9, 7, 3, 2,\n",
       "        5, 4, 6, 9, 3, 2, 1, 6, 8, 2]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_normalized_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(X,w,b):\n",
    "    #softmax\n",
    "    a = X.dot(w)+b\n",
    "    expA = np.exp(a)\n",
    "    y = expA/expA.sum(axis = 1,keepdims = True)\n",
    "    return y\n",
    "\n",
    "\n",
    "\n",
    "def predict(p_y):\n",
    "    return np.argmax(p_y,axis = 1)\n",
    "\n",
    "\n",
    "def error_rate(p_y,t):\n",
    "    prediction = predict(p_y)\n",
    "    return np.mean(prediction != t)\n",
    "\n",
    "\n",
    "def cost(p_y,t):\n",
    "    tot = -t*np.log(p_y)\n",
    "    return tot.sum()\n",
    "\n",
    "\n",
    "def gradw(t,y,X):\n",
    "    return X.T.dot(t-y)\n",
    "\n",
    "\n",
    "def gradb(t,y):\n",
    "    return (t-y).sum(axis = 0)\n",
    "\n",
    "\n",
    "def y2indicator(y):\n",
    "    N = len(y)\n",
    "    y = y.astype(np.int32)\n",
    "    ind = np.zeros((N,10))\n",
    "    for i in range(N):\n",
    "        ind[i,y[i]] = 1\n",
    "    return ind\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def benchmark_full():\n",
    "    Xtrain,Xtest,Ytrain,Ytest = get_normalized_data()\n",
    "    \n",
    "    \n",
    "    N,D = Xtrain.shape\n",
    "    Ytrain_ind = y2indicator(Ytrain)\n",
    "    Ytest_ind = y2indicator(Ytest)\n",
    "    \n",
    "    \n",
    "    w = np.random.randn(D,10)/np.sqrt(D)\n",
    "    b = np.zeros(10)\n",
    "    \n",
    "    lltrain = []\n",
    "    lltest = []\n",
    "    CRtest = []\n",
    "    \n",
    "    \n",
    "    lr = 0.00004\n",
    "    reg = 0.01\n",
    "    \n",
    "    \n",
    "    for i in range(500):\n",
    "        #traning\n",
    "        p_y = forward(Xtrain,w,b)\n",
    "        \n",
    "        ll = cost(p_y,Ytrain_ind) #train cost\n",
    "        lltrain.append(ll)\n",
    "        \n",
    "        #testing\n",
    "        \n",
    "        p_y_test = forward(Xtest,w,b)\n",
    "        \n",
    "        cr = cost(p_y_test,Ytest_ind) #test cost\n",
    "        lltest.append(cr)\n",
    "        \n",
    "        \n",
    "        err = error_rate(p_y_test,Ytest)\n",
    "        CRtest.append(err)\n",
    "        \n",
    "        \n",
    "        w += lr*(gradw(Ytrain_ind,p_y,Xtrain)-reg*w)\n",
    "        b += lr*(gradb(Ytrain_ind,p_y)-reg*b)\n",
    "        \n",
    "        if i % 10 == 0:\n",
    "            print(\"iteration :\",i,\"Cost:\",ll)\n",
    "            print(\"error\",err)\n",
    "            \n",
    "    p_y = forward(Xtrain,w,b)\n",
    "    print(\"Final error rate\",error_rate(p_y,Ytest))\n",
    "    iters  = range(len(lltrain))\n",
    "    plt.plot(iters,lltrain,iters,lltest)\n",
    "    plt.show()\n",
    "    plt.plot(CRtest)\n",
    "    plt.show()\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "    \n",
    "    \n",
    "def benchmark_pca():\n",
    "    Xtrain, Xtest, Ytrain, Ytest = get_transformed_data()\n",
    "    print(\"Performing logistic regression...\")\n",
    "\n",
    "    N, D = Xtrain.shape#(41000,)\n",
    "    print(N,D)\n",
    "    Ytrain  =  Ytrain.astype(np.int32)\n",
    "    Ytest = Ytest.astype(np.int32)\n",
    "    \n",
    "    \n",
    "    Ytrain_ind = np.zeros((N, 10))\n",
    "    for i in range(N):\n",
    "        Ytrain_ind[i, Ytrain[i]] = 1\n",
    "\n",
    "    Ntest = len(Ytest)\n",
    "    print(Ntest)\n",
    "    Ytest_ind = np.zeros((Ntest, 10))\n",
    "    for i in range(Ntest):\n",
    "        Ytest_ind[i, Ytest[i]] = 1\n",
    "\n",
    "    W = np.random.randn(D, 10) / np.sqrt(D)\n",
    "    b = np.zeros(10)\n",
    "    LL = []\n",
    "    LLtest = []\n",
    "    CRtest = []\n",
    "\n",
    "    # D = 300 -> error = 0.07\n",
    "    lr = 0.0001\n",
    "    reg = 0.01\n",
    "    for i in range(200):\n",
    "        #training\n",
    "        p_y = forward(Xtrain, W, b)\n",
    "        # print \"p_y:\", p_y\n",
    "        ll = cost(p_y, Ytrain_ind)\n",
    "        LL.append(ll)\n",
    "        \n",
    "        #testing\n",
    "        p_y_test = forward(Xtest, W, b)\n",
    "        lltest = cost(p_y_test, Ytest_ind)\n",
    "        LLtest.append(lltest)\n",
    "\n",
    "        #error rate\n",
    "        err = error_rate(p_y_test, Ytest)\n",
    "        CRtest.append(err)\n",
    "\n",
    "        W += lr*(gradW(Ytrain_ind, p_y, Xtrain) - reg*W)\n",
    "        b += lr*(gradb(Ytrain_ind, p_y) - reg*b)\n",
    "        if i % 10 == 0:\n",
    "            print(\"Cost at iteration %d: %.6f\" % (i, ll))\n",
    "            print(\"Error rate:\", err)\n",
    "\n",
    "    p_y = forward(Xtest, W, b)\n",
    "    print(\"Final error rate:\", error_rate(p_y, Ytest))\n",
    "    iters = range(len(LL))\n",
    "    plt.plot(iters, LL, iters, LLtest)\n",
    "    plt.show()\n",
    "    plt.plot(CRtest)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed Data\n",
      "Innputs [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "output [3 5 1 ... 6 4 2]\n",
      "(42000, 784)\n",
      "(42000,)\n",
      "Xtrain (41000, 784)\n",
      "Xtest (1000, 784)\n",
      "Ytrain (41000,)\n",
      "Ytest (1000,)\n",
      "(784,)\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(41000, 784)\n",
      "(1000, 784)\n",
      "[[-1.92687332e+02 -6.92293213e+02 -2.34037766e+02 ... -0.00000000e+00\n",
      "  -0.00000000e+00 -0.00000000e+00]\n",
      " [ 2.39956512e+02 -7.05968994e+02 -4.08868904e+01 ...  1.30984886e-03\n",
      "  -2.54572515e-04 -2.43882623e-05]\n",
      " [-9.66904724e+02 -6.74320740e+02  1.79359604e+02 ... -1.08956557e-03\n",
      "  -1.06121646e-04 -4.63867291e-05]\n",
      " ...\n",
      " [-6.20596428e+01  4.52255310e+02  1.57862793e+02 ...  5.04684476e-06\n",
      "  -3.04663604e-06  1.15492367e-06]\n",
      " [-4.37443451e+02 -2.64408417e+02  1.59617035e+02 ... -1.95774464e-06\n",
      "   1.62470610e-06  2.06008025e-07]\n",
      " [ 1.40455688e+02 -3.63016327e+02  8.68286255e+02 ...  1.83774796e-06\n",
      "   4.86394981e-07 -3.58641761e-09]]\n",
      "[[ 2.8345392e+02  6.0747559e+02  4.3305893e+02 ... -9.2577167e-05\n",
      "   8.1497208e-05  7.4267642e-05]\n",
      " [ 1.9081967e+02 -5.9108777e+02  9.9349640e+01 ... -1.3333885e-05\n",
      "   4.5729757e-05  2.3029870e-05]\n",
      " [ 1.3531689e+03 -4.2457684e+02 -6.3827408e+01 ... -1.3099362e-04\n",
      "  -2.1706989e-04  5.9857633e-05]\n",
      " ...\n",
      " [-1.4024866e+02 -3.3113922e+02  9.7114044e+01 ...  8.6217318e-05\n",
      "  -4.1397575e-06  1.4240140e-07]\n",
      " [-1.5513739e+02  7.1332776e+02  1.0943690e+01 ... -7.3866642e-05\n",
      "  -5.1285926e-05 -6.6570072e-05]\n",
      " [ 9.0619421e+02 -5.8735758e-01  1.4952353e+02 ... -3.6039551e-06\n",
      "   2.0598032e-04 -9.4305440e-05]]\n",
      "(41000, 300)\n",
      "(1000, 300)\n",
      "Performing logistic regression...\n",
      "41000 300\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index -12 is out of bounds for axis 1 with size 10",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-accb9a4e030b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbenchmark_pca\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-5-87935decb8fb>\u001b[0m in \u001b[0;36mbenchmark_pca\u001b[1;34m()\u001b[0m\n\u001b[0;32m    117\u001b[0m     \u001b[0mYtrain_ind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m         \u001b[0mYtrain_ind\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mYtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m     \u001b[0mNtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mYtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index -12 is out of bounds for axis 1 with size 10"
     ]
    }
   ],
   "source": [
    "benchmark_pca()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in and transforming data...\n",
      "Innputs [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "output [3 3 5 ... 5 9 0]\n",
      "(42000, 784)\n",
      "(42000,)\n",
      "Xtrain (41000, 784)\n",
      "Xtest (1000, 784)\n",
      "Ytrain (41000,)\n",
      "Ytest (1000,)\n",
      "None\n",
      "(784,)\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "iteration : 0 Cost: 104135.82042408394\n",
      "error 0.909\n",
      "iteration : 10 Cost: 14843.63969950367\n",
      "error 0.121\n",
      "iteration : 20 Cost: 11759.3668167405\n",
      "error 0.092\n",
      "iteration : 30 Cost: 11311.81385821835\n",
      "error 0.099\n",
      "iteration : 40 Cost: 11510.255627965877\n",
      "error 0.109\n",
      "iteration : 50 Cost: 10431.144855521445\n",
      "error 0.095\n",
      "iteration : 60 Cost: 10215.811398413027\n",
      "error 0.095\n",
      "iteration : 70 Cost: 10084.074144856148\n",
      "error 0.096\n",
      "iteration : 80 Cost: 9991.882308099252\n",
      "error 0.096\n",
      "iteration : 90 Cost: 9879.28967304558\n",
      "error 0.095\n",
      "iteration : 100 Cost: 9743.004755044434\n",
      "error 0.096\n",
      "iteration : 110 Cost: 9624.775655221294\n",
      "error 0.096\n",
      "iteration : 120 Cost: 9527.488466752358\n",
      "error 0.094\n"
     ]
    }
   ],
   "source": [
    "benchmark_full()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
